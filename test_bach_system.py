#!/usr/bin/env python3
"""
ë°”í í‰ê· ìœ¨ ê¸°ì¤€ ì™„ì „í•œ ìŒì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
C0ë¶€í„° B8ê¹Œì§€ 108ê°œ ìŒì • ì „ì²´ ë¶„ì„
"""
import requests
import numpy as np
import base64
import math

def generate_complete_frequency_table():
    """ë°”í 12í‰ê· ìœ¨ ê¸°ì¤€ ì™„ì „í•œ ì£¼íŒŒìˆ˜ í…Œì´ë¸” ìƒì„±"""
    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    table = {}
    
    # C4 = 261.63Hz ê¸°ì¤€
    c4_freq = 261.6255653005986
    
    for octave in range(0, 9):  # C0 ~ B8
        for note_idx, note in enumerate(notes):
            # C4ë¡œë¶€í„°ì˜ ë°˜ìŒ ê±°ë¦¬
            semitones_from_c4 = (octave - 4) * 12 + note_idx
            frequency = c4_freq * (2 ** (semitones_from_c4 / 12))
            
            full_name = f"{note}{octave}"
            table[full_name] = frequency
    
    return table

def test_bach_temperament_system():
    """ë°”í í‰ê· ìœ¨ ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¼ ë°”í í‰ê· ìœ¨(Well-Tempered) ì™„ì „ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    freq_table = generate_complete_frequency_table()
    
    # ì£¼ìš” ìŒì •ë“¤ ì„ ë³„ í…ŒìŠ¤íŠ¸ (ëŒ€í‘œì ì¸ 24ê°œ)
    key_notes = [
        # ë‚®ì€ ì˜¥íƒ€ë¸Œ
        "C2", "D2", "E2", "F2", "G2", "A2", "B2",
        # ì¤‘ê°„ ì˜¥íƒ€ë¸Œ (ì„±ì•… ì£¼ìš” ìŒì—­)
        "C3", "D3", "E3", "F3", "G3", "A3", "B3",
        "C4", "D4", "E4", "F4", "G4", "A4", "B4",
        # ë†’ì€ ì˜¥íƒ€ë¸Œ
        "C5", "D5", "E5", "F5", "G5", "A5", "B5",
    ]
    
    print(f"ğŸµ ì£¼ìš” 24ê°œ ìŒì • CREPE ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("-" * 60)
    
    success_count = 0
    total_error = 0.0
    
    for note_name in key_notes:
        target_freq = freq_table[note_name]
        print(f"\nğŸ¼ {note_name}: {target_freq:.1f} Hz")
        
        # ìˆœìˆ˜ ì‚¬ì¸íŒŒ ìƒì„±
        duration = 1.0
        sample_rate = 48000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        
        # ì‹¤ì œ ìŒì„±ê³¼ ìœ ì‚¬í•˜ê²Œ í•˜ëª¨ë‹‰ ì¶”ê°€
        fundamental = 0.8 * np.sin(2 * np.pi * target_freq * t)
        harmonic2 = 0.2 * np.sin(2 * np.pi * target_freq * 2 * t)
        harmonic3 = 0.1 * np.sin(2 * np.pi * target_freq * 3 * t)
        
        audio = fundamental + harmonic2 + harmonic3
        
        # Base64 ì¸ì½”ë”©
        byte_data = audio.astype(np.float32).tobytes()
        audio_b64 = base64.b64encode(byte_data).decode('utf-8')
        
        try:
            response = requests.post('http://localhost:5002/analyze', 
                                   json={
                                       'audio_base64': audio_b64,
                                       'sample_rate': 48000
                                   },
                                   timeout=8)
            
            if response.status_code == 200:
                result = response.json()
                frequencies = result.get('frequencies', [])
                confidences = result.get('confidence', [])
                
                if frequencies and confidences:
                    # ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼
                    max_conf_idx = np.argmax(confidences)
                    detected_freq = frequencies[max_conf_idx]
                    confidence = confidences[max_conf_idx]
                    
                    # ì˜¤ì°¨ ê³„ì‚°
                    error_hz = abs(detected_freq - target_freq)
                    error_cents = 1200 * math.log2(detected_freq / target_freq) if target_freq > 0 else 0
                    
                    # ì •í™•ë„ í‰ê°€
                    if error_cents < 10:
                        status = "âœ… ì™„ë²½"
                        accuracy = "PERFECT"
                    elif error_cents < 20:
                        status = "âœ… ìš°ìˆ˜"
                        accuracy = "EXCELLENT"
                    elif error_cents < 50:
                        status = "âš¡ ì–‘í˜¸"
                        accuracy = "GOOD"
                    else:
                        status = "âš ï¸ ê°œì„ í•„ìš”"
                        accuracy = "NEEDS_WORK"
                    
                    detected_note = frequency_to_note_name(detected_freq)
                    
                    print(f"   ê°ì§€: {detected_freq:.1f} Hz ({detected_note})")
                    print(f"   ì˜¤ì°¨: {error_hz:.1f} Hz ({error_cents:+.1f} ì„¼íŠ¸)")
                    print(f"   ì‹ ë¢°ë„: {confidence:.3f}")
                    print(f"   í‰ê°€: {status} ({accuracy})")
                    
                    if error_hz < 10:  # 10Hz ì´í•˜ëŠ” ì„±ê³µ
                        success_count += 1
                    
                    total_error += error_hz
                    
        except Exception as e:
            print(f"   âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ë°”í í‰ê· ìœ¨ ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)
    print(f"âœ… ì„±ê³µë¥ : {success_count}/{len(key_notes)} ({success_count/len(key_notes)*100:.1f}%)")
    print(f"ğŸ“ˆ í‰ê·  ì˜¤ì°¨: {total_error/len(key_notes):.1f} Hz")
    
    if success_count >= len(key_notes) * 0.9:
        print("ğŸ† ë°”í í‰ê· ìœ¨ ì‹œìŠ¤í…œ ì™„ë²½ êµ¬í˜„ ì„±ê³µ!")
    elif success_count >= len(key_notes) * 0.8:
        print("ğŸ‰ ë°”í í‰ê· ìœ¨ ì‹œìŠ¤í…œ ìš°ìˆ˜í•˜ê²Œ êµ¬í˜„ë¨!")
    else:
        print("âš ï¸ ì‹œìŠ¤í…œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

def frequency_to_note_name(frequency):
    """ì£¼íŒŒìˆ˜ë¥¼ ìŒì • ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    if frequency <= 0:
        return ''
    
    A4 = 440.0
    semitones = 12 * math.log2(frequency / A4)
    note_index = (int(semitones) + 9) % 12
    octave = 4 + (int(semitones) + 9) // 12
    
    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    return f"{notes[note_index]}{octave}"

def test_complete_chromatic_scale():
    """ì „ì²´ ë°˜ìŒê³„ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ¼ ì™„ì „í•œ ë°˜ìŒê³„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (C3-C5)")
    print("-" * 60)
    
    freq_table = generate_complete_frequency_table()
    
    # C3ë¶€í„° C5ê¹Œì§€ 25ê°œ ë°˜ìŒ
    chromatic_notes = []
    for octave in [3, 4, 5]:
        for note in ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']:
            chromatic_notes.append(f"{note}{octave}")
            if note == 'C' and octave == 5:  # C5ê¹Œì§€ë§Œ
                break
    
    print(f"ğŸµ ë°˜ìŒê³„ {len(chromatic_notes)}ê°œ ìŒì • ì—°ì† í…ŒìŠ¤íŠ¸")
    
    for i, note_name in enumerate(chromatic_notes):
        target_freq = freq_table[note_name]
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (ì‹œê°„ ì ˆì•½ì„ ìœ„í•´)
        duration = 0.5
        sample_rate = 48000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio = 0.5 * np.sin(2 * np.pi * target_freq * t)
        
        byte_data = audio.astype(np.float32).tobytes()
        audio_b64 = base64.b64encode(byte_data).decode('utf-8')
        
        try:
            response = requests.post('http://localhost:5002/analyze', 
                                   json={
                                       'audio_base64': audio_b64,
                                       'sample_rate': 48000
                                   },
                                   timeout=5)
            
            if response.status_code == 200:
                result = response.json()
                frequencies = result.get('frequencies', [])
                confidences = result.get('confidence', [])
                
                if frequencies and confidences:
                    max_conf_idx = np.argmax(confidences)
                    detected_freq = frequencies[max_conf_idx]
                    error_hz = abs(detected_freq - target_freq)
                    
                    status = "âœ…" if error_hz < 10 else "âŒ"
                    print(f"{status} {note_name}: {target_freq:.0f}Hz â†’ {detected_freq:.0f}Hz (Â±{error_hz:.1f}Hz)")
                    
        except:
            print(f"âŒ {note_name}: ë¶„ì„ ì‹¤íŒ¨")

if __name__ == "__main__":
    test_bach_temperament_system()
    test_complete_chromatic_scale()