# 🎤 오비완(Obiwan) v4: 인간적 청각 접근법 기반 AI 보컬 트레이너

## 📍 핵심 비전 요약

### 🧠 **일론 머스크의 자율주행 철학을 보컬 트레이닝에 적용**
> "인간은 눈과 생물학적 신경망으로 운전한다. 카메라와 AI만이 일반화된 해법"
> 
> → **오비완**: "인간은 귀와 신경망으로 노래를 판단한다. 마이크와 AI만이 일반화된 보컬 코칭"

### 🎯 **목표**: 취미부터 프로까지 모든 수준에서 사용 가능한 AI 보컬 트레이너
- 마치 **아이폰 프로를 모든 사진가가 쓰듯이**
- **인간 보컬 코치처럼 듣고, 분석하고, 피드백**

---

## 🚀 개발 단계별 로드맵

### **Phase 1: 음정 정확도 마스터 (현재 단계)** ✅ 진행 중
- **핵심**: CREPE + SPICE 듀얼 엔진으로 인간 수준 피치 분석
- **인간적 접근**: 절대 주파수보다 **상대적 음정 패턴(인터벌)** 중시
- **현재 상태**: 기본 피치 검출 완료, 정확도 개선 중

### **Phase 2: 감정 표현 분석**
- **다이내믹 분석**: 크레셴도/디미누엔도 등 강약 변화
- **음색/톤 분석**: 밝기, 따뜻함, 브라시 톤 등 스펙트럴 특성
- **비브라토 패턴**: 속도, 진폭, 표현적 사용

### **Phase 3: 발음·딕션 코칭**
- **노래용 ASR**: 일반 음성 인식과 다른 싱잉 특화 모델
- **포먼트 기반 모음 검증**: Praat 활용 모음 정확도 체크
- **자음 명료도**: 스펙트럴 플럭스 기반 자음 분석

---

## 🧠 **인간 청각 처리 모사 전략**

### **1. 신경과학적 접근**
```
인간 청각 피질의 특성:
✓ 절대 주파수보다 음 간격(인터벌) 인식에 특화
✓ 시간에 따른 패턴(멜로디 윤곽) 분석
✓ 소음 속에서 보컬 분리 능력
```

### **2. 심리음향학적 특성 반영**
- **Mel/Constant-Q 스펙트로그램**: 로그 주파수 축 사용
- **CQT 영역 처리**: 음악적 간격에 대응하는 분석
- **청각 장면 분석**: 배경음과 보컬 분리

### **3. 상대적 평가 중심**
- **연구 결과**: 절대 음 무시하고 음 간격 + 비브라토만으로 **83% 정확도**
- **무곡 평가**: 정해진 멜로디 없이도 인터벌 일관성으로 품질 판단
- **DTW 정렬**: 타이밍 오차 보정 후 노트별 정확도 산출

---

## 🔧 **현재 기술 스택 vs 비전 기술 스택**

### **현재 (v3)**:
```
✅ CREPE: CNN 기반 파형 직접 처리
✅ SPICE: 자기지도 학습, 신뢰도 산출
✅ Flutter + macOS AVAudioEngine
✅ 실시간 오디오 캡처 및 분석
```

### **비전 (v4+ 로드맵)**:
```
🎯 Librosa: 스펙트로그램, 온셋 검출
🎯 Praat/Parselmouth: 포먼트 분석 (발음용)
🎯 YIN/pYIN: 경량 검증용 피치 검출
🎯 Essentia/openSMILE: 다차원 특성 추출
🎯 PyTorch/TensorFlow: 커스텀 평가 모델
🎯 TFLite/CoreML: 온디바이스 경량화
```

---

## 🎭 **인간적 피드백 메커니즘**

### **현재 개선 중**:
- ✅ 센트 단위 정확도 계산
- ✅ 신뢰도 기반 필터링
- ✅ 음표 통합 및 지속시간 체크

### **목표 피드백 스타일**:
```
인간 코치: "후렴은 대체로 맞았지만 마지막 음이 반음 정도 낮았어요"
↓
오비완 목표: "정확 음정 비율 85%. 2분 30초 구간 마지막 음을 반음 올려보세요"
```

### **고급 피드백 단계**:
- **구간별 분석**: "브리지는 완벽, 후렴 마지막 라인 개선 필요"
- **표현 코칭**: "음정 훌륭! 볼륨 대비를 더 주세요"
- **기술적 조언**: "목으로 미는 소리 → 횡격막 서포트 강화"

---

## 🏗️ **시스템 아키텍처 비전**

### **입력 처리**:
```
마이크 입력 → 노이즈 저감 → 보컬 분리 → 특성 추출
```

### **분석 모듈**:
```
1. 피치 검출 (CREPE/SPICE)
2. 리듬/타이밍 (온셋/비트 트래킹)  
3. 음색/볼륨 (스펙트럴 특성)
4. 가사/음소 (노래용 ASR)
```

### **평가 로직**:
```
규칙 기반 + ML 모델 → 종합 점수
↓
사용자 수준별 피드백 스케일링
↓  
시각화 + 텍스트/오디오 코칭
```

---

## 📊 **개발 우선순위 (현재 기준)**

### **🚨 즉시 해결 (v3.1)**:
1. ✅ SPICE 주파수 보정 오류 해결
2. ✅ 과도한 음표 감지 문제 해결  
3. 🔄 실제 사용자 테스트로 정확도 검증

### **🎯 단기 목표 (v3.2)**:
1. **DTW 기반 멜로디 정렬** 구현
2. **비브라토 분석** 모듈 추가
3. **볼륨 다이내믹** 분석 시작

### **🚀 중기 목표 (v4.0)**:
1. **감정 표현 분석** 시스템 구축
2. **노래용 ASR** 통합 시작
3. **커스텀 평가 모델** 학습

---

## 🎓 **핵심 연구 인사이트**

### **검증된 접근법**:
- **노래방 스코어링 연구**: 피치+볼륨+리듬 결합으로 **인간 평가와 0.82 상관**
- **품질 분류 연구**: 인터벌 정확도 + 비브라토만으로 **83% 정확도**
- **발음 탐지 연구**: 포스드 얼라인먼트로 **EER 11.3%** 달성

### **기술적 검증**:
- **SPICE**: 구글 FreddieMeter에서 실제 사용
- **CREPE**: 대규모 데이터 학습, pYIN 대등 성능
- **CQT 변환**: 음악적 특성에 최적화된 주파수 표현

---

## 🎯 **성공 지표**

### **단기 (v3 완성)**:
- [ ] 사용자 테스트에서 "음정이 정확하다" 90%+ 만족도
- [ ] 7개 음 부른 것이 7±2개로 감지되는 정확도
- [ ] 실시간 분석 지연시간 500ms 이하

### **중기 (v4 달성)**:
- [ ] 감정 표현 피드백에 대한 사용자 만족도 80%+
- [ ] 발음 교정 기능으로 딕션 개선 체감도 70%+
- [ ] 인간 보컬 코치와의 평가 일치도 75%+

### **장기 비전**:
- [ ] "AI 보컬 코치" 카테고리 선도 제품
- [ ] 프로 가수들도 사용하는 수준의 피드백 품질
- [ ] 다양한 음악 장르와 보컬 스타일 대응

---

**결론**: 오비완은 단순한 피치 튜너가 아닌, **인간 보컬 코치의 청각과 판단력을 모사한 AI 시스템**을 목표로 한다. 현재 v3에서 기본 피치 분석을 완성하고, 점진적으로 인간적 특성을 더해가며 궁극적으로는 **"귀와 신경망으로 코칭하는 AI"**를 실현한다.