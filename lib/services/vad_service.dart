import 'dart:typed_data';
import 'dart:math' as math;
import 'dart:collection';

/// Voice Activity Detection (VAD) Service
/// ìŒì„± í™œë™ ê°ì§€ë¡œ ë¬´ì„± êµ¬ê°„ ìŠ¤í‚µ â†’ ì—°ì‚°ëŸ‰ 20-40% ì ˆê°
class VADService {
  // VAD íŒŒë¼ë¯¸í„°
  static const double kEnergyThresholdMin = 0.001;
  static const double kEnergyThresholdMax = 0.1;
  static const double kZCRThresholdUnvoiced = 0.3;
  static const double kZCRThresholdVoiced = 0.1;
  static const int kHangoverFrames = 10;
  static const int kLookaheadFrames = 3;
  static const int kSmoothingFrames = 5;
  
  // ìŠ¤í™íŠ¸ëŸ¼ ê¸°ë°˜ VAD íŒŒë¼ë¯¸í„°
  static const double kSpectralCentroidThreshold = 500.0; // Hz
  static const double kSpectralFlatnessThreshold = 0.5;
  static const double kSpectralRolloffThreshold = 0.85;
  
  // ì ì‘í˜• ì„ê³„ê°’
  double _adaptiveEnergyThreshold = 0.01;
  double _noiseFloor = 0.0;
  double _signalPeak = 1.0;
  
  // ìƒíƒœ ì¶”ì 
  bool _isVoiceActive = false;
  int _hangoverCounter = 0;
  int _silenceCounter = 0;
  int _voiceCounter = 0;
  
  // ë²„í¼
  final Queue<double> _energyBuffer = Queue<double>();
  final Queue<double> _zcrBuffer = Queue<double>();
  final Queue<bool> _vadBuffer = Queue<bool>();
  
  // í†µê³„
  int _totalFrames = 0;
  int _voicedFrames = 0;
  int _processedFrames = 0;
  double _computationSaved = 0.0;
  
  /// VAD ì´ˆê¸°í™”
  Future<void> initialize() async {
    print('ğŸ™ï¸ VAD ì„œë¹„ìŠ¤ ì´ˆê¸°í™”');
    await calibrateNoiseFloor();
  }
  
  /// ë…¸ì´ì¦ˆ í”Œë¡œì–´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
  Future<void> calibrateNoiseFloor({List<double>? samples}) async {
    if (samples != null && samples.isNotEmpty) {
      // ì œê³µëœ ìƒ˜í”Œë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
      final energies = <double>[];
      const frameSize = 512;
      
      for (int i = 0; i < samples.length - frameSize; i += frameSize) {
        final frame = samples.sublist(i, i + frameSize);
        energies.add(_calculateEnergy(frame));
      }
      
      if (energies.isNotEmpty) {
        energies.sort();
        _noiseFloor = energies[energies.length ~/ 4]; // 25 í¼ì„¼íƒ€ì¼
        _adaptiveEnergyThreshold = _noiseFloor * 3.0;
        
        print('âœ… ë…¸ì´ì¦ˆ í”Œë¡œì–´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ');
        print('ğŸ“Š Noise Floor: ${_noiseFloor.toStringAsFixed(6)}');
        print('ğŸ“Š Adaptive Threshold: ${_adaptiveEnergyThreshold.toStringAsFixed(6)}');
      }
    }
  }
  
  /// ë©”ì¸ VAD ì²˜ë¦¬
  VADResult processFrame(List<double> frame) {
    _totalFrames++;
    
    // 1. ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ
    final energy = _calculateEnergy(frame);
    final zcr = _calculateZCR(frame);
    final spectralFeatures = _extractSpectralFeatures(frame);
    
    // 2. ë²„í¼ ì—…ë°ì´íŠ¸
    _updateBuffers(energy, zcr);
    
    // 3. ì ì‘í˜• ì„ê³„ê°’ ì—…ë°ì´íŠ¸
    _updateAdaptiveThreshold(energy);
    
    // 4. ë©€í‹°ëª¨ë‹¬ VAD ê²°ì •
    final decision = _makeVADDecision(
      energy: energy,
      zcr: zcr,
      spectralCentroid: spectralFeatures.centroid,
      spectralFlatness: spectralFeatures.flatness,
    );
    
    // 5. í›„ì²˜ë¦¬ (í–‰ì˜¤ë²„, ìŠ¤ë¬´ë”©)
    final finalDecision = _postProcessDecision(decision);
    
    // 6. í†µê³„ ì—…ë°ì´íŠ¸
    if (finalDecision.isVoiced) {
      _voicedFrames++;
      _processedFrames++;
    } else {
      // ë¬´ì„± êµ¬ê°„ì€ ì²˜ë¦¬ ìŠ¤í‚µ
      _computationSaved++;
    }
    
    // 7. ì„±ëŠ¥ ë¦¬í¬íŠ¸ (ë§¤ 100 í”„ë ˆì„ë§ˆë‹¤)
    if (_totalFrames % 100 == 0) {
      final reductionRate = (_computationSaved / _totalFrames) * 100;
      print('ğŸ“Š VAD ì—°ì‚° ì ˆê°ë¥ : ${reductionRate.toStringAsFixed(1)}%');
      print('ğŸ“Š ìŒì„± í”„ë ˆì„ ë¹„ìœ¨: ${(_voicedFrames * 100.0 / _totalFrames).toStringAsFixed(1)}%');
    }
    
    return finalDecision;
  }
  
  /// ì—ë„ˆì§€ ê³„ì‚° (RMS)
  double _calculateEnergy(List<double> frame) {
    double sum = 0;
    for (final sample in frame) {
      sum += sample * sample;
    }
    return math.sqrt(sum / frame.length);
  }
  
  /// Zero Crossing Rate ê³„ì‚°
  double _calculateZCR(List<double> frame) {
    int crossings = 0;
    for (int i = 1; i < frame.length; i++) {
      if ((frame[i] >= 0) != (frame[i-1] >= 0)) {
        crossings++;
      }
    }
    return crossings / frame.length;
  }
  
  /// ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§• ì¶”ì¶œ
  SpectralFeatures _extractSpectralFeatures(List<double> frame) {
    // ê°„ë‹¨í•œ FFT (DFT) êµ¬í˜„
    final fftSize = frame.length;
    final spectrum = <double>[];
    
    // ì‹¤ì œë¡œëŠ” FFT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
    for (int k = 0; k < fftSize ~/ 2; k++) {
      double real = 0;
      double imag = 0;
      
      for (int n = 0; n < fftSize; n++) {
        final angle = -2 * math.pi * k * n / fftSize;
        real += frame[n] * math.cos(angle);
        imag += frame[n] * math.sin(angle);
      }
      
      spectrum.add(math.sqrt(real * real + imag * imag));
    }
    
    // Spectral Centroid (ë¬´ê²Œ ì¤‘ì‹¬ ì£¼íŒŒìˆ˜)
    double centroid = 0;
    double totalMagnitude = 0;
    
    for (int i = 0; i < spectrum.length; i++) {
      final freq = i * 48000.0 / fftSize;
      centroid += freq * spectrum[i];
      totalMagnitude += spectrum[i];
    }
    
    if (totalMagnitude > 0) {
      centroid /= totalMagnitude;
    }
    
    // Spectral Flatness (í‰íƒ„ë„)
    double geometricMean = 1;
    double arithmeticMean = 0;
    int count = 0;
    
    for (final mag in spectrum) {
      if (mag > 0) {
        geometricMean *= math.pow(mag, 1.0 / spectrum.length);
        arithmeticMean += mag;
        count++;
      }
    }
    
    arithmeticMean /= count;
    final flatness = arithmeticMean > 0 ? geometricMean / arithmeticMean : 0;
    
    return SpectralFeatures(
      centroid: centroid,
      flatness: flatness,
      rolloff: 0.85, // ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ê³ ì •ê°’
    );
  }
  
  /// ë²„í¼ ì—…ë°ì´íŠ¸
  void _updateBuffers(double energy, double zcr) {
    _energyBuffer.add(energy);
    if (_energyBuffer.length > kSmoothingFrames) {
      _energyBuffer.removeFirst();
    }
    
    _zcrBuffer.add(zcr);
    if (_zcrBuffer.length > kSmoothingFrames) {
      _zcrBuffer.removeFirst();
    }
  }
  
  /// ì ì‘í˜• ì„ê³„ê°’ ì—…ë°ì´íŠ¸
  void _updateAdaptiveThreshold(double energy) {
    // ì´ë™ í‰ê· ìœ¼ë¡œ ì²œì²œíˆ ì¡°ì •
    const alpha = 0.98; // ìŠ¬ë¡œìš° ì—…ë°ì´íŠ¸
    
    if (!_isVoiceActive) {
      // ë¬´ìŒ êµ¬ê°„ì—ì„œë§Œ ë…¸ì´ì¦ˆ í”Œë¡œì–´ ì—…ë°ì´íŠ¸
      _noiseFloor = alpha * _noiseFloor + (1 - alpha) * energy;
      _adaptiveEnergyThreshold = _noiseFloor * 3.0;
    } else {
      // ìŒì„± êµ¬ê°„ì—ì„œ í”¼í¬ ì¶”ì 
      if (energy > _signalPeak) {
        _signalPeak = energy;
      }
    }
  }
  
  /// ë©€í‹°ëª¨ë‹¬ VAD ê²°ì •
  VADDecision _makeVADDecision({
    required double energy,
    required double zcr,
    required double spectralCentroid,
    required double spectralFlatness,
  }) {
    // ê° íŠ¹ì§•ì— ëŒ€í•œ íˆ¬í‘œ
    int votes = 0;
    double confidence = 0;
    
    // 1. ì—ë„ˆì§€ ê¸°ë°˜ íˆ¬í‘œ
    if (energy > _adaptiveEnergyThreshold) {
      votes++;
      confidence += 0.3;
    }
    
    // 2. ZCR ê¸°ë°˜ íˆ¬í‘œ (ë‚®ì€ ZCR = ìŒì„±)
    if (zcr < kZCRThresholdVoiced) {
      votes++;
      confidence += 0.2;
    } else if (zcr > kZCRThresholdUnvoiced) {
      votes--;
      confidence -= 0.1;
    }
    
    // 3. ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ (ìŒì„±ì€ ë³´í†µ 200-3000Hz)
    if (spectralCentroid > 200 && spectralCentroid < 3000) {
      votes++;
      confidence += 0.25;
    }
    
    // 4. ìŠ¤í™íŠ¸ëŸ¼ í‰íƒ„ë„ (ìŒì„±ì€ ë‚®ì€ í‰íƒ„ë„)
    if (spectralFlatness < kSpectralFlatnessThreshold) {
      votes++;
      confidence += 0.25;
    }
    
    // ìµœì¢… ê²°ì •
    final isVoiced = votes >= 2; // ê³¼ë°˜ìˆ˜ íˆ¬í‘œ
    confidence = confidence.clamp(0, 1);
    
    return VADDecision(
      isVoiced: isVoiced,
      confidence: confidence,
      energy: energy,
      zcr: zcr,
    );
  }
  
  /// í›„ì²˜ë¦¬ (Hangover, Smoothing)
  VADResult _postProcessDecision(VADDecision decision) {
    // Hangover ë¡œì§: ìŒì„± ì¢…ë£Œ í›„ ì¼ì • í”„ë ˆì„ ìœ ì§€
    if (decision.isVoiced) {
      _isVoiceActive = true;
      _hangoverCounter = kHangoverFrames;
      _voiceCounter++;
      _silenceCounter = 0;
    } else {
      _silenceCounter++;
      
      if (_hangoverCounter > 0) {
        _hangoverCounter--;
        _isVoiceActive = true; // Hangover ê¸°ê°„ ì¤‘ì—ëŠ” ìŒì„± ìœ ì§€
      } else {
        _isVoiceActive = false;
        _voiceCounter = 0;
      }
    }
    
    // ìŠ¤ë¬´ë”©: ì§§ì€ ë¬´ìŒ êµ¬ê°„ ë¬´ì‹œ
    _vadBuffer.add(_isVoiceActive);
    if (_vadBuffer.length > kSmoothingFrames) {
      _vadBuffer.removeFirst();
    }
    
    // ë²„í¼ì˜ ê³¼ë°˜ìˆ˜ê°€ ìŒì„±ì´ë©´ ìŒì„±ìœ¼ë¡œ íŒë‹¨
    final voicedCount = _vadBuffer.where((v) => v).length;
    final smoothedDecision = voicedCount > kSmoothingFrames ~/ 2;
    
    // ìµœì¢… ê²°ê³¼
    return VADResult(
      isVoiced: smoothedDecision,
      confidence: decision.confidence,
      energy: decision.energy,
      zcr: decision.zcr,
      hangoverRemaining: _hangoverCounter,
      consecutiveSilence: _silenceCounter,
      consecutiveVoice: _voiceCounter,
    );
  }
  
  /// í†µê³„ íšë“
  VADStatistics getStatistics() {
    return VADStatistics(
      totalFrames: _totalFrames,
      voicedFrames: _voicedFrames,
      processedFrames: _processedFrames,
      computationSaved: _computationSaved / _totalFrames,
      voiceActivityRatio: _voicedFrames / math.max(1, _totalFrames),
      noiseFloor: _noiseFloor,
      adaptiveThreshold: _adaptiveEnergyThreshold,
    );
  }
  
  /// ë¦¬ì…‹
  void reset() {
    _isVoiceActive = false;
    _hangoverCounter = 0;
    _silenceCounter = 0;
    _voiceCounter = 0;
    _energyBuffer.clear();
    _zcrBuffer.clear();
    _vadBuffer.clear();
    _totalFrames = 0;
    _voicedFrames = 0;
    _processedFrames = 0;
    _computationSaved = 0;
  }
  
  /// ê³ ê¸‰ VAD: ê¸°ê³„í•™ìŠµ ê¸°ë°˜ (TFLite ëª¨ë¸ ì‚¬ìš© ì‹œ)
  Future<VADResult> processFrameML(List<double> frame) async {
    // TODO: WebRTC VAD ë˜ëŠ” ê²½ëŸ‰ ML ëª¨ë¸ í†µí•©
    // í˜„ì¬ëŠ” ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
    return processFrame(frame);
  }
}

/// ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§•
class SpectralFeatures {
  final double centroid;  // ì£¼íŒŒìˆ˜ ë¬´ê²Œ ì¤‘ì‹¬
  final double flatness;  // ìŠ¤í™íŠ¸ëŸ¼ í‰íƒ„ë„
  final double rolloff;   // ì—ë„ˆì§€ 85% ì§€ì 
  
  const SpectralFeatures({
    required this.centroid,
    required this.flatness,
    required this.rolloff,
  });
}

/// VAD ê²°ì • (ë‚´ë¶€ìš©)
class VADDecision {
  final bool isVoiced;
  final double confidence;
  final double energy;
  final double zcr;
  
  const VADDecision({
    required this.isVoiced,
    required this.confidence,
    required this.energy,
    required this.zcr,
  });
}

/// VAD ê²°ê³¼
class VADResult {
  final bool isVoiced;
  final double confidence;
  final double energy;
  final double zcr;
  final int hangoverRemaining;
  final int consecutiveSilence;
  final int consecutiveVoice;
  
  const VADResult({
    required this.isVoiced,
    required this.confidence,
    required this.energy,
    required this.zcr,
    required this.hangoverRemaining,
    required this.consecutiveSilence,
    required this.consecutiveVoice,
  });
  
  /// ì²˜ë¦¬ ìŠ¤í‚µ ì—¬ë¶€ ê²°ì •
  bool get shouldSkipProcessing => !isVoiced && consecutiveSilence > 3;
  
  /// ìŒì„± ì‹œì‘ ê°ì§€
  bool get isVoiceOnset => isVoiced && consecutiveVoice == 1;
  
  /// ìŒì„± ì¢…ë£Œ ê°ì§€
  bool get isVoiceOffset => !isVoiced && consecutiveSilence == 1;
}

/// VAD í†µê³„
class VADStatistics {
  final int totalFrames;
  final int voicedFrames;
  final int processedFrames;
  final double computationSaved;
  final double voiceActivityRatio;
  final double noiseFloor;
  final double adaptiveThreshold;
  
  const VADStatistics({
    required this.totalFrames,
    required this.voicedFrames,
    required this.processedFrames,
    required this.computationSaved,
    required this.voiceActivityRatio,
    required this.noiseFloor,
    required this.adaptiveThreshold,
  });
  
  @override
  String toString() {
    return '''
VAD Statistics:
  Total Frames: $totalFrames
  Voiced Frames: $voicedFrames (${(voiceActivityRatio * 100).toStringAsFixed(1)}%)
  Processed Frames: $processedFrames
  Computation Saved: ${(computationSaved * 100).toStringAsFixed(1)}%
  Noise Floor: ${noiseFloor.toStringAsFixed(6)}
  Adaptive Threshold: ${adaptiveThreshold.toStringAsFixed(6)}
''';
  }
}