import 'dart:async';
import 'dart:typed_data';
import 'dart:math' as math;
import 'dart:convert';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import '../models/analysis_result.dart';

/// CREPE + SPICE ë“€ì–¼ ì—”ì§„ ì„œë¹„ìŠ¤
class DualEngineService {
  static const String _crepeUrl = 'http://localhost:5002';
  static const String _spiceUrl = 'http://localhost:5003';
  
  late final Dio _crepeClient;
  late final Dio _spiceClient;
  
  // ì‹±ê¸€í†¤
  static final DualEngineService _instance = DualEngineService._internal();
  factory DualEngineService() => _instance;
  
  DualEngineService._internal() {
    _crepeClient = Dio(BaseOptions(
      baseUrl: _crepeUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
    ));
    
    _spiceClient = Dio(BaseOptions(
      baseUrl: _spiceUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
    ));
  }
  
  /// ì„œë²„ ìƒíƒœ í™•ì¸
  Future<EngineStatus> checkStatus() async {
    final crepeHealthy = await _checkServerHealth(_crepeClient);
    final spiceHealthy = await _checkServerHealth(_spiceClient);
    
    return EngineStatus(
      crepeHealthy: crepeHealthy,
      spiceHealthy: spiceHealthy,
    );
  }
  
  Future<bool> _checkServerHealth(Dio client) async {
    try {
      final response = await client.get('/health');
      return response.statusCode == 200 && 
             response.data['status'] == 'healthy';
    } catch (e) {
      debugPrint('Server health check failed: $e');
      return false;
    }
  }
  
  /// CREPE ë‹¨ì¼ ë¶„ì„
  Future<CrepeResult?> analyzeWithCrepe(Float32List audioData) async {
    try {
      // Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”©
      final audioBase64 = _encodeAudioToBase64(audioData);
      
      final response = await _crepeClient.post('/analyze', data: {
        'audio_base64': audioBase64,
        'sample_rate': 48000,
        'encoding': 'base64_float32'
      });
      
      if (response.statusCode == 200 && _isValidJsonResponse(response.data)) {
        if (response.data['success'] == true) {
          return CrepeResult.fromJson(response.data['data']);
        }
      }
      return null;
    } catch (e) {
      debugPrint('CREPE analysis failed: $e');
      return null;
    }
  }
  
  /// SPICE ë‹¨ì¼ ë¶„ì„
  Future<SpiceResult?> analyzeWithSpice(Float32List audioData) async {
    try {
      // Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”©
      final audioBase64 = _encodeAudioToBase64(audioData);
      
      final response = await _spiceClient.post('/analyze', data: {
        'audio_base64': audioBase64,
        'sample_rate': 48000,
        'encoding': 'base64_float32'
      });
      
      if (response.statusCode == 200 && _isValidJsonResponse(response.data)) {
        if (response.data['success'] == true) {
          return SpiceResult.fromJson(response.data['data']);
        }
      }
      return null;
    } catch (e) {
      debugPrint('SPICE analysis failed: $e');
      return null;
    }
  }
  
  /// ì‹œê°„ë³„ í”¼ì¹˜ ë¶„ì„ (ì²­í¬ ë‹¨ìœ„)
  Future<List<DualResult>> analyzeTimeBasedPitch(Float32List audioData, {
    int windowSize = 2048,
    int hopSize = 512,
    double sampleRate = 48000.0,
  }) async {
    final results = <DualResult>[];
    
    if (audioData.length < windowSize) {
      return results;
    }
    
    final numWindows = (audioData.length - windowSize) ~/ hopSize + 1;
    print('ğŸµ [DualEngine] ì‹œê°„ë³„ ë¶„ì„ ì‹œì‘: $numWindowsê°œ ìœˆë„ìš°');
    
    for (int i = 0; i < numWindows; i++) {
      final startIdx = i * hopSize;
      final endIdx = math.min(startIdx + windowSize, audioData.length);
      
      if (endIdx - startIdx < windowSize) break;
      
      final chunk = Float32List.fromList(
        audioData.sublist(startIdx, endIdx)
      );
      
      final timeSeconds = startIdx / sampleRate;
      
      try {
        final result = await analyzeDual(chunk);
        if (result != null) {
          // ì‹œê°„ ì •ë³´ ì¶”ê°€
          final timedResult = DualResult(
            frequency: result.frequency,
            confidence: result.confidence,
            timestamp: result.timestamp,
            crepeResult: result.crepeResult,
            spiceResult: result.spiceResult,
            recommendedEngine: result.recommendedEngine,
            analysisQuality: result.analysisQuality,
            timeSeconds: timeSeconds, // ì‹œê°„ ì •ë³´ ì¶”ê°€
          );
          results.add(timedResult);
        }
      } catch (e) {
        print('âš ï¸ [DualEngine] ì²­í¬ $i ë¶„ì„ ì‹¤íŒ¨: $e');
      }
    }
    
    print('âœ… [DualEngine] ì‹œê°„ë³„ ë¶„ì„ ì™„ë£Œ: ${results.length}ê°œ ê²°ê³¼');
    return results;
  }

  /// ë“€ì–¼ ì—”ì§„ ë¶„ì„ (ìë™ ì„ íƒ)
  Future<DualResult?> analyzeDual(Float32List audioData) async {
    // ì˜¤ë””ì˜¤ ë³µì¡ë„ íŒë‹¨
    final isComplex = _isComplexAudio(audioData);
    
    // ë³‘ë ¬ ì‹¤í–‰
    final futures = <Future>[];
    futures.add(analyzeWithCrepe(audioData));
    
    if (isComplex) {
      futures.add(analyzeWithSpice(audioData));
    }
    
    final results = await Future.wait(futures, eagerError: false);
    
    final crepeResult = results[0] as CrepeResult?;
    final spiceResult = results.length > 1 ? results[1] as SpiceResult? : null;
    
    return _fuseResults(crepeResult, spiceResult);
  }
  
  /// ì˜¤ë””ì˜¤ ë³µì¡ë„ íŒë‹¨
  bool _isComplexAudio(Float32List audioData) {
    if (audioData.length < 100) return false;
    
    // ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: RMSì™€ Zero-crossing rate
    final rms = _calculateRMS(audioData);
    final zcr = _calculateZCR(audioData);
    
    return rms > 0.05 && zcr > 0.1;
  }
  
  double _calculateRMS(Float32List data) {
    if (data.isEmpty) return 0.0;
    
    double sum = 0.0;
    for (final sample in data) {
      sum += sample * sample;
    }
    return math.sqrt(sum / data.length);
  }
  
  double _calculateZCR(Float32List data) {
    if (data.length < 2) return 0.0;
    
    int crossings = 0;
    for (int i = 1; i < data.length; i++) {
      if ((data[i-1] >= 0) != (data[i] >= 0)) {
        crossings++;
      }
    }
    return crossings / data.length;
  }
  
  /// Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”©
  String _encodeAudioToBase64(Float32List audioData) {
    try {
      // Float32ë¥¼ ë°”ì´íŠ¸ ë°°ì—´ë¡œ ë³€í™˜
      final byteData = ByteData(audioData.length * 4);
      for (int i = 0; i < audioData.length; i++) {
        byteData.setFloat32(i * 4, audioData[i], Endian.little);
      }
      
      // Base64ë¡œ ì¸ì½”ë”©
      final bytes = byteData.buffer.asUint8List();
      return base64Encode(bytes);
    } catch (e) {
      debugPrint('Audio encoding failed: $e');
      rethrow;
    }
  }
  
  /// JSON ì‘ë‹µ ì•ˆì „ì„± ê²€ì¦
  bool _isValidJsonResponse(Map<String, dynamic> data) {
    try {
      // í•„ìˆ˜ í•„ë“œ í™•ì¸
      if (!data.containsKey('success') || !data.containsKey('data')) {
        return false;
      }
      
      // ë°ì´í„° íƒ€ì… ê²€ì¦
      final success = data['success'];
      if (success is! bool) return false;
      
      // ì„±ê³µ ì‘ë‹µì¸ ê²½ìš° ë°ì´í„° í•„ë“œ ê²€ì¦
      if (success && data['data'] == null) {
        return false;
      }
      
      return true;
    } catch (e) {
      debugPrint('JSON validation failed: $e');
      return false;
    }
  }
  
  /// ê²°ê³¼ ìœµí•©
  DualResult? _fuseResults(CrepeResult? crepe, SpiceResult? spice) {
    if (crepe == null && spice == null) return null;
    
    // ì£¼ìš” í”¼ì¹˜ ì„ íƒ (CREPE ìš°ì„ )
    final mainFreq = crepe?.frequency ?? spice?.frequency ?? 0.0;
    final mainConf = crepe?.confidence ?? spice?.confidence ?? 0.0;
    
    // ì¶”ì²œ ì—”ì§„ ê²°ì •
    String recommended = 'CREPE';
    if (spice != null && spice.isChord) {
      recommended = 'SPICE';
    }
    
    // ë¶„ì„ í’ˆì§ˆ ê³„ì‚°
    double quality = 0.0;
    if (crepe != null) quality += crepe.confidence * 0.7;
    if (spice != null) quality += spice.confidence * 0.3;
    
    return DualResult(
      frequency: mainFreq,
      confidence: mainConf,
      timestamp: DateTime.now(),
      crepeResult: crepe,
      spiceResult: spice,
      recommendedEngine: recommended,
      analysisQuality: quality,
    );
  }
}

/// ì—”ì§„ ìƒíƒœ
class EngineStatus {
  final bool crepeHealthy;
  final bool spiceHealthy;
  
  EngineStatus({
    required this.crepeHealthy,
    required this.spiceHealthy,
  });
  
  bool get anyHealthy => crepeHealthy || spiceHealthy;
  bool get bothHealthy => crepeHealthy && spiceHealthy;
  
  String get statusText {
    if (bothHealthy) return "ë‘ ì—”ì§„ ëª¨ë‘ ì •ìƒ";
    if (crepeHealthy) return "CREPEë§Œ ì •ìƒ";
    if (spiceHealthy) return "SPICEë§Œ ì •ìƒ";
    return "ë‘ ì—”ì§„ ëª¨ë‘ ì˜¤í”„ë¼ì¸";
  }
}

/// ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼
class RealtimeAnalysisStream {
  final DualEngineService _service = DualEngineService();
  final StreamController<DualResult> _controller = 
      StreamController<DualResult>.broadcast();
  
  Stream<DualResult> get stream => _controller.stream;
  
  Timer? _timer;
  final List<Float32List> _buffer = [];
  static const int _maxBufferSize = 3;
  
  void startStream() {
    _timer = Timer.periodic(const Duration(milliseconds: 500), (_) {
      _processBuffer();
    });
  }
  
  void addAudioChunk(Float32List chunk) {
    _buffer.add(chunk);
    if (_buffer.length > _maxBufferSize) {
      _buffer.removeAt(0);
    }
  }
  
  void _processBuffer() async {
    if (_buffer.isEmpty) return;
    
    // ë²„í¼ ê²°í•©
    final totalLength = _buffer.fold<int>(0, (sum, chunk) => sum + chunk.length);
    final combined = Float32List(totalLength);
    
    int offset = 0;
    for (final chunk in _buffer) {
      combined.setRange(offset, offset + chunk.length, chunk);
      offset += chunk.length;
    }
    
    // ë¶„ì„ ì‹¤í–‰
    final result = await _service.analyzeDual(combined);
    if (result != null) {
      _controller.add(result);
    }
  }
  
  void stopStream() {
    _timer?.cancel();
    _timer = null;
    _buffer.clear();
  }
  
  void dispose() {
    stopStream();
    _controller.close();
  }
}