import 'dart:async';
import 'dart:typed_data';
import 'dart:math' as math;
import 'dart:convert';
import 'dart:io';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import '../models/analysis_result.dart';
import 'single_pitch_tracker.dart';

/// ì´ˆê³ ì† CREPE + SPICE ë“€ì–¼ ì—”ì§„ ì„œë¹„ìŠ¤ (HTTP/2 + ë°°ì¹˜ ì²˜ë¦¬)
class DualEngineService {
  static const String _crepeUrl = 'http://localhost:5002';
  static const String _spiceUrl = 'http://localhost:5003';
  
  late final Dio _crepeClient;
  late final Dio _spiceClient;
  
  // HTTP/2 ì§€ì›ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸
  late final HttpClient _http2CrepeClient;
  late final HttpClient _http2SpiceClient;
  SinglePitchTracker? _pitchTracker;
  
  // í”¼ì¹˜ ë¶„ì„ ìºì‹œ (ìµœê·¼ 10ê°œ ê²°ê³¼ ì €ì¥)
  final Map<String, DualResult> _pitchCache = {};
  static const int _maxCacheSize = 10;
  
  // ì‹±ê¸€í†¤
  static final DualEngineService _instance = DualEngineService._internal();
  factory DualEngineService() => _instance;
  
  // ë°°ì¹˜ ì²˜ë¦¬ìš© í
  final List<BatchRequest> _crepeQueue = [];
  final List<BatchRequest> _spiceQueue = [];
  Timer? _batchTimer;
  
  // ì—°ê²° í’€ë§
  final Map<String, String> _connectionPool = {};

  DualEngineService._internal() {
    _initializeClients();
    _startBatchProcessor();
  }
  
  void _initializeClients() {
    // ê¸°ì¡´ Dio í´ë¼ì´ì–¸íŠ¸ (í´ë°±ìš©)
    _crepeClient = Dio(BaseOptions(
      baseUrl: _crepeUrl,
      connectTimeout: const Duration(seconds: 5),  // ë” ë¹ ë¥¸ íƒ€ì„ì•„ì›ƒ
      receiveTimeout: const Duration(seconds: 8),
      headers: {
        'Connection': 'keep-alive',
        'Keep-Alive': 'timeout=30, max=100',
      },
    ));
    
    _spiceClient = Dio(BaseOptions(
      baseUrl: _spiceUrl,
      connectTimeout: const Duration(seconds: 5),
      receiveTimeout: const Duration(seconds: 8),
      headers: {
        'Connection': 'keep-alive',
        'Keep-Alive': 'timeout=30, max=100',
      },
    ));
    
    // HTTP/2 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    _http2CrepeClient = HttpClient()
      ..connectionTimeout = const Duration(seconds: 3)
      ..idleTimeout = const Duration(seconds: 30)
      ..maxConnectionsPerHost = 10;
      
    _http2SpiceClient = HttpClient()
      ..connectionTimeout = const Duration(seconds: 3) 
      ..idleTimeout = const Duration(seconds: 30)
      ..maxConnectionsPerHost = 10;
  }
  
  /// ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
  void _startBatchProcessor() {
    _batchTimer = Timer.periodic(const Duration(milliseconds: 50), (timer) {
      _processBatches();
    });
  }
  
  /// SinglePitchTrackerë¥¼ ì§€ì—° ì´ˆê¸°í™”
  SinglePitchTracker get pitchTracker {
    _pitchTracker ??= SinglePitchTracker();
    return _pitchTracker!;
  }
  
  /// ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
  void _processBatches() async {
    if (_crepeQueue.isNotEmpty) {
      await _processCrepeBatch();
    }
    if (_spiceQueue.isNotEmpty) {
      await _processSpiceBatch();
    }
  }
  
  /// CREPE ë°°ì¹˜ ì²˜ë¦¬
  Future<void> _processCrepeBatch() async {
    if (_crepeQueue.isEmpty) return;
    
    final batch = List<BatchRequest>.from(_crepeQueue);
    _crepeQueue.clear();
    
    try {
      // HTTP/2 ë‹¤ì¤‘ ìš”ì²­ (ë³‘ë ¬ ì²˜ë¦¬)
      final futures = batch.map((request) => 
        _sendHttp2Request(_http2CrepeClient, _crepeUrl, request));
      
      final results = await Future.wait(futures);
      
      // ê²°ê³¼ ë¶„ë°°
      for (int i = 0; i < results.length; i++) {
        batch[i].completer.complete(results[i]);
      }
    } catch (e) {
      // ì‹¤íŒ¨ì‹œ í´ë°±
      for (final request in batch) {
        request.completer.completeError(e);
      }
    }
  }
  
  /// SPICE ë°°ì¹˜ ì²˜ë¦¬
  Future<void> _processSpiceBatch() async {
    if (_spiceQueue.isEmpty) return;
    
    final batch = List<BatchRequest>.from(_spiceQueue);
    _spiceQueue.clear();
    
    try {
      final futures = batch.map((request) => 
        _sendHttp2Request(_http2SpiceClient, _spiceUrl, request));
      
      final results = await Future.wait(futures);
      
      for (int i = 0; i < results.length; i++) {
        batch[i].completer.complete(results[i]);
      }
    } catch (e) {
      for (final request in batch) {
        request.completer.completeError(e);
      }
    }
  }
  
  /// HTTP/2 ìš”ì²­ ì „ì†¡
  Future<DualResult> _sendHttp2Request(HttpClient client, String baseUrl, BatchRequest request) async {
    final uri = Uri.parse('$baseUrl/analyze');
    
    final httpRequest = await client.postUrl(uri);
    httpRequest.headers.set('Content-Type', 'application/json');
    httpRequest.headers.set('Accept-Encoding', 'gzip, deflate, br'); // ì••ì¶• ì§€ì›
    
    final requestBody = json.encode({
      'audio_data': request.audioData.toList(),
      'sample_rate': request.sampleRate,
      'batch_id': request.batchId,
    });
    
    httpRequest.write(requestBody);
    
    final httpResponse = await httpRequest.close();
    final responseBody = await httpResponse.transform(utf8.decoder).join();
    
    final Map<String, dynamic> data = json.decode(responseBody);
    
    return DualResult(
      frequency: data['frequency']?.toDouble() ?? 0.0,
      confidence: data['confidence']?.toDouble() ?? 0.0,
      timestamp: DateTime.now(),
      noteName: data['note'] ?? '',
      cents: data['cents']?.toDouble() ?? 0.0,
      recommendedEngine: baseUrl.contains('crepe') ? 'CREPE' : 'SPICE',
    );
  }
  
  /// ì´ˆê³ ì† ë‹¨ì¼ í”¼ì¹˜ ë¶„ì„ (ë°°ì¹˜ í ì‚¬ìš©)
  Future<DualResult?> analyzeSinglePitchFast(Float32List audioData, {double sampleRate = 48000}) async {
    // ìºì‹œ í™•ì¸
    final cacheKey = _generateCacheKey(audioData);
    if (_pitchCache.containsKey(cacheKey)) {
      return _pitchCache[cacheKey];
    }
    
    // ë°°ì¹˜ ìš”ì²­ ìƒì„±
    final request = BatchRequest(
      audioData: audioData,
      sampleRate: sampleRate,
      batchId: DateTime.now().millisecondsSinceEpoch,
      completer: Completer<DualResult>(),
    );
    
    // íì— ì¶”ê°€ (CREPE ìš°ì„ )
    _crepeQueue.add(request);
    
    try {
      final result = await request.completer.future.timeout(
        const Duration(seconds: 5),
        onTimeout: () => DualResult(
          frequency: 0, 
          confidence: 0, 
          timestamp: DateTime.now(),
          noteName: '', 
          cents: 0, 
          recommendedEngine: 'TIMEOUT'
        ),
      );
      
      // ê²°ê³¼ ìºì‹±
      _cacheResult(cacheKey, result);
      return result;
      
    } catch (e) {
      debugPrint('âŒ ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: $e');
      // ë¡œì»¬ ë¶„ì„ìœ¼ë¡œ í´ë°±
      return await _fallbackToLocalAnalysis(audioData, sampleRate);
    }
  }
  
  /// ë¡œì»¬ ë¶„ì„ í´ë°±
  Future<DualResult?> _fallbackToLocalAnalysis(Float32List audioData, double sampleRate) async {
    try {
      final result = await pitchTracker.trackSinglePitch(audioData, sampleRate: sampleRate);
      
      return DualResult(
        frequency: result.frequency,
        confidence: result.confidence,
        timestamp: DateTime.now(),
        noteName: result.noteName,
        cents: result.cents,
        recommendedEngine: 'LOCAL',
      );
    } catch (e) {
      debugPrint('âŒ ë¡œì»¬ ë¶„ì„ë„ ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// ì‹¤ì‹œê°„ ë‹¨ì¼ í”¼ì¹˜ ë¶„ì„ (ê¸°ì¡´ í˜¸í™˜ì„±)
  Future<DualResult?> analyzeSinglePitch(Float32List audioData) async {
    try {
      // ìƒˆë¡œìš´ ê³ ì† ë°°ì¹˜ ë°©ì‹ ì‚¬ìš©
      final cacheKey = _generateCacheKey(audioData);
      
      // ìºì‹œ í™•ì¸
      if (_pitchCache.containsKey(cacheKey)) {
        print('ğŸ¯ [Cache Hit] ìºì‹œëœ í”¼ì¹˜ ê²°ê³¼ ì‚¬ìš©');
        return _pitchCache[cacheKey];
      }
      
      // ì‹¤ì‹œê°„ ë¶„ì„ìš© ì ì ˆí•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
      final crepeClient = Dio(BaseOptions(
        baseUrl: _crepeUrl,
        connectTimeout: const Duration(seconds: 2),  // ì—°ê²° íƒ€ì„ì•„ì›ƒ 2ì´ˆ
        receiveTimeout: const Duration(seconds: 3),  // ìˆ˜ì‹  íƒ€ì„ì•„ì›ƒ 3ì´ˆ
      ));
      
      // Base64 ì¸ì½”ë”©
      final base64Audio = base64Encode(audioData.buffer.asUint8List());
      
      final response = await crepeClient.post(
        '/analyze',
        data: {
          'audio_base64': base64Audio,
          'sample_rate': 44100,  // MP3ëŠ” ë³´í†µ 44.1kHz
        },
      );
      
      if (response.statusCode == 200) {
        final data = response.data;
        
        // CREPEëŠ” ë°°ì—´ë¡œ ë°˜í™˜í•˜ë¯€ë¡œ í‰ê· ê°’ ë˜ëŠ” ìµœë¹ˆê°’ ì‚¬ìš©
        double frequency = 0;
        double confidence = 0;
        String note = '';
        
        if (data['frequencies'] is List && (data['frequencies'] as List).isNotEmpty) {
          // ë°°ì—´ì˜ í‰ê· ê°’ ê³„ì‚°
          final freqs = (data['frequencies'] as List).map((e) => (e as num).toDouble()).toList();
          final confs = (data['confidence'] as List).map((e) => (e as num).toDouble()).toList();
          
          // ì‹ ë¢°ë„ê°€ ë†’ì€ ê°’ë“¤ì˜ í‰ê· 
          double totalFreq = 0;
          double totalConf = 0;
          int count = 0;
          
          for (int i = 0; i < freqs.length && i < confs.length; i++) {
            if (confs[i] > 0.5) {  // ì‹ ë¢°ë„ 50% ì´ìƒë§Œ
              totalFreq += freqs[i];
              totalConf += confs[i];
              count++;
            }
          }
          
          if (count > 0) {
            frequency = totalFreq / count;
            confidence = totalConf / count;
          }
          
          if (data['notes'] is List && (data['notes'] as List).isNotEmpty) {
            note = (data['notes'] as List).first.toString();
          }
        } else if (data['frequency'] != null) {
          // ë‹¨ì¼ ê°’ ì²˜ë¦¬ (ì´ì „ í˜•ì‹ í˜¸í™˜)
          frequency = (data['frequency'] as num).toDouble();
          confidence = (data['confidence'] ?? 0.8).toDouble();
          note = data['note'] ?? '';
        }
        
        final result = DualResult(
          frequency: frequency,
          confidence: confidence,
          timestamp: DateTime.now(),
          noteName: note,
          recommendedEngine: 'CREPE',
        );
        
        // ìºì‹œì— ì €ì¥
        _addToCache(cacheKey, result);
        
        return result;
      }
    } catch (e) {
      // íƒ€ì„ì•„ì›ƒì´ë‚˜ ì—ëŸ¬ ì‹œ ë¹ ë¥¸ í´ë°±
      print('Quick CREPE analysis failed: $e');
    }
    return null;
  }
  
  /// ìºì‹œ í‚¤ ìƒì„± (ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ê°„ë‹¨í•œ í•´ì‹œ)
  String _generateCacheKey(Float32List audioData) {
    if (audioData.isEmpty) return '';
    
    // ì²˜ìŒê³¼ ë, ì¤‘ê°„ ê°’ë“¤ë¡œ ê°„ë‹¨í•œ í‚¤ ìƒì„±
    final keyValues = <double>[];
    keyValues.add(audioData.first);
    keyValues.add(audioData.last);
    keyValues.add(audioData[audioData.length ~/ 2]);
    keyValues.add(audioData.length.toDouble());
    
    // RMS ê°’ë„ ì¶”ê°€ (ì „ì²´ì ì¸ ë³¼ë¥¨ íŠ¹ì„±)
    double sum = 0;
    for (int i = 0; i < math.min(100, audioData.length); i++) {
      sum += audioData[i] * audioData[i];
    }
    keyValues.add(math.sqrt(sum / math.min(100, audioData.length)));
    
    return keyValues.map((v) => v.toStringAsFixed(3)).join('_');
  }
  
  /// ìºì‹œì— ê²°ê³¼ ì¶”ê°€
  void _addToCache(String key, DualResult result) {
    if (key.isEmpty) return;
    
    // ìºì‹œ í¬ê¸° ì œí•œ
    if (_pitchCache.length >= _maxCacheSize) {
      // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
      _pitchCache.remove(_pitchCache.keys.first);
    }
    
    _pitchCache[key] = result;
    print('ğŸ’¾ [Cache] í”¼ì¹˜ ê²°ê³¼ ìºì‹œì— ì €ì¥ (ìºì‹œ í¬ê¸°: ${_pitchCache.length})');
  }
  
  /// ì„œë²„ ìƒíƒœ í™•ì¸
  // Public initialize method for external access
  Future<void> initialize() async {
    await checkStatus();
  }

  // Analyze pitch method for compatibility
  Future<Map<String, dynamic>> analyzePitch(Float32List audioData) async {
    final result = await analyzeSinglePitch(audioData);
    if (result == null) {
      return {
        'frequency': 0.0,
        'confidence': 0.0,
        'note': '',
        'error': 'No pitch detected'
      };
    }
    return {
      'frequency': result.frequency,
      'confidence': result.confidence,
      'note': result.noteName ?? '',
      'timestamp': DateTime.now().toIso8601String()
    };
  }

  // Getter for pitch stream
  Stream<Map<String, dynamic>> get pitchStream {
    // Create a realtime analysis stream
    final analysisStream = RealtimeAnalysisStream._internal(this);
    analysisStream.startStream();
    
    // Convert DualResult stream to Map stream
    return analysisStream.stream.map((result) => {
      'frequency': result.frequency,
      'confidence': result.confidence,
      'note': result.noteName ?? '',
      'timestamp': DateTime.now().toIso8601String()
    });
  }

  Future<EngineStatus> checkStatus() async {
    final crepeHealthy = await _checkServerHealth(_crepeClient);
    final spiceHealthy = await _checkServerHealth(_spiceClient);
    
    return EngineStatus(
      crepeHealthy: crepeHealthy,
      spiceHealthy: spiceHealthy,
    );
  }
  
  Future<bool> _checkServerHealth(Dio client) async {
    try {
      final response = await client.get('/health');
      return response.statusCode == 200 && 
             response.data['status'] == 'healthy';
    } catch (e) {
      debugPrint('Server health check failed: $e');
      return false;
    }
  }
  
  /// CREPE ë‹¨ì¼ ë¶„ì„
  Future<CrepeResult?> analyzeWithCrepe(Float32List audioData) async {
    try {
      print('ğŸµ [CREPE] ë¶„ì„ ì‹œì‘ - ë°ì´í„° í¬ê¸°: ${audioData.length}');
      
      // ì˜¤ë””ì˜¤ ë°ì´í„° ê²€ì¦ (ë””ë²„ê¹…)
      final audioMax = audioData.reduce((a, b) => a.abs() > b.abs() ? a : b);
      final audioRMS = math.sqrt(audioData.map((x) => x * x).reduce((a, b) => a + b) / audioData.length);
      print('ğŸ“Š [CREPE] ì…ë ¥ ì˜¤ë””ì˜¤: max=${audioMax.toStringAsFixed(4)}, RMS=${audioRMS.toStringAsFixed(4)}');
      
      // Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”© (ì „ì²˜ë¦¬ í¬í•¨)
      final audioBase64 = _encodeAudioToBase64(audioData);
      print('ğŸµ [CREPE] Base64 ì¸ì½”ë”© ì™„ë£Œ: ${audioBase64.length} ë°”ì´íŠ¸');
      
      final response = await _crepeClient.post('/analyze', data: {
        'audio_base64': audioBase64,
        'sample_rate': 48000,
        'encoding': 'base64_float32'
      });
      
      print('ğŸµ [CREPE] ì„œë²„ ì‘ë‹µ: ${response.statusCode}');
      
      if (response.statusCode == 200 && response.data != null) {
        // CREPE ì„œë²„ëŠ” ì§ì ‘ ë°°ì—´ì„ ë°˜í™˜
        if (response.data['frequencies'] != null && response.data['confidence'] != null) {
          final frequencies = (response.data['frequencies'] as List).map((e) => (e as num).toDouble()).toList();
          final confidences = (response.data['confidence'] as List).map((e) => (e as num).toDouble()).toList();
          
          if (frequencies.isNotEmpty && confidences.isNotEmpty) {
            // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì£¼íŒŒìˆ˜ ì„ íƒ
            int bestIdx = 0;
            double maxConf = confidences[0];
            for (int i = 1; i < confidences.length; i++) {
              if (confidences[i] > maxConf) {
                maxConf = confidences[i];
                bestIdx = i;
              }
            }
            
            final result = CrepeResult(
              frequency: frequencies[bestIdx],
              confidence: maxConf,
              timestamp: DateTime.now(),
              stability: 0.8,  // ê¸°ë³¸ê°’
              voicedRatio: maxConf,  // ì‹ ë¢°ë„ë¥¼ voiced ratioë¡œ ì‚¬ìš©
              processingTimeMs: 100.0,  // ê¸°ë³¸ê°’
            );
            print('âœ… [CREPE] ë¶„ì„ ì„±ê³µ: ${result.frequency.toStringAsFixed(1)}Hz, ì‹ ë¢°ë„: ${result.confidence}');
            return result;
          }
        }
      }
      print('âš ï¸ [CREPE] ë¶„ì„ ì‹¤íŒ¨ - ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜');
      return null;
    } catch (e) {
      if (e.toString().contains('silence or noise only')) {
        print('ğŸ”‡ [CREPE] ì¹¨ë¬µ/ë…¸ì´ì¦ˆë§Œ ê°ì§€ë¨ - ë¶„ì„ ìƒëµ');
        return null;
      }
      print('âŒ [CREPE] ë¶„ì„ ì˜¤ë¥˜: $e');
      return null;
    }
  }
  
  /// SPICE ë‹¨ì¼ ë¶„ì„
  Future<SpiceResult?> analyzeWithSpice(Float32List audioData) async {
    try {
      print('ğŸµ [SPICE] ë¶„ì„ ì‹œì‘ - ë°ì´í„° í¬ê¸°: ${audioData.length}');
      
      // Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”© (ì „ì²˜ë¦¬ í¬í•¨)
      final audioBase64 = _encodeAudioToBase64(audioData);
      print('ğŸµ [SPICE] Base64 ì¸ì½”ë”© ì™„ë£Œ: ${audioBase64.length} ë°”ì´íŠ¸');
      
      final response = await _spiceClient.post('/analyze', data: {
        'audio_base64': audioBase64,
        'sample_rate': 48000,
        'encoding': 'base64_float32'
      });
      
      print('ğŸµ [SPICE] ì„œë²„ ì‘ë‹µ: ${response.statusCode}');
      
      if (response.statusCode == 200 && response.data != null) {
        // SPICE ì„œë²„ëŠ” successì™€ data êµ¬ì¡°ë¡œ ì‘ë‹µ
        if (response.data['success'] == true && response.data['data'] != null) {
          final data = response.data['data'];
          if (data['frequencies'] != null && data['confidence'] != null) {
            final frequencies = (data['frequencies'] as List).map((e) => (e as num).toDouble()).toList();
            final confidences = (data['confidence'] as List).map((e) => (e as num).toDouble()).toList();
            
            if (frequencies.isNotEmpty && confidences.isNotEmpty) {
              // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì£¼íŒŒìˆ˜ ì„ íƒ
              int bestIdx = 0;
              double maxConf = confidences[0];
              for (int i = 1; i < confidences.length; i++) {
                if (confidences[i] > maxConf) {
                  maxConf = confidences[i];
                  bestIdx = i;
                }
              }
              
              // SPICE ì£¼íŒŒìˆ˜ ë³´ì • ì œê±°: ì›ë³¸ ì£¼íŒŒìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
              final rawFreq = frequencies[bestIdx];
              final correctedFreq = rawFreq; // ë³´ì • ì—†ì´ ì›ë³¸ ì£¼íŒŒìˆ˜ ì‚¬ìš©
              
              final result = SpiceResult(
                frequency: correctedFreq,
                confidence: maxConf,
                timestamp: DateTime.now(),
                multiplePitches: [MultiplePitch(
                  frequency: correctedFreq,
                  strength: maxConf,
                  confidence: maxConf,
                )],
                detectedPitchCount: 1,
                processingTimeMs: 100.0,  // ê¸°ë³¸ê°’
              );
              print('âœ… [SPICE] ë¶„ì„ ì„±ê³µ: ${correctedFreq.toStringAsFixed(1)}Hz (ì›ë³¸: ${frequencies[bestIdx].toStringAsFixed(1)}Hz), ì‹ ë¢°ë„: ${maxConf.toStringAsFixed(3)}');
              return result;
            }
          }
        }
      }
      print('âš ï¸ [SPICE] ë¶„ì„ ì‹¤íŒ¨ - ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜');
      return null;
    } catch (e) {
      if (e.toString().contains('silence or noise only')) {
        print('ğŸ”‡ [SPICE] ì¹¨ë¬µ/ë…¸ì´ì¦ˆë§Œ ê°ì§€ë¨ - ë¶„ì„ ìƒëµ');
        return null;
      }
      print('âŒ [SPICE] ë¶„ì„ ì˜¤ë¥˜: $e');
      return null;
    }
  }
  
  /// ê³ ì •ë°€ ë‹¨ì¼ ìŒì • ë¶„ì„ (SinglePitchTracker ì‚¬ìš©)
  /// ë‹¨ì„  CREPE ë¶„ì„ (ë‹¨ì¼ ì²­í¬ìš©)
  Future<double> analyzeSingleWithCREPE(Float32List audioData, {
    double sampleRate = 48000.0,
  }) async {
    try {
      // Base64 ì¸ì½”ë”©
      final audioBytes = audioData.buffer.asUint8List();
      final audioBase64 = base64Encode(audioBytes);
      
      // CREPE ì„œë²„ë¡œ ìš”ì²­
      final response = await _crepeClient.post('/analyze', data: {
        'audio_base64': audioBase64,
        'sample_rate': sampleRate,
      });
      
      if (response.statusCode == 200) {
        final data = response.data;
        final frequencies = List<double>.from(data['frequencies'] ?? []);
        final confidences = List<double>.from(data['confidence'] ?? []);
        
        if (frequencies.isNotEmpty && confidences.isNotEmpty) {
          // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì£¼íŒŒìˆ˜ ë°˜í™˜
          int bestIdx = 0;
          double maxConf = confidences[0];
          for (int i = 1; i < confidences.length; i++) {
            if (confidences[i] > maxConf) {
              maxConf = confidences[i];
              bestIdx = i;
            }
          }
          return frequencies[bestIdx];
        }
      }
      return 0;
    } catch (e) {
      print('âŒ [CREPE] ì„œë²„ ìš”ì²­ ì‹¤íŒ¨: $e');
      return 0;
    }
  }
  
  /// ë‹¨ì„  ë©œë¡œë””ì— ìµœì í™”ëœ ì •í™•í•œ ìŒì • ë¶„ì„
  Future<List<DualResult>> analyzeSinglePitchAccurate(Float32List audioData, {
    int windowSize = 24000,   // 0.5ì´ˆ ë¶„ëŸ‰ (SinglePitchTracker ìµœì )
    int hopSize = 6000,       // 0.125ì´ˆ ê°„ê²© (75% ì˜¤ë²„ë©)
    double sampleRate = 48000.0,
  }) async {
    print('ğŸ¯ [DualEngine] analyzeSinglePitchAccurate í˜¸ì¶œë¨ - ì˜¤ë””ì˜¤ ê¸¸ì´: ${audioData.length} ìƒ˜í”Œ');
    
    if (audioData.length < windowSize) {
      print('âš ï¸ [SinglePitch] ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìŒ: ${audioData.length} < $windowSize');
      return [];
    }
    
    final numWindows = (audioData.length - windowSize) ~/ hopSize + 1;
    print('ğŸ¯ [SinglePitch] ê³ ì •ë°€ ë‹¨ì¼ ìŒì • ë¶„ì„ ì‹œì‘: $numWindowsê°œ ìœˆë„ìš°');
    
    final results = <DualResult>[];
    
    for (int i = 0; i < numWindows; i++) {
      final startIdx = i * hopSize;
      final endIdx = math.min(startIdx + windowSize, audioData.length);
      
      if (endIdx - startIdx < windowSize) break;
      
      final window = audioData.sublist(startIdx, endIdx);
      final timeSeconds = startIdx / sampleRate;
      
      try {
        // SinglePitchTrackerë¥¼ ì‚¬ìš©í•œ ê³ ì •ë°€ ë¶„ì„
        final pitchResult = await pitchTracker.trackSinglePitch(
          Float32List.fromList(window),
          sampleRate: sampleRate,
        );
        
        final dualResult = DualResult(
          frequency: pitchResult.frequency,
          confidence: pitchResult.confidence,
          timestamp: DateTime.now(),
          timeSeconds: timeSeconds,
          // SinglePitchTracker ê²°ê³¼ ì¶”ê°€ ì •ë³´
          noteName: pitchResult.noteName,
          cents: pitchResult.cents,
          isAccurate: pitchResult.isAccurate,
          latencyMs: pitchResult.latencyMs,
        );
        
        results.add(dualResult);
        
        if (i % 10 == 0) {
          print('ğŸ¯ ì²­í¬ $i ë¶„ì„: ${pitchResult.frequency.toStringAsFixed(1)}Hz (${pitchResult.noteName}) ì‹ ë¢°ë„: ${(pitchResult.confidence * 100).toStringAsFixed(0)}%');
        }
        
      } catch (e) {
        print('âŒ [SinglePitch] ì²­í¬ $i ë¶„ì„ ì‹¤íŒ¨: $e');
        
        // ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ê°’ ì¶”ê°€
        results.add(DualResult(
          frequency: 0,
          confidence: 0,
          timestamp: DateTime.now(),
          timeSeconds: timeSeconds,
        ));
      }
      
      // ì§„í–‰ ìƒí™© ë¡œê·¸
      if ((i + 1) % 20 == 0 || i == numWindows - 1) {
        print('ğŸ“Š [SinglePitch] ì§„í–‰: ${i + 1}/$numWindows ì™„ë£Œ');
      }
    }
    
    print('âœ… [SinglePitch] ê³ ì •ë°€ ë‹¨ì¼ ìŒì • ë¶„ì„ ì™„ë£Œ: ${results.length}ê°œ ê²°ê³¼');
    return results;
  }

  /// ì‹œê°„ë³„ í”¼ì¹˜ ë¶„ì„ (ê¸°ì¡´ CREPE+SPICE ë“€ì–¼ ì—”ì§„)
  Future<List<DualResult>> analyzeTimeBasedPitch(Float32List audioData, {
    int windowSize = 48000,  // 1ì´ˆ ë¶„ëŸ‰ (CREPE/SPICE ìµœì )
    int hopSize = 48000,     // 1ì´ˆ ê°„ê²© (0% ì˜¤ë²„ë©) - ê·¹ë‹¨ì ìœ¼ë¡œ í° ê°„ê²©
    double sampleRate = 48000.0,
    double confidenceThreshold = 0.8,  // ì‹ ë¢°ë„ ì„ê³„ê°’ì„ 80%ë¡œ ê°•í™”
    double minimumNoteDuration = 0.8,   // ìµœì†Œ ìŒí‘œ ì§€ì†ì‹œê°„ì„ 0.8ì´ˆë¡œ ê°•í™”
  }) async {
    if (audioData.length < windowSize) {
      print('âš ï¸ [DualEngine] ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìŒ: ${audioData.length} < $windowSize');
      return [];
    }
    
    final numWindows = (audioData.length - windowSize) ~/ hopSize + 1;
    print('ğŸµ [DualEngine] ì‹œê°„ë³„ ë¶„ì„ ì‹œì‘: $numWindowsê°œ ìœˆë„ìš°');
    
    final results = <DualResult>[];
    int successCount = 0;
    int failCount = 0;
    
    // ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë˜ ì„œë²„ í˜¸ì¶œì€ ë³‘ë ¬ë¡œ
    for (int i = 0; i < numWindows; i++) {
      final startIdx = i * hopSize;
      final endIdx = math.min(startIdx + windowSize, audioData.length);
      
      if (endIdx - startIdx < windowSize) break;
      
      final chunk = Float32List.fromList(
        audioData.sublist(startIdx, endIdx)
      );
      
      // ì²­í¬ í†µê³„ ì¶œë ¥ (ë””ë²„ê¹…)
      if (i == 0 || i == numWindows ~/ 2 || i == numWindows - 1) {
        final chunkMax = chunk.reduce((a, b) => a.abs() > b.abs() ? a : b);
        final chunkRMS = math.sqrt(chunk.map((x) => x * x).reduce((a, b) => a + b) / chunk.length);
        print('ğŸ“Š ì²­í¬ $i í†µê³„: max=${chunkMax.toStringAsFixed(4)}, RMS=${chunkRMS.toStringAsFixed(4)}');
      }
      
      final timeSeconds = startIdx / sampleRate;
      
      try {
        // ê° ì²­í¬ì— íƒ€ì„ì•„ì›ƒ ì ìš©
        final result = await analyzeDual(chunk).timeout(
          const Duration(seconds: 8),
          onTimeout: () {
            print('â° ì²­í¬ $i ë¶„ì„ íƒ€ì„ì•„ì›ƒ');
            return null;
          },
        );
        
        if (result != null && result.frequency > 0 && result.confidence >= confidenceThreshold) {
          // ì‹œê°„ ì •ë³´ë¥¼ ì¶”ê°€í•œ ìƒˆ ê²°ê³¼ ìƒì„±
          results.add(DualResult(
            frequency: result.frequency,
            confidence: result.confidence,
            timestamp: result.timestamp,
            crepeResult: result.crepeResult,
            spiceResult: result.spiceResult,
            recommendedEngine: result.recommendedEngine,
            analysisQuality: result.analysisQuality,
            timeSeconds: timeSeconds,
          ));
          
          successCount++;
          if (i % 5 == 0) { // 5ê°œë§ˆë‹¤ ë¡œê·¸
            print('âœ… ì²­í¬ $i ë¶„ì„ ì™„ë£Œ: ${result.frequency.toStringAsFixed(1)}Hz at ${timeSeconds.toStringAsFixed(2)}s (ì‹ ë¢°ë„: ${(result.confidence * 100).toInt()}%)');
          }
        } else {
          failCount++;
          if (result?.confidence != null && result!.confidence < confidenceThreshold) {
            print('âš ï¸ ì²­í¬ $i ì‹ ë¢°ë„ ë‚®ìŒ: ${(result.confidence * 100).toInt()}% < ${(confidenceThreshold * 100).toInt()}%');
          }
        }
      } catch (e) {
        print('âŒ ì²­í¬ $i ë¶„ì„ ì‹¤íŒ¨: $e');
        failCount++;
      }
      
      // ì§„í–‰ ìƒí™© í‘œì‹œ (10ê°œë§ˆë‹¤)
      if ((i + 1) % 10 == 0) {
        print('ğŸ“Š ì§„í–‰: ${i + 1}/$numWindows ì™„ë£Œ (ì„±ê³µ: $successCount, ì‹¤íŒ¨: $failCount)');
      }
    }
    
    final successRate = (successCount / numWindows * 100).toStringAsFixed(1);
    print('ğŸ“Š [DualEngine] ì›ë³¸ ë¶„ì„ ì™„ë£Œ: ${results.length}ê°œ ê²°ê³¼ (ì„±ê³µë¥ : $successRate%)');
    
    // ìŒí‘œ í†µí•©: ë¹„ìŠ·í•œ ì—°ì† í”¼ì¹˜ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
    final consolidatedResults = _consolidateNotes(results, minimumNoteDuration);
    print('âœ… [DualEngine] ìŒí‘œ í†µí•© ì™„ë£Œ: ${consolidatedResults.length}ê°œ ìµœì¢… ê²°ê³¼ (${results.length}ê°œì—ì„œ ê°ì†Œ)');
    
    return consolidatedResults;
  }

  /// ìŒí‘œ í†µí•©: ë¹„ìŠ·í•œ ì—°ì† í”¼ì¹˜ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
  List<DualResult> _consolidateNotes(List<DualResult> results, double minimumDuration) {
    if (results.isEmpty) return results;
    
    final consolidated = <DualResult>[];
    DualResult? currentNote;
    double currentNoteStartTime = 0.0;
    
    for (final result in results) {
      final frequency = result.frequency;
      final time = result.timeSeconds ?? 0.0;
      
      if (currentNote == null) {
        // ì²« ë²ˆì§¸ ìŒí‘œ
        currentNote = result;
        currentNoteStartTime = time;
      } else {
        // í˜„ì¬ ìŒí‘œì™€ ë¹„ìŠ·í•œì§€ í™•ì¸ (Â±5% í—ˆìš©)
        final frequencyDiff = (frequency - currentNote.frequency).abs();
        final frequencyThreshold = currentNote.frequency * 0.05; // 5% í—ˆìš©
        
        if (frequencyDiff <= frequencyThreshold) {
          // ê°™ì€ ìŒí‘œ ê³„ì† - ì‹ ë¢°ë„ê°€ ë” ë†’ìœ¼ë©´ ì—…ë°ì´íŠ¸
          if (result.confidence > currentNote.confidence) {
            currentNote = DualResult(
              frequency: result.frequency,
              confidence: result.confidence,
              timestamp: result.timestamp,
              crepeResult: result.crepeResult,
              spiceResult: result.spiceResult,
              recommendedEngine: result.recommendedEngine,
              analysisQuality: result.analysisQuality,
              timeSeconds: currentNoteStartTime, // ì‹œì‘ ì‹œê°„ ìœ ì§€
            );
          }
        } else {
          // ìƒˆë¡œìš´ ìŒí‘œ - ì´ì „ ìŒí‘œê°€ ìµœì†Œ ì§€ì†ì‹œê°„ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
          final noteDuration = time - currentNoteStartTime;
          if (noteDuration >= minimumDuration) {
            consolidated.add(currentNote);
          }
          
          // ìƒˆ ìŒí‘œ ì‹œì‘
          currentNote = result;
          currentNoteStartTime = time;
        }
      }
    }
    
    // ë§ˆì§€ë§‰ ìŒí‘œ ì¶”ê°€ (ìµœì†Œ ì§€ì†ì‹œê°„ í™•ì¸)
    if (currentNote != null) {
      final lastTime = results.last.timeSeconds ?? 0.0;
      final noteDuration = lastTime - currentNoteStartTime;
      if (noteDuration >= minimumDuration) {
        consolidated.add(currentNote);
      }
    }
    
    return consolidated;
  }

  /// ë“€ì–¼ ì—”ì§„ ë¶„ì„ (ë¬´ì¡°ê±´ ë³‘ë ¬ ì‹¤í–‰)
  Future<DualResult?> analyzeDual(Float32List audioData) async {
    // CREPEì™€ SPICEë¥¼ í•­ìƒ ë³‘ë ¬ë¡œ ì‹¤í–‰ (ì†ë„ ìµœìš°ì„ )
    final results = await Future.wait([
      analyzeWithCrepe(audioData).catchError((e) {
        print('âš ï¸ CREPE ì‹¤íŒ¨: $e');
        return null;
      }),
      analyzeWithSpice(audioData).catchError((e) {
        print('âš ï¸ SPICE ì‹¤íŒ¨: $e');
        return null;
      }),
    ], eagerError: false);
    
    final crepeResult = results[0] as CrepeResult?;
    final spiceResult = results[1] as SpiceResult?;
    
    return _fuseResults(crepeResult, spiceResult);
  }
  
  /// ì˜¤ë””ì˜¤ ë³µì¡ë„ íŒë‹¨
  bool _isComplexAudio(Float32List audioData) {
    if (audioData.length < 100) return false;
    
    // ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: RMSì™€ Zero-crossing rate
    final rms = _calculateRMS(audioData);
    final zcr = _calculateZCR(audioData);
    
    return rms > 0.05 && zcr > 0.1;
  }
  
  double _calculateRMS(Float32List data) {
    if (data.isEmpty) return 0.0;
    
    double sum = 0.0;
    for (final sample in data) {
      sum += sample * sample;
    }
    return math.sqrt(sum / data.length);
  }
  
  double _calculateZCR(Float32List data) {
    if (data.length < 2) return 0.0;
    
    int crossings = 0;
    for (int i = 1; i < data.length; i++) {
      if ((data[i-1] >= 0) != (data[i] >= 0)) {
        crossings++;
      }
    }
    return crossings / data.length;
  }
  
  /// ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (ë…¸ì´ì¦ˆ ê°ì†Œ, ì •ê·œí™”, ì¹¨ë¬µ ê°ì§€)
  Float32List _preprocessAudio(Float32List audioData) {
    if (audioData.isEmpty) return audioData;
    
    try {
      // 1. ì¹¨ë¬µ ê°ì§€
      if (_isSilence(audioData)) {
        debugPrint('ğŸ”‡ [Preprocessing] ì¹¨ë¬µ êµ¬ê°„ ê°ì§€ë¨');
        return Float32List(0); // ë¹ˆ ë°°ì—´ ë°˜í™˜í•˜ì—¬ ë¶„ì„ ìƒëµ
      }
      
      // 2. ë…¸ì´ì¦ˆ ê°ì†Œ (ê°„ë‹¨í•œ í•˜ì´íŒ¨ìŠ¤ í•„í„°)
      final filtered = _applyHighPassFilter(audioData);
      
      // 3. ì •ê·œí™” (RMS ê¸°ë°˜)
      final normalized = _normalizeAudio(filtered);
      
      // 4. ìœˆë„ì‰ (Hamming window)
      final windowed = _applyHammingWindow(normalized);
      
      debugPrint('ğŸ›ï¸ [Preprocessing] ì „ì²˜ë¦¬ ì™„ë£Œ - ì›ë³¸: ${audioData.length}, ì²˜ë¦¬ í›„: ${windowed.length}');
      return windowed;
      
    } catch (e) {
      debugPrint('âŒ [Preprocessing] ì „ì²˜ë¦¬ ì‹¤íŒ¨: $e');
      return audioData; // ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    }
  }
  
  /// ì¹¨ë¬µ ê°ì§€ (RMS ê¸°ë°˜)
  bool _isSilence(Float32List audioData, {double threshold = 0.01}) {
    if (audioData.isEmpty) return true;
    
    final rms = _calculateRMS(audioData);
    return rms < threshold;
  }
  
  /// ê°„ë‹¨í•œ í•˜ì´íŒ¨ìŠ¤ í•„í„° (80Hz ì´í•˜ ì£¼íŒŒìˆ˜ ì œê±°)
  Float32List _applyHighPassFilter(Float32List audioData, {double cutoffHz = 80.0}) {
    if (audioData.length < 2) return audioData;
    
    try {
      // ê°„ë‹¨í•œ 1ì°¨ IIR í•˜ì´íŒ¨ìŠ¤ í•„í„°
      const double sampleRate = 48000.0;
      final double rc = 1.0 / (2.0 * math.pi * cutoffHz);
      final double dt = 1.0 / sampleRate;
      final double alpha = rc / (rc + dt);
      
      final filtered = Float32List(audioData.length);
      filtered[0] = audioData[0];
      
      for (int i = 1; i < audioData.length; i++) {
        filtered[i] = alpha * (filtered[i-1] + audioData[i] - audioData[i-1]);
      }
      
      return filtered;
    } catch (e) {
      debugPrint('âŒ í•˜ì´íŒ¨ìŠ¤ í•„í„° ì‹¤íŒ¨: $e');
      return audioData;
    }
  }
  
  /// RMS ì •ê·œí™”
  Float32List _normalizeAudio(Float32List audioData, {double targetRMS = 0.3}) {
    if (audioData.isEmpty) return audioData;
    
    try {
      final currentRMS = _calculateRMS(audioData);
      if (currentRMS < 1e-6) return audioData; // ë„ˆë¬´ ì‘ì€ ì‹ í˜¸ëŠ” ì •ê·œí™”í•˜ì§€ ì•ŠìŒ
      
      final gain = targetRMS / currentRMS;
      final normalized = Float32List(audioData.length);
      
      for (int i = 0; i < audioData.length; i++) {
        normalized[i] = math.max(-1.0, math.min(1.0, audioData[i] * gain)); // í´ë¦¬í•‘ ë°©ì§€
      }
      
      return normalized;
    } catch (e) {
      debugPrint('âŒ ì •ê·œí™” ì‹¤íŒ¨: $e');
      return audioData;
    }
  }
  
  /// Hamming ìœˆë„ìš° ì ìš© (ìŠ¤í™íŠ¸ëŸ¼ ëˆ„ìˆ˜ ë°©ì§€)
  Float32List _applyHammingWindow(Float32List audioData) {
    if (audioData.isEmpty) return audioData;
    
    try {
      final windowed = Float32List(audioData.length);
      final length = audioData.length;
      
      for (int i = 0; i < length; i++) {
        final window = 0.54 - 0.46 * math.cos(2.0 * math.pi * i / (length - 1));
        windowed[i] = audioData[i] * window;
      }
      
      return windowed;
    } catch (e) {
      debugPrint('âŒ ìœˆë„ì‰ ì‹¤íŒ¨: $e');
      return audioData;
    }
  }
  
  /// Float32Listë¥¼ ì•ˆì „í•œ Base64ë¡œ ì¸ì½”ë”©
  String _encodeAudioToBase64(Float32List audioData) {
    try {
      // ì „ì²˜ë¦¬ ì ìš©
      final preprocessed = _preprocessAudio(audioData);
      if (preprocessed.isEmpty) {
        // ì¹¨ë¬µì´ë‚˜ ë…¸ì´ì¦ˆë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        throw Exception('Audio preprocessing detected silence or noise only');
      }
      
      // Float32ë¥¼ ë°”ì´íŠ¸ ë°°ì—´ë¡œ ë³€í™˜
      final byteData = ByteData(preprocessed.length * 4);
      for (int i = 0; i < preprocessed.length; i++) {
        byteData.setFloat32(i * 4, preprocessed[i], Endian.little);
      }
      
      // Base64ë¡œ ì¸ì½”ë”©
      final bytes = byteData.buffer.asUint8List();
      return base64Encode(bytes);
    } catch (e) {
      debugPrint('Audio encoding failed: $e');
      rethrow;
    }
  }
  
  /// JSON ì‘ë‹µ ì•ˆì „ì„± ê²€ì¦
  bool _isValidJsonResponse(Map<String, dynamic> data) {
    try {
      // í•„ìˆ˜ í•„ë“œ í™•ì¸
      if (!data.containsKey('success') || !data.containsKey('data')) {
        return false;
      }
      
      // ë°ì´í„° íƒ€ì… ê²€ì¦
      final success = data['success'];
      if (success is! bool) return false;
      
      // ì„±ê³µ ì‘ë‹µì¸ ê²½ìš° ë°ì´í„° í•„ë“œ ê²€ì¦
      if (success && data['data'] == null) {
        return false;
      }
      
      return true;
    } catch (e) {
      debugPrint('JSON validation failed: $e');
      return false;
    }
  }
  
  /// ê²°ê³¼ ìœµí•©
  DualResult? _fuseResults(CrepeResult? crepe, SpiceResult? spice) {
    if (crepe == null && spice == null) return null;
    
    // ì£¼ìš” í”¼ì¹˜ ì„ íƒ (CREPE ìš°ì„ )
    final mainFreq = crepe?.frequency ?? spice?.frequency ?? 0.0;
    final mainConf = crepe?.confidence ?? spice?.confidence ?? 0.0;
    
    // ì¶”ì²œ ì—”ì§„ ê²°ì •
    String recommended = 'CREPE';
    if (spice != null && spice.isChord) {
      recommended = 'SPICE';
    }
    
    // ë¶„ì„ í’ˆì§ˆ ê³„ì‚°
    double quality = 0.0;
    if (crepe != null) quality += crepe.confidence * 0.7;
    if (spice != null) quality += spice.confidence * 0.3;
    
    return DualResult(
      frequency: mainFreq,
      confidence: mainConf,
      timestamp: DateTime.now(),
      crepeResult: crepe,
      spiceResult: spice,
      recommendedEngine: recommended,
      analysisQuality: quality,
    );
  }
  
  
  /// ê²°ê³¼ ìºì‹± (LRU ë°©ì‹)
  void _cacheResult(String key, DualResult result) {
    if (_pitchCache.length >= _maxCacheSize) {
      // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (ë‹¨ìˆœ FIFO)
      final oldestKey = _pitchCache.keys.first;
      _pitchCache.remove(oldestKey);
    }
    
    _pitchCache[key] = result;
  }

  /// ì•± ì¢…ë£Œì‹œ í˜¸ì¶œí•  ì •ë¦¬ ë©”ì„œë“œ (ìµœì í™” ë²„ì „)
  Future<void> cleanup() async {
    debugPrint('ğŸ§¹ [DualEngineService] Starting optimized cleanup...');
    
    try {
      // ë°°ì¹˜ íƒ€ì´ë¨¸ ì •ì§€
      _batchTimer?.cancel();
      _batchTimer = null;
      
      // ì§„í–‰ ì¤‘ì¸ ìš”ì²­ë“¤ ì •ë¦¬
      for (final request in _crepeQueue) {
        if (!request.completer.isCompleted) {
          request.completer.completeError('Service disposed');
        }
      }
      for (final request in _spiceQueue) {
        if (!request.completer.isCompleted) {
          request.completer.completeError('Service disposed');
        }
      }
      
      // ìºì‹œ ì •ë¦¬
      _pitchCache.clear();
      _crepeQueue.clear();
      _spiceQueue.clear();
      
      // HTTP/2 í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
      try {
        _http2CrepeClient.close(force: true);
        _http2SpiceClient.close(force: true);
      } catch (e) {
        debugPrint('HTTP/2 í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: $e');
      }
      
      // ê¸°ì¡´ HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
      try {
        _crepeClient.close(force: true);
        _spiceClient.close(force: true);
      } catch (e) {
        debugPrint('HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: $e');
      }
      
      // ì—°ê²° í’€ ì •ë¦¬
      _connectionPool.clear();
      
      // SinglePitchTracker ì •ë¦¬
      if (_pitchTracker != null) {
        try {
          // SinglePitchTrackerì— dispose ë©”ì„œë“œê°€ ìˆë‹¤ë©´ í˜¸ì¶œ
          _pitchTracker = null;
        } catch (e) {
          debugPrint('PitchTracker ì •ë¦¬ ì‹¤íŒ¨: $e');
        }
      }
      
      debugPrint('âœ… [DualEngineService] Cleanup completed');
    } catch (e) {
      debugPrint('âŒ [DualEngineService] Cleanup failed: $e');
    }
  }
  
  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (dispose íŒ¨í„´)
  void dispose() {
    cleanup();
  }
}

/// ì—”ì§„ ìƒíƒœ
class EngineStatus {
  final bool crepeHealthy;
  final bool spiceHealthy;
  
  EngineStatus({
    required this.crepeHealthy,
    required this.spiceHealthy,
  });
  
  bool get anyHealthy => crepeHealthy || spiceHealthy;
  bool get bothHealthy => crepeHealthy && spiceHealthy;
  
  String get statusText {
    if (bothHealthy) return "ë‘ ì—”ì§„ ëª¨ë‘ ì •ìƒ";
    if (crepeHealthy) return "CREPEë§Œ ì •ìƒ";
    if (spiceHealthy) return "SPICEë§Œ ì •ìƒ";
    return "ë‘ ì—”ì§„ ëª¨ë‘ ì˜¤í”„ë¼ì¸";
  }
}

/// ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼
class RealtimeAnalysisStream {
  final DualEngineService _service;
  
  RealtimeAnalysisStream._internal(this._service);
  
  final StreamController<DualResult> _controller = 
      StreamController<DualResult>.broadcast();
  
  Stream<DualResult> get stream => _controller.stream;
  
  Timer? _timer;
  final List<Float32List> _buffer = [];
  static const int _maxBufferSize = 3;
  bool _isDisposed = false;
  
  void startStream() {
    if (_isDisposed) return;
    
    _timer = Timer.periodic(const Duration(milliseconds: 500), (_) {
      if (!_isDisposed) {
        _processBuffer();
      }
    });
  }
  
  void addAudioChunk(Float32List chunk) {
    if (_isDisposed) return;
    
    _buffer.add(chunk);
    if (_buffer.length > _maxBufferSize) {
      _buffer.removeAt(0);
    }
  }
  
  void _processBuffer() async {
    if (_buffer.isEmpty || _isDisposed) return;
    
    try {
      // ë²„í¼ ê²°í•© (ì•ˆì „í•œ í¬ê¸° ì²´í¬)
      final totalLength = _buffer.fold<int>(0, (sum, chunk) => sum + chunk.length);
      if (totalLength <= 0) return;
      
      final combined = Float32List(totalLength);
      
      int offset = 0;
      for (final chunk in _buffer) {
        if (_isDisposed) return; // ì¤‘ê°„ì— disposeëœ ê²½ìš° ì¦‰ì‹œ ë°˜í™˜
        
        if (offset + chunk.length <= combined.length) {
          combined.setRange(offset, offset + chunk.length, chunk);
          offset += chunk.length;
        }
      }
      
      // ë¶„ì„ ì‹¤í–‰ (dispose ì²´í¬)
      if (!_isDisposed) {
        final result = await _service.analyzeDual(combined);
        if (result != null && !_isDisposed && !_controller.isClosed) {
          _controller.add(result);
        }
      }
    } catch (e) {
      if (!_isDisposed) {
        debugPrint('âŒ [RealtimeAnalysisStream] Process buffer error: $e');
      }
    }
  }
  
  void stopStream() {
    _timer?.cancel();
    _timer = null;
    _buffer.clear();
  }
  
  void dispose() {
    if (_isDisposed) return;
    
    _isDisposed = true;
    stopStream();
    
    // StreamController ì•ˆì „í•˜ê²Œ ë‹«ê¸°
    if (!_controller.isClosed) {
      _controller.close();
    }
    
    debugPrint('âœ… [RealtimeAnalysisStream] Disposed successfully');
  }
}

/// ë°°ì¹˜ ìš”ì²­ í´ë˜ìŠ¤
class BatchRequest {
  final Float32List audioData;
  final double sampleRate;
  final int batchId;
  final Completer<DualResult> completer;
  
  BatchRequest({
    required this.audioData,
    required this.sampleRate,
    required this.batchId,
    required this.completer,
  });
}