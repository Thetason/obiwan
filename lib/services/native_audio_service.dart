import 'dart:async';
import 'dart:math' as math;
import 'package:flutter/services.dart';
import 'package:flutter/foundation.dart';
import '../core/debug_logger.dart';
import '../core/error_handler.dart';

class NativeAudioService {
  static const MethodChannel _channel = MethodChannel('audio_capture');
  static NativeAudioService? _instance;
  
  StreamController<Map<String, double>>? _audioLevelController;
  Function(double)? onAudioLevelChanged;
  bool _isInitialized = false;
  bool _isDisposed = false;  // CRITICAL FIX: disposal ìƒíƒœ ì¶”ì 
  
  NativeAudioService._();
  
  static NativeAudioService get instance {
    _instance ??= NativeAudioService._();
    return _instance!;
  }
  
  bool get isInitialized => _isInitialized;
  
  Stream<Map<String, double>> get audioLevelStream {
    _audioLevelController ??= StreamController<Map<String, double>>.broadcast();
    return _audioLevelController!.stream;
  }
  
  Future<void> initialize() async {
    return await errorHandler.safeExecute(
      () async {
        await logger.info('ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘', tag: 'NATIVE_AUDIO');
        
        // ë©”ì„œë“œ ì½œ í•¸ë“¤ëŸ¬ ë“±ë¡
        _channel.setMethodCallHandler((MethodCall call) async {
          await logger.debug('Swiftë¡œë¶€í„° ë©”ì„œë“œ í˜¸ì¶œ ìˆ˜ì‹ : ${call.method}', tag: 'NATIVE_AUDIO');
          return await _handleMethodCall(call);
        });
        
        await logger.info('ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ', tag: 'NATIVE_AUDIO');
        _isInitialized = true;
      },
      operationName: 'Native Audio Service Initialize',
    );
  }
  
  Future<bool> startRecording() async {
    if (defaultTargetPlatform != TargetPlatform.macOS) {
      await logger.warning('í˜„ì¬ í”Œë«í¼ì—ì„œëŠ” ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ê°€ ì§€ì›ë˜ì§€ ì•ŠìŒ', tag: 'NATIVE_AUDIO');
      return false;
    }

    final result = await errorHandler.handleAudioError(
      () async {
        final result = await _channel.invokeMethod<bool>('startRecording');
        await logger.info('ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘ ì„±ê³µ: $result', tag: 'NATIVE_AUDIO');
        return result ?? false;
      },
      'Start Recording',
    );
    
    return result ?? false;
  }
  
  Future<bool> stopRecording() async {
    if (defaultTargetPlatform != TargetPlatform.macOS) {
      return false;
    }

    final result = await errorHandler.handleAudioError(
      () async {
        final result = await _channel.invokeMethod<bool>('stopRecording');
        await logger.info('ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ë…¹ìŒ ì¢…ë£Œ ì„±ê³µ: $result', tag: 'NATIVE_AUDIO');
        return result ?? false;
      },
      'Stop Recording',
    );
    
    return result ?? false;
  }
  
  Future<List<double>?> getRecordedAudio() async {
    if (defaultTargetPlatform != TargetPlatform.macOS) {
      return null;
    }

    return await errorHandler.handleAudioError(
      () async {
        final result = await _channel.invokeMethod<List<dynamic>>('getRecordedAudio');
        final audioData = result?.cast<double>();
        
        if (audioData != null && audioData.isNotEmpty) {
          await logger.info('ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ: ${audioData.length} ìƒ˜í”Œ', tag: 'NATIVE_AUDIO');
        } else {
          await logger.warning('ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ', tag: 'NATIVE_AUDIO');
        }
        
        return audioData ?? [];
      },
      'Get Recorded Audio',
    );
  }
  
  Future<List<double>?> getRealtimeAudioBuffer() async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<List<dynamic>>('getRealtimeAudioBuffer');
        final audioData = result?.cast<double>();
        if (audioData != null && audioData.isNotEmpty) {
          print('ğŸ¤ [Dart] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ ìˆ˜ì‹ : ${audioData.length} ìƒ˜í”Œ');
        }
        return audioData;
      } else {
        return null;
      }
    } catch (e) {
      print('âŒ [Dart] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: $e');
      return null;
    }
  }
  
  Future<Map<String, dynamic>?> loadAudioFile(String filePath) async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<Map<dynamic, dynamic>>(
          'loadAudioFile',
          {'path': filePath},
        );
        
        if (result != null) {
          // Map<dynamic, dynamic>ì„ Map<String, dynamic>ìœ¼ë¡œ ë³€í™˜
          final audioData = Map<String, dynamic>.from(result);
          final samples = (audioData['samples'] as List<dynamic>?)?.cast<double>();
          
          print('ğŸµ [Dart] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: ${samples?.length ?? 0} ìƒ˜í”Œ');
          
          return {
            'samples': samples,
            'sampleRate': audioData['sampleRate'],
            'duration': audioData['duration'],
          };
        }
      }
      return null;
    } catch (e) {
      print('âŒ [Dart] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: $e');
      return null;
    }
  }
  
  Future<bool> playAudio() async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<bool>('playAudio');
        print('ğŸ”Š [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘: $result');
        return result ?? false;
      } else {
        return false;
      }
    } catch (e) {
      print('âŒ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  Future<bool> pauseAudio() async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<bool>('pauseAudio');
        print('â¸ï¸ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì¼ì‹œì •ì§€: $result');
        return result ?? false;
      } else {
        return false;
      }
    } catch (e) {
      print('âŒ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì¼ì‹œì •ì§€ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  Future<bool> stopAudio() async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<bool>('stopAudio');
        print('â¹ï¸ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì •ì§€: $result');
        return result ?? false;
      } else {
        return false;
      }
    } catch (e) {
      print('âŒ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ì •ì§€ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  Future<bool> seekAudio(double position) async {
    try {
      if (defaultTargetPlatform == TargetPlatform.macOS) {
        final result = await _channel.invokeMethod<bool>('seekAudio', {'position': position});
        print('â­ï¸ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ìœ„ì¹˜ ì´ë™: $result');
        return result ?? false;
      } else {
        return false;
      }
    } catch (e) {
      print('âŒ [Dart] ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ìœ„ì¹˜ ì´ë™ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  Future<dynamic> _handleMethodCall(MethodCall call) async {
    try {
      print('ğŸ“ [Dart] ë©”ì„œë“œ ì²˜ë¦¬ ì¤‘: ${call.method}');
      
      switch (call.method) {
        case 'onAudioLevel':
          // Mapìœ¼ë¡œ ì „ë‹¬ë˜ëŠ” ì˜¤ë””ì˜¤ ë ˆë²¨ ë°ì´í„° ì²˜ë¦¬
          final Map<String, dynamic> levelData = Map<String, dynamic>.from(call.arguments as Map);
          
          final dbLevel = (levelData['level'] as num?)?.toDouble() ?? -60.0;
          final rms = (levelData['rms'] as num?)?.toDouble() ?? 0.0;
          final samples = (levelData['samples'] as num?)?.toInt() ?? 0;
          
          print('ğŸ”Š [Dart] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤: ${dbLevel.toStringAsFixed(1)}dB, RMS=${rms.toStringAsFixed(3)}, ìƒ˜í”Œ=${samples}');
          
          // RMS ê°’ìœ¼ë¡œ ì½œë°± í˜¸ì¶œ
          onAudioLevelChanged?.call(rms);
          
          // ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ì†¡
          _audioLevelController?.add({
            'level': dbLevel,
            'rms': rms,
            'samples': samples.toDouble(),
          });
          
          return 'success';
        default:
          print('âš ï¸ [Dart] ì•Œ ìˆ˜ ì—†ëŠ” ë„¤ì´í‹°ë¸Œ ë©”ì„œë“œ í˜¸ì¶œ: ${call.method}');
          return 'unknown_method';
      }
    } catch (e) {
      print('âŒ [Dart] ë©”ì„œë“œ ì²˜ë¦¬ ì‹¤íŒ¨: $e');
      return 'error: $e';
    }
  }
  
  /// ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
  Future<List<double>?> getRecordedAudioData() async {
    try {
      await logger.info('ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ìš”ì²­', tag: 'NATIVE_AUDIO');
      
      // Swiftì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (getRecordedAudio ë©”ì„œë“œ ì‚¬ìš©)
      final result = await _channel.invokeMethod('getRecordedAudio');
      
      if (result != null) {
        // List<dynamic>ì„ List<double>ë¡œ ë³€í™˜
        final audioData = (result as List).map((e) => (e as num).toDouble()).toList();
        await logger.info('ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ : ${audioData.length} ìƒ˜í”Œ', tag: 'NATIVE_AUDIO');
        return audioData;
      }
      
      return null;
    } catch (e) {
      await logger.error('ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
      return null;
    }
  }
  
  /// ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
  Future<Map<String, dynamic>> getAudioSystemStatus() async {
    if (defaultTargetPlatform != TargetPlatform.macOS) {
      return {'supported': false, 'reason': 'Platform not supported'};
    }

    try {
      await logger.debug('ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹œì‘', tag: 'NATIVE_AUDIO');
      
      // ì„ì‹œë¡œ ë…¹ìŒ ì‹œì‘ì„ ì‹œë„í•´ì„œ ìƒíƒœ í™•ì¸
      bool canStart = false;
      String? errorMessage;
      
      try {
        canStart = await _channel.invokeMethod<bool>('startRecording') ?? false;
        if (canStart) {
          // ì¦‰ì‹œ ì¤‘ì§€
          await _channel.invokeMethod<bool>('stopRecording');
        }
      } on PlatformException catch (e) {
        errorMessage = e.message;
        await logger.error('ì˜¤ë””ì˜¤ ìƒíƒœ í™•ì¸ ì¤‘ ì—ëŸ¬: ${e.code} - ${e.message}', tag: 'NATIVE_AUDIO');
      }
      
      final status = {
        'supported': true,
        'canRecord': canStart,
        'error': errorMessage,
        'platform': 'macOS',
        'timestamp': DateTime.now().toIso8601String(),
      };
      
      await logger.info('ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ìƒíƒœ: $status', tag: 'NATIVE_AUDIO');
      return status;
      
    } catch (e) {
      await logger.error('ì˜¤ë””ì˜¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
      return {
        'supported': false,
        'error': e.toString(),
        'timestamp': DateTime.now().toIso8601String(),
      };
    }
  }

  /// ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ì´ í¬í•¨ëœ ë…¹ìŒ ì‹œì‘
  Future<bool> startRecordingWithRetry({int maxRetries = 3}) async {
    for (int attempt = 1; attempt <= maxRetries; attempt++) {
      await logger.info('ë…¹ìŒ ì‹œì‘ ì‹œë„ $attempt/$maxRetries', tag: 'NATIVE_AUDIO');
      
      final success = await startRecording();
      if (success) {
        await logger.info('ë…¹ìŒ ì‹œì‘ ì„±ê³µ (ì‹œë„ $attemptíšŒ)', tag: 'NATIVE_AUDIO');
        return true;
      }
      
      if (attempt < maxRetries) {
        await logger.warning('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨, ${attempt * 500}ms í›„ ì¬ì‹œë„', tag: 'NATIVE_AUDIO');
        await Future.delayed(Duration(milliseconds: attempt * 500));
      }
    }
    
    await logger.error('ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŒ', tag: 'NATIVE_AUDIO');
    return false;
  }

  /// ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
  Future<bool> validateRecordedAudio() async {
    final audioData = await getRecordedAudio();
    
    if (audioData == null || audioData.isEmpty) {
      await logger.error('ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ', tag: 'NATIVE_AUDIO');
      return false;
    }
    
    // ê¸°ë³¸ í’ˆì§ˆ ê²€ì‚¬
    final rmsLevel = _calculateRMS(audioData);
    final peakLevel = audioData.reduce((a, b) => a.abs() > b.abs() ? a : b);
    
    await logger.info('ì˜¤ë””ì˜¤ í’ˆì§ˆ: RMS=$rmsLevel, Peak=$peakLevel, ê¸¸ì´=${audioData.length}', tag: 'NATIVE_AUDIO');
    
    // ë„ˆë¬´ ì¡°ìš©í•˜ê±°ë‚˜ í´ë¦¬í•‘ëœ ì˜¤ë””ì˜¤ ì²´í¬
    if (rmsLevel < 0.001) {
      await logger.warning('ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì¡°ìš©í•¨ (RMS: $rmsLevel)', tag: 'NATIVE_AUDIO');
      return false;
    }
    
    if (peakLevel.abs() > 0.95) {
      await logger.warning('ì˜¤ë””ì˜¤ í´ë¦¬í•‘ ê°ì§€ (Peak: $peakLevel)', tag: 'NATIVE_AUDIO');
    }
    
    return true;
  }

  /// RMS ë ˆë²¨ ê³„ì‚°
  double _calculateRMS(List<double> samples) {
    if (samples.isEmpty) return 0.0;
    
    double sum = 0.0;
    for (final sample in samples) {
      sum += sample * sample;
    }
    return math.sqrt(sum / samples.length);
  }
  
  /// ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì¬ìƒ
  Future<bool> playRecordedAudio() async {
    try {
      await logger.info('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘', tag: 'NATIVE_AUDIO');
      final result = await _channel.invokeMethod<bool>('playAudio');
      
      if (result == true) {
        await logger.info('ì˜¤ë””ì˜¤ ì¬ìƒ ì„±ê³µ', tag: 'NATIVE_AUDIO');
        return true;
      } else {
        await logger.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨', tag: 'NATIVE_AUDIO');
        return false;
      }
    } catch (e) {
      await logger.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜ˆì™¸: $e', tag: 'NATIVE_AUDIO');
      return false;
    }
  }
  
  /// ì¬ìƒ ì¤‘ì§€
  Future<void> stopPlayback() async {
    try {
      await logger.info('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€', tag: 'NATIVE_AUDIO');
      await _channel.invokeMethod('stopPlayback')
          .timeout(const Duration(seconds: 2));
    } on PlatformException catch (e) {
      // Native ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì§€ ì•Šì€ ê²½ìš° ë¬´ì‹œ
      if (e.code != 'MissingPluginException') {
        await logger.error('ì¬ìƒ ì¤‘ì§€ í”Œë«í¼ ì—ëŸ¬: ${e.code} - ${e.message}', tag: 'NATIVE_AUDIO');
      }
    } on TimeoutException {
      await logger.warning('ì¬ìƒ ì¤‘ì§€ íƒ€ì„ì•„ì›ƒ', tag: 'NATIVE_AUDIO');
    } catch (e) {
      await logger.error('ì¬ìƒ ì¤‘ì§€ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
    }
  }
  
  /// í˜„ì¬ ì˜¤ë””ì˜¤ ë ˆë²¨ ê°€ì ¸ì˜¤ê¸°
  Future<double> getCurrentAudioLevel() async {
    try {
      final level = await _channel.invokeMethod<double>('getCurrentAudioLevel')
          .timeout(const Duration(seconds: 2));
      return level ?? 0.0;
    } on PlatformException catch (e) {
      await logger.warning('Native ì˜¤ë””ì˜¤ ë ˆë²¨ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: ${e.code} - ${e.message}', tag: 'NATIVE_AUDIO');
      return 0.0;
    } on TimeoutException catch (e) {
      await logger.warning('Native ì˜¤ë””ì˜¤ ë ˆë²¨ íƒ€ì„ì•„ì›ƒ: $e', tag: 'NATIVE_AUDIO');
      return 0.0;
    } catch (e) {
      await logger.error('ì˜¤ë””ì˜¤ ë ˆë²¨ ê°€ì ¸ì˜¤ê¸° ì˜ˆì™¸: $e', tag: 'NATIVE_AUDIO');
      // ì‹¤ì œ êµ¬í˜„ì´ ì—†ëŠ” ê²½ìš° 0.0 ë°˜í™˜ (ëœë¤ ê°’ ì œê±°)
      return 0.0;
    }
  }

  void dispose() {
    logger.info('Native Audio Service ì •ë¦¬', tag: 'NATIVE_AUDIO');
    _isDisposed = true;  // CRITICAL FIX: disposal ìƒíƒœ ì„¤ì •
    
    // ì§„í–‰ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì‘ì—… ëª¨ë‘ ì¤‘ì§€
    try {
      stopAudio().catchError((e) {
        logger.warning('dispose ì¤‘ ì˜¤ë””ì˜¤ ì •ì§€ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
      });
      stopRecording().catchError((e) {
        logger.warning('dispose ì¤‘ ë…¹ìŒ ì •ì§€ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
      });
    } catch (e) {
      logger.error('dispose ì¤‘ ì˜¤ë””ì˜¤ ì •ë¦¬ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
    }
    
    // StreamController ì•ˆì „í•˜ê²Œ ì •ë¦¬
    try {
      if (_audioLevelController != null && !_audioLevelController!.isClosed) {
        _audioLevelController!.close();
      }
    } catch (e) {
      logger.error('StreamController ì •ë¦¬ ì‹¤íŒ¨: $e', tag: 'NATIVE_AUDIO');
    } finally {
      _audioLevelController = null;
    }
    
    // ì½œë°± ì •ë¦¬
    onAudioLevelChanged = null;
    _isInitialized = false;
  }
}