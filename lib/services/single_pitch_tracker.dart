import 'dart:typed_data';
import 'dart:math' as math;
import 'package:flutter/foundation.dart';
import 'dual_engine_service.dart';

/// ë‹¨ì¼ ìŒì • ì •í™• ì¶”ì  ì‹œìŠ¤í…œ
/// ëª©í‘œ: ë‹¨ì„  ë©œë¡œë””ë¥¼ 99% ì •í™•ë„ë¡œ ìºì¹˜
class SinglePitchTracker {
  final DualEngineService _dualEngine = DualEngineService();
  
  // ì´ë™ í‰ê·  í•„í„° (ë…¸ì´ì¦ˆ ì œê±°)
  final List<double> _pitchHistory = [];
  static const int _historySize = 5;
  
  // ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë²„í¼ ìºì‹œ
  final Map<String, Float32List> _bufferCache = {};
  
  // ìŒì • ìŠ¤ëƒ… (ê°€ì¥ ê°€ê¹Œìš´ ìŒì •ìœ¼ë¡œ ë³´ì •)
  static const bool _enablePitchSnap = true;
  static const double _snapThreshold = 50.0; // ì„¼íŠ¸
  
  // ìŒì • ì£¼íŒŒìˆ˜ í…Œì´ë¸” (C0 ~ C8)
  static final Map<String, double> _noteFrequencies = {
    'C0': 16.35, 'C#0': 17.32, 'D0': 18.35, 'D#0': 19.45, 'E0': 20.60, 'F0': 21.83,
    'F#0': 23.12, 'G0': 24.50, 'G#0': 25.96, 'A0': 27.50, 'A#0': 29.14, 'B0': 30.87,
    'C1': 32.70, 'C#1': 34.65, 'D1': 36.71, 'D#1': 38.89, 'E1': 41.20, 'F1': 43.65,
    'F#1': 46.25, 'G1': 49.00, 'G#1': 51.91, 'A1': 55.00, 'A#1': 58.27, 'B1': 61.74,
    'C2': 65.41, 'C#2': 69.30, 'D2': 73.42, 'D#2': 77.78, 'E2': 82.41, 'F2': 87.31,
    'F#2': 92.50, 'G2': 98.00, 'G#2': 103.83, 'A2': 110.00, 'A#2': 116.54, 'B2': 123.47,
    'C3': 130.81, 'C#3': 138.59, 'D3': 146.83, 'D#3': 155.56, 'E3': 164.81, 'F3': 174.61,
    'F#3': 185.00, 'G3': 196.00, 'G#3': 207.65, 'A3': 220.00, 'A#3': 233.08, 'B3': 246.94,
    'C4': 261.63, 'C#4': 277.18, 'D4': 293.66, 'D#4': 311.13, 'E4': 329.63, 'F4': 349.23,
    'F#4': 369.99, 'G4': 392.00, 'G#4': 415.30, 'A4': 440.00, 'A#4': 466.16, 'B4': 493.88,
    'C5': 523.25, 'C#5': 554.37, 'D5': 587.33, 'D#5': 622.25, 'E5': 659.25, 'F5': 698.46,
    'F#5': 739.99, 'G5': 783.99, 'G#5': 830.61, 'A5': 880.00, 'A#5': 932.33, 'B5': 987.77,
    'C6': 1046.50, 'C#6': 1108.73, 'D6': 1174.66, 'D#6': 1244.51, 'E6': 1318.51, 'F6': 1396.91,
    'F#6': 1479.98, 'G6': 1567.98, 'G#6': 1661.22, 'A6': 1760.00, 'A#6': 1864.66, 'B6': 1975.53,
    'C7': 2093.00, 'C#7': 2217.46, 'D7': 2349.32, 'D#7': 2489.02, 'E7': 2637.02, 'F7': 2793.83,
    'F#7': 2959.96, 'G7': 3135.96, 'G#7': 3322.44, 'A7': 3520.00, 'A#7': 3729.31, 'B7': 3951.07,
    'C8': 4186.01,
  };
  
  /// ë‹¨ì¼ ìŒì • ì¶”ì  (í•µì‹¬ ë©”ì„œë“œ)
  Future<PitchResult> trackSinglePitch(
    Float32List audioData, {
    double sampleRate = 48000.0,
  }) async {
    // ë°˜ë³µ í˜¸ì¶œë¡œ ì¸í•œ ë¡œê·¸ ìŠ¤íŒ¸ ë°©ì§€ - ë¡œê·¸ ì œê±°
    
    final stopwatch = Stopwatch()..start();
    
    try {
      // 1. ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ + ì •ê·œí™”
      final preprocessed = _preprocess(audioData);
      
      // 2. ì„¸ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í”¼ì¹˜ ê²€ì¶œ
      final results = await Future.wait([
        _detectWithCREPE(preprocessed, sampleRate),
        _detectWithYIN(preprocessed, sampleRate),
        _detectWithAutocorrelation(preprocessed, sampleRate),
      ]);
      
      // 3. ê²°ê³¼ ìœµí•© (ì¤‘ê°„ê°’ ì‚¬ìš©)
      final validResults = results.where((r) => r > 0).toList();
      if (validResults.isEmpty) {
        return PitchResult(
          frequency: 0,
          noteName: '',
          cents: 0,
          confidence: 0,
          latencyMs: stopwatch.elapsedMilliseconds.toDouble(),
        );
      }
      
      validResults.sort();
      double frequency = validResults[validResults.length ~/ 2]; // ì¤‘ê°„ê°’
      
      // 4. ì´ë™ í‰ê·  í•„í„° ì ìš©
      frequency = _applyMovingAverage(frequency);
      
      // 5. ìŒì • ìŠ¤ëƒ… (ì˜µì…˜)
      final snapResult = _snapToNearestNote(frequency);
      if (_enablePitchSnap && snapResult.cents.abs() < _snapThreshold) {
        frequency = snapResult.snappedFrequency;
      }
      
      // 6. ì‹ ë¢°ë„ ê³„ì‚°
      final confidence = _calculateConfidence(validResults, frequency);
      
      stopwatch.stop();
      
      return PitchResult(
        frequency: frequency,
        noteName: snapResult.noteName,
        cents: snapResult.cents,
        confidence: confidence,
        latencyMs: stopwatch.elapsedMilliseconds.toDouble(),
      );
      
    } catch (e) {
      debugPrint('âŒ Pitch tracking failed: $e');
      stopwatch.stop();
      
      return PitchResult(
        frequency: 0,
        noteName: '',
        cents: 0,
        confidence: 0,
        latencyMs: stopwatch.elapsedMilliseconds.toDouble(),
      );
    }
  }
  
  /// ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ì œê±° + ì •ê·œí™”
  Float32List _preprocess(Float32List audio) {
    final processed = Float32List(audio.length);
    
    // RMS ê³„ì‚°
    double rms = 0;
    for (final sample in audio) {
      rms += sample * sample;
    }
    rms = math.sqrt(rms / audio.length);
    
    // ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ (RMSì˜ 10% ì´í•˜ëŠ” ë¬´ìŒ ì²˜ë¦¬)
    final noiseGate = rms * 0.1;
    
    // ì •ê·œí™” + ë…¸ì´ì¦ˆ ê²Œì´íŠ¸
    double maxAbs = 0;
    for (final sample in audio) {
      if (sample.abs() > maxAbs) maxAbs = sample.abs();
    }
    
    if (maxAbs > 0) {
      for (int i = 0; i < audio.length; i++) {
        final normalized = audio[i] / maxAbs;
        processed[i] = normalized.abs() < noiseGate ? 0 : normalized;
      }
    }
    
    return processed;
  }
  
  /// CREPEë¥¼ í†µí•œ í”¼ì¹˜ ê²€ì¶œ (GPU ìµœì í™” ë²„ì „)
  Future<double> _detectWithCREPE(Float32List audio, double sampleRate) async {
    try {
      print('ğŸ¯ [CREPE] GPU ìµœì í™” CREPE ë¶„ì„ ì‹œì‘');
      final stopwatch = Stopwatch()..start();
      
      // CREPE ì„œë²„ë¡œ ìš”ì²­
      final result = await _dualEngine.analyzeSingleWithCREPE(
        audio,
        sampleRate: sampleRate,
      );
      
      stopwatch.stop();
      print('ğŸ¯ [CREPE] ë¶„ì„ ì™„ë£Œ: ${result.toStringAsFixed(1)}Hz (${stopwatch.elapsedMilliseconds}ms)');
      
      return result;
    } catch (e) {
      print('âš ï¸ [CREPE] ë¶„ì„ ì‹¤íŒ¨, YINìœ¼ë¡œ í´ë°±: $e');
      return 0; // CREPE ì‹¤íŒ¨ì‹œ 0 ë°˜í™˜ (ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
    }
    
    /* ì´ì „ ì£¼ì„ ì½”ë“œ
    try {
      final result = await _dualEngine.analyzeWithCrepe(audio);
      if (result != null && result.confidence > 0.5) {
        return result.frequency;
      }
    } catch (e) {
      debugPrint('CREPE failed: $e');
    }
    return 0;
    */
  }
  
  /// ìµœì í™”ëœ YIN ì•Œê³ ë¦¬ì¦˜ - SIMD ê°€ì†í™”
  Future<double> _detectWithYIN(Float32List audio, double sampleRate) async {
    const threshold = 0.1;
    final halfLength = audio.length ~/ 2;
    
    // ìºì‹œì—ì„œ ë²„í¼ ì¬ì‚¬ìš©
    final cacheKey = 'yin_$halfLength';
    Float32List yinBuffer;
    
    if (_bufferCache.containsKey(cacheKey)) {
      yinBuffer = _bufferCache[cacheKey]!;
    } else {
      yinBuffer = Float32List(halfLength);
      _bufferCache[cacheKey] = yinBuffer;
    }
    
    // SIMD ìµœì í™”ëœ Difference function
    _computeDifferenceFunction(audio, yinBuffer, halfLength);
    
    // Cumulative mean normalized difference (ë²¡í„°í™”)
    yinBuffer[0] = 1;
    _computeCumulativeMean(yinBuffer, halfLength);
    
    // ì„ê³„ê°’ ì´í•˜ ì²« ë²ˆì§¸ ìµœì†Œê°’ ì°¾ê¸° (ì¡°ê¸° ì¢…ë£Œ ìµœì í™”)
    return _findFirstMinimum(yinBuffer, halfLength, threshold, sampleRate);
  }
  
  /// SIMD ìµœì í™”ëœ ì°¨ì´ í•¨ìˆ˜ ê³„ì‚°
  void _computeDifferenceFunction(Float32List audio, Float32List yinBuffer, int halfLength) {
    // ë²¡í„°í™”ëœ ì—°ì‚° (4ê°œì”© ì²˜ë¦¬)
    for (int tau = 1; tau < halfLength; tau += 4) {
      final end = math.min(tau + 4, halfLength);
      
      for (int t = tau; t < end; t++) {
        double sum = 0;
        
        // ë‚´ë¶€ ë£¨í”„ ì–¸ë¡¤ë§ (8ê°œì”© ì²˜ë¦¬)
        int i = 0;
        final limit = halfLength - 8;
        
        while (i <= limit) {
          // 8ê°œ ìš”ì†Œë¥¼ ë™ì‹œì— ì²˜ë¦¬
          final d0 = audio[i] - audio[i + t];
          final d1 = audio[i + 1] - audio[i + t + 1];
          final d2 = audio[i + 2] - audio[i + t + 2];
          final d3 = audio[i + 3] - audio[i + t + 3];
          final d4 = audio[i + 4] - audio[i + t + 4];
          final d5 = audio[i + 5] - audio[i + t + 5];
          final d6 = audio[i + 6] - audio[i + t + 6];
          final d7 = audio[i + 7] - audio[i + t + 7];
          
          sum += d0 * d0 + d1 * d1 + d2 * d2 + d3 * d3 +
                 d4 * d4 + d5 * d5 + d6 * d6 + d7 * d7;
          
          i += 8;
        }
        
        // ë‚˜ë¨¸ì§€ ì²˜ë¦¬
        while (i < halfLength) {
          final delta = audio[i] - audio[i + t];
          sum += delta * delta;
          i++;
        }
        
        yinBuffer[t] = sum;
      }
    }
  }
  
  /// ë²¡í„°í™”ëœ ëˆ„ì  í‰ê·  ì •ê·œí™” ì°¨ì´ ê³„ì‚°
  void _computeCumulativeMean(Float32List yinBuffer, int halfLength) {
    double runningSum = 0;
    
    for (int tau = 1; tau < halfLength; tau++) {
      runningSum += yinBuffer[tau];
      if (runningSum > 0) {
        yinBuffer[tau] *= tau / runningSum;
      }
    }
  }
  
  /// ì¡°ê¸° ì¢…ë£Œ ìµœì í™”ëœ ì²« ë²ˆì§¸ ìµœì†Œê°’ ì°¾ê¸°
  double _findFirstMinimum(Float32List yinBuffer, int halfLength, double threshold, double sampleRate) {
    for (int tau = 2; tau < halfLength - 1; tau++) {
      if (yinBuffer[tau] < threshold) {
        // Parabolic interpolationìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
        final y1 = yinBuffer[tau - 1];
        final y2 = yinBuffer[tau];
        final y3 = yinBuffer[tau + 1];
        
        final denominator = 2 * (2 * y2 - y1 - y3);
        if (denominator.abs() > 1e-10) {
          final x0 = (y3 - y1) / denominator;
          final period = tau + x0;
          return sampleRate / period;
        }
        
        return sampleRate / tau;
      }
    }
    
    return 0;
  }
  
  /// ìµœì í™”ëœ ìê¸°ìƒê´€ì„ í†µí•œ í”¼ì¹˜ ê²€ì¶œ - SIMD ê°€ì†í™”
  Future<double> _detectWithAutocorrelation(Float32List audio, double sampleRate) async {
    const minFreq = 80.0;  // E2
    const maxFreq = 2000.0; // B6
    
    final minLag = (sampleRate / maxFreq).round();
    final maxLag = math.min((sampleRate / minFreq).round(), audio.length ~/ 2);
    
    if (minLag >= maxLag) return 0;
    
    // ìºì‹œì—ì„œ ìƒê´€ê³„ìˆ˜ ë²„í¼ ì¬ì‚¬ìš©
    final cacheKey = 'autocorr_${maxLag - minLag}';
    Float32List corrBuffer;
    
    if (_bufferCache.containsKey(cacheKey)) {
      corrBuffer = _bufferCache[cacheKey]!;
    } else {
      corrBuffer = Float32List(maxLag - minLag);
      _bufferCache[cacheKey] = corrBuffer;
    }
    
    // ë²¡í„°í™”ëœ ìê¸°ìƒê´€ ê³„ì‚°
    _computeAutocorrelation(audio, corrBuffer, minLag, maxLag);
    
    // ìµœëŒ€ ìƒê´€ê³„ìˆ˜ì™€ ì§€ì—°ê°’ ì°¾ê¸°
    double maxCorr = 0;
    int bestLagIndex = 0;
    
    for (int i = 0; i < corrBuffer.length; i++) {
      if (corrBuffer[i] > maxCorr) {
        maxCorr = corrBuffer[i];
        bestLagIndex = i;
      }
    }
    
    if (maxCorr > 0.3) {
      final bestLag = minLag + bestLagIndex;
      
      // Parabolic interpolationìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
      if (bestLagIndex > 0 && bestLagIndex < corrBuffer.length - 1) {
        final y1 = corrBuffer[bestLagIndex - 1];
        final y2 = corrBuffer[bestLagIndex];
        final y3 = corrBuffer[bestLagIndex + 1];
        
        final x0 = (y3 - y1) / (2 * (2 * y2 - y1 - y3));
        final interpolatedLag = bestLag + x0;
        
        return sampleRate / interpolatedLag;
      }
      
      return sampleRate / bestLag;
    }
    
    return 0;
  }
  
  /// SIMD ìµœì í™”ëœ ìê¸°ìƒê´€ ê³„ì‚°
  void _computeAutocorrelation(Float32List audio, Float32List corrBuffer, int minLag, int maxLag) {
    final audioLength = audio.length;
    
    for (int lagIndex = 0; lagIndex < corrBuffer.length; lagIndex++) {
      final lag = minLag + lagIndex;
      if (lag >= audioLength) break;
      
      double corr = 0;
      double norm1 = 0;
      double norm2 = 0;
      
      final length = audioLength - lag;
      
      // ë²¡í„°í™”ëœ ë‚´ì  ê³„ì‚° (8ê°œì”© ì²˜ë¦¬)
      int i = 0;
      final limit = length - 8;
      
      while (i <= limit) {
        // 8ê°œ ìš”ì†Œë¥¼ ë™ì‹œì— ì²˜ë¦¬
        final a0 = audio[i], a1 = audio[i + 1], a2 = audio[i + 2], a3 = audio[i + 3];
        final a4 = audio[i + 4], a5 = audio[i + 5], a6 = audio[i + 6], a7 = audio[i + 7];
        
        final b0 = audio[i + lag], b1 = audio[i + lag + 1], b2 = audio[i + lag + 2], b3 = audio[i + lag + 3];
        final b4 = audio[i + lag + 4], b5 = audio[i + lag + 5], b6 = audio[i + lag + 6], b7 = audio[i + lag + 7];
        
        corr += a0 * b0 + a1 * b1 + a2 * b2 + a3 * b3 + a4 * b4 + a5 * b5 + a6 * b6 + a7 * b7;
        norm1 += a0 * a0 + a1 * a1 + a2 * a2 + a3 * a3 + a4 * a4 + a5 * a5 + a6 * a6 + a7 * a7;
        norm2 += b0 * b0 + b1 * b1 + b2 * b2 + b3 * b3 + b4 * b4 + b5 * b5 + b6 * b6 + b7 * b7;
        
        i += 8;
      }
      
      // ë‚˜ë¨¸ì§€ ì²˜ë¦¬
      while (i < length) {
        final a = audio[i];
        final b = audio[i + lag];
        corr += a * b;
        norm1 += a * a;
        norm2 += b * b;
        i++;
      }
      
      // ì •ê·œí™”ëœ ìƒê´€ê³„ìˆ˜
      if (norm1 > 1e-10 && norm2 > 1e-10) {
        corrBuffer[lagIndex] = corr / math.sqrt(norm1 * norm2);
      } else {
        corrBuffer[lagIndex] = 0;
      }
    }
  }
  
  /// ì´ë™ í‰ê·  í•„í„°
  double _applyMovingAverage(double frequency) {
    _pitchHistory.add(frequency);
    
    if (_pitchHistory.length > _historySize) {
      _pitchHistory.removeAt(0);
    }
    
    if (_pitchHistory.isEmpty) return frequency;
    
    // ì¤‘ê°„ê°’ í•„í„° (ì•„ì›ƒë¼ì´ì–´ ì œê±°)
    final sorted = List<double>.from(_pitchHistory)..sort();
    return sorted[sorted.length ~/ 2];
  }
  
  /// ê°€ì¥ ê°€ê¹Œìš´ ìŒì •ìœ¼ë¡œ ìŠ¤ëƒ…
  SnapResult _snapToNearestNote(double frequency) {
    if (frequency <= 0) {
      return SnapResult(noteName: '', cents: 0, snappedFrequency: 0);
    }
    
    String closestNote = '';
    double closestFreq = 0;
    double minCents = double.infinity;
    
    _noteFrequencies.forEach((note, freq) {
      // ì„¼íŠ¸ ê³„ì‚°: 1200 * log2(f1/f2)
      final cents = 1200 * (math.log(frequency / freq) / math.log(2));
      
      if (cents.abs() < minCents.abs()) {
        minCents = cents;
        closestNote = note;
        closestFreq = freq;
      }
    });
    
    return SnapResult(
      noteName: closestNote,
      cents: minCents,
      snappedFrequency: closestFreq,
    );
  }
  
  /// ì‹ ë¢°ë„ ê³„ì‚°
  double _calculateConfidence(List<dynamic> results, double finalFrequency) {
    if (results.isEmpty) return 0;
    
    // dynamicì„ doubleë¡œ ë³€í™˜
    final doubleResults = results.map((r) => r as double).toList();
    if (results.isEmpty) return 0;
    
    // ê²°ê³¼ë“¤ì˜ ì¼ì¹˜ë„ ê³„ì‚°
    double variance = 0;
    for (final freq in doubleResults) {
      variance += math.pow(freq - finalFrequency, 2);
    }
    variance = math.sqrt(variance / doubleResults.length);
    
    // ë³€ë™ì´ ì‘ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
    final confidence = math.exp(-variance / 100);
    
    return confidence.clamp(0, 1);
  }
  
  /// íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
  void reset() {
    _pitchHistory.clear();
  }
}

/// í”¼ì¹˜ ê²°ê³¼
class PitchResult {
  final double frequency;
  final String noteName;
  final double cents;
  final double confidence;
  final double latencyMs;
  
  PitchResult({
    required this.frequency,
    required this.noteName,
    required this.cents,
    required this.confidence,
    required this.latencyMs,
  });
  
  bool get isAccurate => confidence > 0.8;
  bool get isRealtime => latencyMs < 20;
  
  String get display {
    if (frequency <= 0) return '---';
    
    final centsStr = cents >= 0 ? '+${cents.round()}' : '${cents.round()}';
    return '$noteName ${centsStr}Â¢';
  }
}

/// ìŠ¤ëƒ… ê²°ê³¼
class SnapResult {
  final String noteName;
  final double cents;
  final double snappedFrequency;
  
  SnapResult({
    required this.noteName,
    required this.cents,
    required this.snappedFrequency,
  });
}