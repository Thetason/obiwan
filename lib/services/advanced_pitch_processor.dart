import 'dart:typed_data';
import 'dart:math' as math;
import 'package:flutter/foundation.dart';
import 'dart:async';
import 'dual_engine_service.dart';
import '../models/analysis_result.dart';
import 'vibrato_analyzer.dart';
import '../utils/pitch_color_system.dart';

/// ê³ ë„í™”ëœ í”¼ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ
/// ì‹¤ì‹œê°„ FFT, ìë™ ë³´ì •, í•˜ëª¨ë‹‰ ë¶„ì„ ë“± ì •êµí•œ ê¸°ëŠ¥ êµ¬í˜„
class AdvancedPitchProcessor {
  final DualEngineService _dualEngine = DualEngineService();
  final VibratoAnalyzer _vibratoAnalyzer = VibratoAnalyzer();
  
  // ìºì‹œ ì‹œìŠ¤í…œ
  final Map<int, _FFTCache> _fftCache = {};
  Timer? _cacheCleanupTimer;
  
  // ì¹¼ë§Œ í•„í„° ìƒíƒœ (ë…¸ì´ì¦ˆ ì œê±°ìš©)
  double _kalmanState = 0.0;
  double _kalmanUncertainty = 1.0;
  static const double _kalmanQ = 0.01; // í”„ë¡œì„¸ìŠ¤ ë…¸ì´ì¦ˆ
  static const double _kalmanR = 0.1;  // ì¸¡ì • ë…¸ì´ì¦ˆ
  
  AdvancedPitchProcessor() {
    // ìºì‹œ ì •ë¦¬ íƒ€ì´ë¨¸ (5ë¶„ë§ˆë‹¤)
    _cacheCleanupTimer = Timer.periodic(const Duration(minutes: 5), (_) {
      _cleanupCache();
    });
  }
  
  void dispose() {
    _cacheCleanupTimer?.cancel();
    _vibratoAnalyzer.clearHistory();
  }
  
  /// ğŸµ ë¹„ë¸Œë¼í†  ë¶„ì„ê¸° íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
  void clearVibratoHistory() {
    _vibratoAnalyzer.clearHistory();
  }
  
  /// ğŸ“Š ë¹„ë¸Œë¼í†  ë¶„ì„ í†µê³„ ì •ë³´
  VibratoAnalysisStats getVibratoStats() {
    return _vibratoAnalyzer.getAnalysisStats();
  }
  
  /// ê³ ê¸‰ í”¼ì¹˜ ë¶„ì„ (ì‹¤ì‹œê°„ ì²˜ë¦¬)
  Future<AdvancedPitchResult> analyzeAdvanced(
    Float32List audioData, {
    double sampleRate = 48000.0,
    bool useKalmanFilter = true,
    bool detectVibrato = true,
    bool analyzeFormants = true,
  }) async {
    final stopwatch = Stopwatch()..start();
    
    try {
      // 1. ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ + í”„ë¦¬ì— í¼ì‹œìŠ¤
      final preprocessed = _preprocess(audioData, sampleRate);
      
      // 2. ì‹¤ì‹œê°„ FFT ìŠ¤í™íŠ¸ëŸ¼ ê³„ì‚°
      final spectrum = _computeFFTSpectrum(preprocessed, sampleRate);
      
      // 3. ê¸°ë³¸ ì£¼íŒŒìˆ˜ ê²€ì¶œ (ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ì•™ìƒë¸”)
      final fundamentalResult = await _detectFundamental(
        preprocessed, 
        spectrum, 
        sampleRate
      );
      
      // 4. ì¹¼ë§Œ í•„í„°ë¡œ ë…¸ì´ì¦ˆ ì œê±° (ì˜µì…˜)
      double filteredFrequency = fundamentalResult.frequency;
      if (useKalmanFilter && fundamentalResult.frequency > 0) {
        filteredFrequency = _applyKalmanFilter(fundamentalResult.frequency);
      }
      
      // 5. í•˜ëª¨ë‹‰ êµ¬ì¡° ë¶„ì„
      final harmonics = _analyzeHarmonics(
        spectrum, 
        filteredFrequency,
        sampleRate
      );
      
      // 6. ê³ ê¸‰ ë¹„ë¸Œë¼í†  ë¶„ì„ (ì˜µì…˜)
      VibratoInfo? vibratoInfo;
      if (detectVibrato && pitchResult.frequency > 0 && pitchResult.confidence > 0.5) {
        // PitchData ê°ì²´ ìƒì„±
        final pitchData = PitchData(
          frequency: smoothedFreq,
          confidence: pitchResult.confidence,
          cents: pitchAccuracy.cents,
          timestamp: DateTime.now(),
          amplitude: spectrum.magnitude.isNotEmpty ? spectrum.magnitude.reduce(math.max) : 0.0,
        );
        
        // ìƒˆë¡œìš´ ë¹„ë¸Œë¼í†  ë¶„ì„ê¸° ì‚¬ìš©
        final vibratoResult = _vibratoAnalyzer.analyzeVibrato(pitchData);
        
        if (vibratoResult.isPresent) {
          vibratoInfo = VibratoInfo(
            rate: vibratoResult.rate,
            depth: vibratoResult.depth,
            regularity: vibratoResult.regularity,
            quality: vibratoResult.quality.description,
            intensity: vibratoResult.intensity,
          );
        }
      }
      
      // 7. í¬ë¨¼íŠ¸ ë¶„ì„ (ìŒìƒ‰ íŠ¹ì„±)
      FormantInfo? formantInfo;
      if (analyzeFormants) {
        formantInfo = _analyzeFormants(spectrum, sampleRate);
      }
      
      // 8. ìŒì • ì •í™•ë„ ê³„ì‚°
      final pitchAccuracy = _calculatePitchAccuracy(filteredFrequency);
      
      // 9. ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì§• ì¶”ì¶œ
      final spectralFeatures = _extractSpectralFeatures(spectrum);
      
      stopwatch.stop();
      
      return AdvancedPitchResult(
        frequency: filteredFrequency,
        confidence: fundamentalResult.confidence,
        harmonics: harmonics,
        vibrato: vibratoInfo,
        formants: formantInfo,
        pitchAccuracy: pitchAccuracy,
        spectralFeatures: spectralFeatures,
        processingTimeMs: stopwatch.elapsedMilliseconds.toDouble(),
        timestamp: DateTime.now(),
      );
      
    } catch (e) {
      debugPrint('âŒ Advanced pitch analysis failed: $e');
      stopwatch.stop();
      
      return AdvancedPitchResult(
        frequency: 0,
        confidence: 0,
        harmonics: [],
        vibrato: null,
        formants: null,
        pitchAccuracy: PitchAccuracy(noteName: '', cents: 0, inTune: false),
        spectralFeatures: SpectralFeatures.empty(),
        processingTimeMs: stopwatch.elapsedMilliseconds.toDouble(),
        timestamp: DateTime.now(),
      );
    }
  }
  
  /// ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ + í”„ë¦¬ì— í¼ì‹œìŠ¤
  Float32List _preprocess(Float32List audio, double sampleRate) {
    final processed = Float32List(audio.length);
    
    // 1. ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ (ë§¤ìš° ì‘ì€ ì‹ í˜¸ ì œê±°)
    const double noiseGate = 0.01;
    
    // 2. í”„ë¦¬ì— í¼ì‹œìŠ¤ í•„í„° (ê³ ì£¼íŒŒ ê°•ì¡°)
    const double preEmphasis = 0.97;
    
    for (int i = 0; i < audio.length; i++) {
      // ë…¸ì´ì¦ˆ ê²Œì´íŠ¸
      double sample = audio[i].abs() < noiseGate ? 0.0 : audio[i];
      
      // í”„ë¦¬ì— í¼ì‹œìŠ¤
      if (i > 0) {
        sample = sample - preEmphasis * audio[i - 1];
      }
      
      processed[i] = sample;
    }
    
    return processed;
  }
  
  /// ì‹¤ì œ FFT ìŠ¤í™íŠ¸ëŸ¼ ê³„ì‚°
  FrequencySpectrum _computeFFTSpectrum(
    Float32List audio, 
    double sampleRate
  ) {
    // ìºì‹œ í™•ì¸
    final cacheKey = audio.hashCode;
    if (_fftCache.containsKey(cacheKey)) {
      final cached = _fftCache[cacheKey]!;
      if (DateTime.now().difference(cached.timestamp).inSeconds < 1) {
        return cached.spectrum;
      }
    }
    
    // FFT í¬ê¸° (2ì˜ ê±°ë“­ì œê³±)
    final fftSize = _nextPowerOfTwo(audio.length);
    final paddedAudio = Float32List(fftSize);
    
    // ì œë¡œ íŒ¨ë”©
    for (int i = 0; i < audio.length && i < fftSize; i++) {
      paddedAudio[i] = audio[i];
    }
    
    // í•´ë° ìœˆë„ìš° ì ìš©
    _applyHammingWindow(paddedAudio);
    
    // FFT ìˆ˜í–‰ (Cooley-Tukey ì•Œê³ ë¦¬ì¦˜)
    final complexData = _performFFT(paddedAudio);
    
    // íŒŒì›Œ ìŠ¤í™íŠ¸ëŸ¼ ê³„ì‚°
    final spectrum = FrequencySpectrum(
      frequencies: Float32List(fftSize ~/ 2),
      magnitudes: Float32List(fftSize ~/ 2),
      sampleRate: sampleRate,
    );
    
    for (int i = 0; i < fftSize ~/ 2; i++) {
      final real = complexData[i * 2];
      final imag = complexData[i * 2 + 1];
      
      spectrum.frequencies[i] = i * sampleRate / fftSize;
      spectrum.magnitudes[i] = math.sqrt(real * real + imag * imag);
    }
    
    // ìºì‹œ ì €ì¥
    _fftCache[cacheKey] = _FFTCache(
      spectrum: spectrum,
      timestamp: DateTime.now(),
    );
    
    return spectrum;
  }
  
  /// FFT êµ¬í˜„ (Cooley-Tukey ì•Œê³ ë¦¬ì¦˜)
  Float32List _performFFT(Float32List data) {
    final n = data.length;
    final complexData = Float32List(n * 2); // real, imag pairs
    
    // ì‹¤ìˆ˜ ë°ì´í„°ë¥¼ ë³µì†Œìˆ˜ë¡œ ë³€í™˜
    for (int i = 0; i < n; i++) {
      complexData[i * 2] = data[i];     // real
      complexData[i * 2 + 1] = 0;       // imag
    }
    
    // Bit-reversal permutation
    int j = 0;
    for (int i = 1; i < n - 1; i++) {
      int bit = n >> 1;
      while (j >= bit) {
        j -= bit;
        bit >>= 1;
      }
      j += bit;
      
      if (i < j) {
        // Swap
        final tempReal = complexData[i * 2];
        final tempImag = complexData[i * 2 + 1];
        complexData[i * 2] = complexData[j * 2];
        complexData[i * 2 + 1] = complexData[j * 2 + 1];
        complexData[j * 2] = tempReal;
        complexData[j * 2 + 1] = tempImag;
      }
    }
    
    // Cooley-Tukey FFT
    for (int len = 2; len <= n; len <<= 1) {
      final halfLen = len >> 1;
      final angleStep = -2 * math.pi / len;
      
      for (int i = 0; i < n; i += len) {
        double angle = 0;
        
        for (int j = 0; j < halfLen; j++) {
          final cos = math.cos(angle);
          final sin = math.sin(angle);
          
          final idx1 = (i + j) * 2;
          final idx2 = (i + j + halfLen) * 2;
          
          final tReal = cos * complexData[idx2] - sin * complexData[idx2 + 1];
          final tImag = sin * complexData[idx2] + cos * complexData[idx2 + 1];
          
          complexData[idx2] = complexData[idx1] - tReal;
          complexData[idx2 + 1] = complexData[idx1 + 1] - tImag;
          
          complexData[idx1] = complexData[idx1] + tReal;
          complexData[idx1 + 1] = complexData[idx1 + 1] + tImag;
          
          angle += angleStep;
        }
      }
    }
    
    return complexData;
  }
  
  /// ê¸°ë³¸ ì£¼íŒŒìˆ˜ ê²€ì¶œ (ì•™ìƒë¸” ë°©ë²•)
  Future<FundamentalResult> _detectFundamental(
    Float32List audio,
    FrequencySpectrum spectrum,
    double sampleRate,
  ) async {
    // 1. AI ì—”ì§„ ê²°ê³¼ (ê°€ì¥ ì •í™•)
    DualResult? aiResult;
    try {
      aiResult = await _dualEngine.analyzeDual(audio);
    } catch (e) {
      debugPrint('AI engine failed: $e');
    }
    
    // 2. ìê¸°ìƒê´€(Autocorrelation) ë°©ë²•
    final acfFreq = _autocorrelationPitch(audio, sampleRate);
    
    // 3. ìŠ¤í™íŠ¸ëŸ¼ í”¼í¬ ë°©ë²•
    final peakFreq = _spectralPeakPitch(spectrum);
    
    // 4. Cepstrum ë°©ë²•
    final cepstrumFreq = _cepstrumPitch(audio, sampleRate);
    
    // ì•™ìƒë¸”: ê°€ì¤‘ í‰ê· 
    double frequency = 0;
    double confidence = 0;
    double totalWeight = 0;
    
    if (aiResult != null && aiResult.frequency > 0) {
      frequency += aiResult.frequency * 0.5; // AI ê°€ì¤‘ì¹˜ 50%
      confidence += aiResult.confidence * 0.5;
      totalWeight += 0.5;
    }
    
    if (acfFreq > 0) {
      frequency += acfFreq * 0.2; // ACF ê°€ì¤‘ì¹˜ 20%
      confidence += 0.8 * 0.2;
      totalWeight += 0.2;
    }
    
    if (peakFreq > 0) {
      frequency += peakFreq * 0.2; // ìŠ¤í™íŠ¸ëŸ¼ ê°€ì¤‘ì¹˜ 20%
      confidence += 0.7 * 0.2;
      totalWeight += 0.2;
    }
    
    if (cepstrumFreq > 0) {
      frequency += cepstrumFreq * 0.1; // Cepstrum ê°€ì¤‘ì¹˜ 10%
      confidence += 0.6 * 0.1;
      totalWeight += 0.1;
    }
    
    if (totalWeight > 0) {
      frequency /= totalWeight;
      confidence /= totalWeight;
    }
    
    return FundamentalResult(
      frequency: frequency,
      confidence: confidence,
      method: 'Ensemble',
    );
  }
  
  /// ìê¸°ìƒê´€ í”¼ì¹˜ ê²€ì¶œ
  double _autocorrelationPitch(Float32List audio, double sampleRate) {
    const int minLag = 20;  // ~2400Hz
    final int maxLag = (sampleRate / 50).round(); // ~50Hz
    
    double maxCorr = 0;
    int bestLag = 0;
    
    for (int lag = minLag; lag < maxLag && lag < audio.length ~/ 2; lag++) {
      double corr = 0;
      double norm1 = 0;
      double norm2 = 0;
      
      for (int i = 0; i < audio.length - lag; i++) {
        corr += audio[i] * audio[i + lag];
        norm1 += audio[i] * audio[i];
        norm2 += audio[i + lag] * audio[i + lag];
      }
      
      // ì •ê·œí™”ëœ ìƒê´€ê³„ìˆ˜
      if (norm1 > 0 && norm2 > 0) {
        corr = corr / math.sqrt(norm1 * norm2);
        
        if (corr > maxCorr) {
          maxCorr = corr;
          bestLag = lag;
        }
      }
    }
    
    if (bestLag > 0 && maxCorr > 0.3) {
      return sampleRate / bestLag;
    }
    
    return 0;
  }
  
  /// ìŠ¤í™íŠ¸ëŸ¼ í”¼í¬ í”¼ì¹˜ ê²€ì¶œ
  double _spectralPeakPitch(FrequencySpectrum spectrum) {
    double maxMag = 0;
    double peakFreq = 0;
    
    // 50Hz ~ 2000Hz ë²”ìœ„ì—ì„œ í”¼í¬ ì°¾ê¸°
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      final freq = spectrum.frequencies[i];
      if (freq < 50 || freq > 2000) continue;
      
      if (spectrum.magnitudes[i] > maxMag) {
        maxMag = spectrum.magnitudes[i];
        peakFreq = freq;
      }
    }
    
    // Parabolic interpolation for sub-bin accuracy
    final peakIdx = spectrum.frequencies.indexOf(peakFreq);
    if (peakIdx > 0 && peakIdx < spectrum.magnitudes.length - 1) {
      final y1 = spectrum.magnitudes[peakIdx - 1];
      final y2 = spectrum.magnitudes[peakIdx];
      final y3 = spectrum.magnitudes[peakIdx + 1];
      
      final x0 = (y3 - y1) / (2 * (2 * y2 - y1 - y3));
      peakFreq += x0 * (spectrum.frequencies[1] - spectrum.frequencies[0]);
    }
    
    return peakFreq;
  }
  
  /// Cepstrum í”¼ì¹˜ ê²€ì¶œ
  double _cepstrumPitch(Float32List audio, double sampleRate) {
    // ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
    final spectrum = _computeFFTSpectrum(audio, sampleRate);
    
    // ë¡œê·¸ ìŠ¤í™íŠ¸ëŸ¼
    final logSpectrum = Float32List(spectrum.magnitudes.length);
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      logSpectrum[i] = math.log(spectrum.magnitudes[i] + 1e-10);
    }
    
    // IFFT of log spectrum = cepstrum
    // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìê¸°ìƒê´€ìœ¼ë¡œ ëŒ€ì²´
    return _autocorrelationPitch(logSpectrum, sampleRate);
  }
  
  /// ì¹¼ë§Œ í•„í„° ì ìš©
  double _applyKalmanFilter(double measurement) {
    // ì˜ˆì¸¡ ë‹¨ê³„
    final predictedState = _kalmanState;
    final predictedUncertainty = _kalmanUncertainty + _kalmanQ;
    
    // ì—…ë°ì´íŠ¸ ë‹¨ê³„
    final kalmanGain = predictedUncertainty / (predictedUncertainty + _kalmanR);
    _kalmanState = predictedState + kalmanGain * (measurement - predictedState);
    _kalmanUncertainty = (1 - kalmanGain) * predictedUncertainty;
    
    return _kalmanState;
  }
  
  /// í•˜ëª¨ë‹‰ êµ¬ì¡° ë¶„ì„
  List<HarmonicComponent> _analyzeHarmonics(
    FrequencySpectrum spectrum,
    double fundamental,
    double sampleRate,
  ) {
    if (fundamental <= 0) return [];
    
    final harmonics = <HarmonicComponent>[];
    const int maxHarmonics = 10;
    const double tolerance = 10; // Hz
    
    for (int n = 1; n <= maxHarmonics; n++) {
      final targetFreq = fundamental * n;
      if (targetFreq > sampleRate / 2) break;
      
      // íƒ€ê²Ÿ ì£¼íŒŒìˆ˜ ê·¼ì²˜ì—ì„œ í”¼í¬ ì°¾ê¸°
      double peakMag = 0;
      double actualFreq = targetFreq;
      
      for (int i = 0; i < spectrum.frequencies.length; i++) {
        final freq = spectrum.frequencies[i];
        if ((freq - targetFreq).abs() < tolerance) {
          if (spectrum.magnitudes[i] > peakMag) {
            peakMag = spectrum.magnitudes[i];
            actualFreq = freq;
          }
        }
      }
      
      if (peakMag > 0) {
        harmonics.add(HarmonicComponent(
          order: n,
          frequency: actualFreq,
          amplitude: peakMag,
          deviation: actualFreq - targetFreq,
        ));
      }
    }
    
    return harmonics;
  }
  
  /// ê³ ê¸‰ ë¹„ë¸Œë¼í†  ê²€ì¶œ
  VibratoInfo _detectVibratoAdvanced(Float32List audio, double sampleRate) {
    // ì§§ì€ ìœˆë„ìš°ë¡œ í”¼ì¹˜ ì¶”ì 
    const int windowSize = 512;
    const int hopSize = 128;
    final pitchContour = <double>[];
    
    for (int i = 0; i < audio.length - windowSize; i += hopSize) {
      final window = audio.sublist(i, i + windowSize);
      final pitch = _autocorrelationPitch(Float32List.fromList(window), sampleRate);
      if (pitch > 0) {
        pitchContour.add(pitch);
      }
    }
    
    if (pitchContour.length < 10) {
      return VibratoInfo(rate: 0, depth: 0, regularity: 0);
    }
    
    // í”¼ì¹˜ ë³€ë™ ë¶„ì„
    final mean = pitchContour.reduce((a, b) => a + b) / pitchContour.length;
    
    // Detrend
    final detrended = pitchContour.map((p) => p - mean).toList();
    
    // ìê¸°ìƒê´€ìœ¼ë¡œ ì£¼ê¸° ì°¾ê¸°
    double maxCorr = 0;
    int bestLag = 0;
    
    for (int lag = 5; lag < detrended.length ~/ 2; lag++) {
      double corr = 0;
      for (int i = 0; i < detrended.length - lag; i++) {
        corr += detrended[i] * detrended[i + lag];
      }
      
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    
    // ë¹„ë¸Œë¼í†  íŒŒë¼ë¯¸í„° ê³„ì‚°
    final vibratoRate = bestLag > 0 ? sampleRate / (bestLag * hopSize) : 0;
    
    // ê¹Šì´ (ì„¼íŠ¸ ë‹¨ìœ„)
    double variance = 0;
    for (final p in pitchContour) {
      variance += math.pow(p - mean, 2);
    }
    variance /= pitchContour.length;
    final depth = 1200 * math.log(1 + math.sqrt(variance) / mean) / math.log(2);
    
    // ê·œì¹™ì„± (0~1)
    final regularity = maxCorr / (detrended.length * variance + 1e-10);
    
    return VibratoInfo(
      rate: vibratoRate,
      depth: depth,
      regularity: regularity.clamp(0, 1),
    );
  }
  
  /// í¬ë¨¼íŠ¸ ë¶„ì„
  FormantInfo _analyzeFormants(FrequencySpectrum spectrum, double sampleRate) {
    // LPC(ì„ í˜• ì˜ˆì¸¡ ì½”ë”©) ë°©ë²•ì˜ ê°„ë‹¨í•œ êµ¬í˜„
    final peaks = <FormantPeak>[];
    
    // ìŠ¤í™íŠ¸ëŸ¼ í¬ë½ì„  ì¶”ì¶œ
    final envelope = _extractSpectralEnvelope(spectrum);
    
    // ë¡œì»¬ ìµœëŒ€ê°’ ì°¾ê¸°
    for (int i = 1; i < envelope.length - 1; i++) {
      if (envelope[i] > envelope[i - 1] && envelope[i] > envelope[i + 1]) {
        final freq = spectrum.frequencies[i];
        
        // í¬ë¨¼íŠ¸ ë²”ìœ„ ì²´í¬ (F1: 200-1000Hz, F2: 500-2500Hz, F3: 1500-3500Hz)
        if (freq > 200 && freq < 3500) {
          peaks.add(FormantPeak(
            frequency: freq,
            amplitude: envelope[i],
            bandwidth: _estimateBandwidth(spectrum, i),
          ));
        }
      }
    }
    
    // ìƒìœ„ 3ê°œ í¬ë¨¼íŠ¸ ì„ íƒ
    peaks.sort((a, b) => b.amplitude.compareTo(a.amplitude));
    
    return FormantInfo(
      f1: peaks.isNotEmpty ? peaks[0].frequency : 0,
      f2: peaks.length > 1 ? peaks[1].frequency : 0,
      f3: peaks.length > 2 ? peaks[2].frequency : 0,
      peaks: peaks.take(5).toList(),
    );
  }
  
  /// ìŠ¤í™íŠ¸ëŸ¼ í¬ë½ì„  ì¶”ì¶œ
  Float32List _extractSpectralEnvelope(FrequencySpectrum spectrum) {
    final envelope = Float32List(spectrum.magnitudes.length);
    const int smoothingWindow = 5;
    
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      double sum = 0;
      int count = 0;
      
      for (int j = -smoothingWindow; j <= smoothingWindow; j++) {
        final idx = i + j;
        if (idx >= 0 && idx < spectrum.magnitudes.length) {
          sum += spectrum.magnitudes[idx];
          count++;
        }
      }
      
      envelope[i] = count > 0 ? sum / count : 0;
    }
    
    return envelope;
  }
  
  /// ëŒ€ì—­í­ ì¶”ì •
  double _estimateBandwidth(FrequencySpectrum spectrum, int peakIdx) {
    final peakMag = spectrum.magnitudes[peakIdx];
    final halfPower = peakMag / math.sqrt(2);
    
    // 3dB ëŒ€ì—­í­ ì°¾ê¸°
    int leftIdx = peakIdx;
    int rightIdx = peakIdx;
    
    while (leftIdx > 0 && spectrum.magnitudes[leftIdx] > halfPower) {
      leftIdx--;
    }
    
    while (rightIdx < spectrum.magnitudes.length - 1 && 
           spectrum.magnitudes[rightIdx] > halfPower) {
      rightIdx++;
    }
    
    return spectrum.frequencies[rightIdx] - spectrum.frequencies[leftIdx];
  }
  
  /// ìŒì • ì •í™•ë„ ê³„ì‚°
  PitchAccuracy _calculatePitchAccuracy(double frequency) {
    if (frequency <= 0) {
      return PitchAccuracy(noteName: '', cents: 0, inTune: false);
    }
    
    // A4 = 440Hz ê¸°ì¤€
    const double a4 = 440.0;
    
    // MIDI ë…¸íŠ¸ ë²ˆí˜¸ ê³„ì‚°
    final midiNote = 69 + 12 * math.log(frequency / a4) / math.log(2);
    final nearestNote = midiNote.round();
    
    // ì„¼íŠ¸ ì˜¤ì°¨
    final cents = (midiNote - nearestNote) * 100;
    
    // ë…¸íŠ¸ ì´ë¦„
    const notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    final noteName = notes[nearestNote % 12];
    final octave = (nearestNote ~/ 12) - 1;
    
    return PitchAccuracy(
      noteName: '$noteName$octave',
      cents: cents,
      inTune: cents.abs() < 10, // Â±10ì„¼íŠ¸ ì´ë‚´ë©´ ì •í™•
    );
  }
  
  /// ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì§• ì¶”ì¶œ
  SpectralFeatures _extractSpectralFeatures(FrequencySpectrum spectrum) {
    if (spectrum.magnitudes.isEmpty) {
      return SpectralFeatures.empty();
    }
    
    // ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬
    double centroid = 0;
    double totalMag = 0;
    
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      centroid += spectrum.frequencies[i] * spectrum.magnitudes[i];
      totalMag += spectrum.magnitudes[i];
    }
    
    if (totalMag > 0) {
      centroid /= totalMag;
    }
    
    // ìŠ¤í™íŠ¸ëŸ´ ìŠ¤í”„ë ˆë“œ
    double spread = 0;
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      spread += math.pow(spectrum.frequencies[i] - centroid, 2) * spectrum.magnitudes[i];
    }
    
    if (totalMag > 0) {
      spread = math.sqrt(spread / totalMag);
    }
    
    // ìŠ¤í™íŠ¸ëŸ´ í”ŒëŸ­ìŠ¤
    double flux = 0;
    // (ì´ì „ í”„ë ˆì„ê³¼ ë¹„êµ í•„ìš” - ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ êµ¬í˜„)
    
    // ìŠ¤í™íŠ¸ëŸ´ ë¡¤ì˜¤í”„
    double rolloff = 0;
    double cumSum = 0;
    final threshold = totalMag * 0.85;
    
    for (int i = 0; i < spectrum.magnitudes.length; i++) {
      cumSum += spectrum.magnitudes[i];
      if (cumSum >= threshold) {
        rolloff = spectrum.frequencies[i];
        break;
      }
    }
    
    return SpectralFeatures(
      centroid: centroid,
      spread: spread,
      flux: flux,
      rolloff: rolloff,
      brightness: centroid / 1000, // ì •ê·œí™”
    );
  }
  
  /// í•´ë° ìœˆë„ìš° ì ìš©
  void _applyHammingWindow(Float32List data) {
    final n = data.length;
    for (int i = 0; i < n; i++) {
      data[i] *= 0.54 - 0.46 * math.cos(2 * math.pi * i / (n - 1));
    }
  }
  
  /// 2ì˜ ê±°ë“­ì œê³± ì°¾ê¸°
  int _nextPowerOfTwo(int n) {
    int power = 1;
    while (power < n) {
      power *= 2;
    }
    return power;
  }
  
  /// ìºì‹œ ì •ë¦¬
  void _cleanupCache() {
    final now = DateTime.now();
    _fftCache.removeWhere((key, cache) => 
      now.difference(cache.timestamp).inMinutes > 5
    );
  }
}

// === ë°ì´í„° í´ë˜ìŠ¤ë“¤ ===

class AdvancedPitchResult {
  final double frequency;
  final double confidence;
  final List<HarmonicComponent> harmonics;
  final VibratoInfo? vibrato;
  final FormantInfo? formants;
  final PitchAccuracy pitchAccuracy;
  final SpectralFeatures spectralFeatures;
  final double processingTimeMs;
  final DateTime timestamp;
  
  AdvancedPitchResult({
    required this.frequency,
    required this.confidence,
    required this.harmonics,
    this.vibrato,
    this.formants,
    required this.pitchAccuracy,
    required this.spectralFeatures,
    required this.processingTimeMs,
    required this.timestamp,
  });
}

class FrequencySpectrum {
  final Float32List frequencies;
  final Float32List magnitudes;
  final double sampleRate;
  
  FrequencySpectrum({
    required this.frequencies,
    required this.magnitudes,
    required this.sampleRate,
  });
}

class FundamentalResult {
  final double frequency;
  final double confidence;
  final String method;
  
  FundamentalResult({
    required this.frequency,
    required this.confidence,
    required this.method,
  });
}

class HarmonicComponent {
  final int order;
  final double frequency;
  final double amplitude;
  final double deviation;
  
  HarmonicComponent({
    required this.order,
    required this.frequency,
    required this.amplitude,
    required this.deviation,
  });
}

class VibratoInfo {
  final double rate;         // Hz
  final double depth;        // cents
  final double regularity;   // 0-1
  final String quality;      // í’ˆì§ˆ ì„¤ëª…
  final double intensity;    // ê°•ë„ (0-1)
  
  VibratoInfo({
    required this.rate,
    required this.depth,
    required this.regularity,
    this.quality = '',
    this.intensity = 0.0,
  });
}

class FormantInfo {
  final double f1;
  final double f2;
  final double f3;
  final List<FormantPeak> peaks;
  
  FormantInfo({
    required this.f1,
    required this.f2,
    required this.f3,
    required this.peaks,
  });
}

class FormantPeak {
  final double frequency;
  final double amplitude;
  final double bandwidth;
  
  FormantPeak({
    required this.frequency,
    required this.amplitude,
    required this.bandwidth,
  });
}

class PitchAccuracy {
  final String noteName;
  final double cents;
  final bool inTune;
  
  PitchAccuracy({
    required this.noteName,
    required this.cents,
    required this.inTune,
  });
}

class SpectralFeatures {
  final double centroid;
  final double spread;
  final double flux;
  final double rolloff;
  final double brightness;
  
  SpectralFeatures({
    required this.centroid,
    required this.spread,
    required this.flux,
    required this.rolloff,
    required this.brightness,
  });
  
  factory SpectralFeatures.empty() {
    return SpectralFeatures(
      centroid: 0,
      spread: 0,
      flux: 0,
      rolloff: 0,
      brightness: 0,
    );
  }
}

class _FFTCache {
  final FrequencySpectrum spectrum;
  final DateTime timestamp;
  
  _FFTCache({
    required this.spectrum,
    required this.timestamp,
  });
}