import 'dart:convert';
import 'dart:typed_data';
import 'dart:math' as math;
import 'package:shared_preferences/shared_preferences.dart';
import 'package:flutter/foundation.dart';
import '../core/advanced_pitch_tracker.dart';

/// User Voice Profile Service
/// ì‚¬ìš©ì ë§ì¶¤ í”„ë¡œí•„ ìƒì„± ë° ê´€ë¦¬
/// ê°œì¸í™”ëœ í”¼ì¹˜ ì¶”ì  ì •í™•ë„ í–¥ìƒ
class UserProfileService {
  static const String kProfileKey = 'user_voice_profile_v1';
  static const String kCalibrationKey = 'calibration_history';
  static const String kAdapterKey = 'model_adapter_params';
  
  // í”„ë¡œí•„ íŒŒë¼ë¯¸í„°
  static const int kMinCalibrationSamples = 100;
  static const int kProfileHistoryDays = 30;
  static const double kConfidenceThreshold = 0.7;
  
  // ì–´ëŒ‘í„° íŒŒë¼ë¯¸í„° (ê²½ëŸ‰ ê°œì¸í™”)
  static const int kAdapterSize = 128; // 128ì°¨ì› ì–´ëŒ‘í„° ë²¡í„°
  static const double kLearningRate = 0.01;
  static const int kMaxAdapterUpdates = 100;
  
  // í˜„ì¬ í”„ë¡œí•„
  UserVoiceProfile? _currentProfile;
  VoiceAdapter? _modelAdapter;
  final List<CalibrationSession> _calibrationHistory = [];
  
  // í†µê³„
  final VoiceStatistics _statistics = VoiceStatistics();
  
  /// ì´ˆê¸°í™” ë° í”„ë¡œí•„ ë¡œë“œ
  Future<void> initialize() async {
    print('ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”');
    
    await loadProfile();
    await loadAdapter();
    
    if (_currentProfile != null) {
      print('âœ… ê¸°ì¡´ í”„ë¡œí•„ ë¡œë“œ ì™„ë£Œ');
      print(_currentProfile);
    } else {
      print('â„¹ï¸ ìƒˆ ì‚¬ìš©ì - í”„ë¡œí•„ ìƒì„± í•„ìš”');
    }
  }
  
  /// í”„ë¡œí•„ ë¡œë“œ
  Future<void> loadProfile() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final profileJson = prefs.getString(kProfileKey);
      
      if (profileJson != null) {
        final profileData = json.decode(profileJson);
        _currentProfile = UserVoiceProfile.fromJson(profileData);
        
        // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ ë¡œë“œ
        final historyJson = prefs.getString(kCalibrationKey);
        if (historyJson != null) {
          final historyData = json.decode(historyJson) as List;
          _calibrationHistory.clear();
          _calibrationHistory.addAll(
            historyData.map((e) => CalibrationSession.fromJson(e))
          );
        }
      }
    } catch (e) {
      print('âŒ í”„ë¡œí•„ ë¡œë“œ ì‹¤íŒ¨: $e');
    }
  }
  
  /// í”„ë¡œí•„ ì €ì¥
  Future<void> saveProfile() async {
    if (_currentProfile == null) return;
    
    try {
      final prefs = await SharedPreferences.getInstance();
      
      // í”„ë¡œí•„ ì €ì¥
      await prefs.setString(kProfileKey, json.encode(_currentProfile!.toJson()));
      
      // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ ì €ì¥ (ìµœê·¼ 30ì¼ë§Œ)
      final recentHistory = _calibrationHistory
          .where((s) => s.timestamp.isAfter(
              DateTime.now().subtract(Duration(days: kProfileHistoryDays))))
          .toList();
      
      await prefs.setString(
        kCalibrationKey,
        json.encode(recentHistory.map((s) => s.toJson()).toList()),
      );
      
      print('ğŸ’¾ í”„ë¡œí•„ ì €ì¥ ì™„ë£Œ');
    } catch (e) {
      print('âŒ í”„ë¡œí•„ ì €ì¥ ì‹¤íŒ¨: $e');
    }
  }
  
  /// ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¸ì…˜ ì‹œì‘
  Future<CalibrationResult> startCalibration({
    required Stream<PitchResult> pitchStream,
    Duration duration = const Duration(seconds: 30),
  }) async {
    print('ğŸ¤ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘ (${duration.inSeconds}ì´ˆ)');
    
    final samples = <VoiceSample>[];
    final stopwatch = Stopwatch()..start();
    
    // ì•ˆë‚´ ë©”ì‹œì§€
    final exercises = [
      'í¸ì•ˆí•œ ìŒë†’ì´ë¡œ "ì•„~" ì†Œë¦¬ë¥¼ 5ì´ˆê°„ ë‚´ì£¼ì„¸ìš”',
      'ë‚®ì€ ìŒì—ì„œ ë†’ì€ ìŒìœ¼ë¡œ ì²œì²œíˆ ì˜¬ë ¤ì£¼ì„¸ìš”',
      'ë†’ì€ ìŒì—ì„œ ë‚®ì€ ìŒìœ¼ë¡œ ì²œì²œíˆ ë‚´ë ¤ì£¼ì„¸ìš”',
      'ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ë¥¼ ì§§ê²Œ ë¶ˆëŸ¬ì£¼ì„¸ìš”',
    ];
    
    int exerciseIndex = 0;
    int exerciseStartTime = 0;
    
    await for (final pitch in pitchStream) {
      // ìš´ë™ ì „í™˜
      final elapsed = stopwatch.elapsedMilliseconds;
      if (elapsed > exerciseStartTime + 7500 && exerciseIndex < exercises.length - 1) {
        exerciseIndex++;
        exerciseStartTime = elapsed;
        print('ğŸµ ë‹¤ìŒ: ${exercises[exerciseIndex]}');
      }
      
      // ìœ íš¨í•œ ìƒ˜í”Œë§Œ ìˆ˜ì§‘
      if (pitch.isVoiced && pitch.confidence > kConfidenceThreshold) {
        samples.add(VoiceSample(
          frequency: pitch.frequency,
          confidence: pitch.confidence,
          timestamp: pitch.timestamp,
          exerciseType: exerciseIndex,
        ));
      }
      
      // ì‹œê°„ ì œí•œ
      if (stopwatch.elapsed >= duration) break;
    }
    
    stopwatch.stop();
    
    // ë¶„ì„ ë° í”„ë¡œí•„ ìƒì„±
    if (samples.length < kMinCalibrationSamples) {
      return CalibrationResult(
        success: false,
        message: 'ì¶©ë¶„í•œ ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (${samples.length}/${kMinCalibrationSamples})',
      );
    }
    
    // í”„ë¡œí•„ ìƒì„±/ì—…ë°ì´íŠ¸
    final newProfile = _analyzeVoiceSamples(samples);
    
    // ê¸°ì¡´ í”„ë¡œí•„ê³¼ ë³‘í•©
    if (_currentProfile != null) {
      _currentProfile = _mergeProfiles(_currentProfile!, newProfile);
    } else {
      _currentProfile = newProfile;
    }
    
    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¸ì…˜ ê¸°ë¡
    final session = CalibrationSession(
      timestamp: DateTime.now(),
      sampleCount: samples.length,
      duration: stopwatch.elapsed,
      profile: newProfile,
    );
    _calibrationHistory.add(session);
    
    // ì €ì¥
    await saveProfile();
    
    // ì–´ëŒ‘í„° ì—…ë°ì´íŠ¸
    await _updateAdapter(samples);
    
    return CalibrationResult(
      success: true,
      profile: _currentProfile!,
      message: 'ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ! ìŒì—­ëŒ€ì™€ íŠ¹ì„±ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.',
      improvements: _calculateImprovements(newProfile),
    );
  }
  
  /// ìŒì„± ìƒ˜í”Œ ë¶„ì„
  UserVoiceProfile _analyzeVoiceSamples(List<VoiceSample> samples) {
    // ì£¼íŒŒìˆ˜ ë¶„í¬ ë¶„ì„
    final frequencies = samples.map((s) => s.frequency).toList()..sort();
    
    // í†µê³„ ê³„ì‚°
    final minFreq = frequencies[frequencies.length ~/ 20]; // 5 percentile
    final maxFreq = frequencies[frequencies.length * 19 ~/ 20]; // 95 percentile
    final medianFreq = frequencies[frequencies.length ~/ 2];
    final meanFreq = frequencies.reduce((a, b) => a + b) / frequencies.length;
    
    // í‘œì¤€í¸ì°¨ (ì•ˆì •ì„± ì§€í‘œ)
    double variance = 0;
    for (final freq in frequencies) {
      variance += math.pow(freq - meanFreq, 2);
    }
    final stdDev = math.sqrt(variance / frequencies.length);
    
    // ë¹„ë¸Œë¼í†  íŠ¹ì„± ë¶„ì„
    final vibratoSamples = _detectVibratoCharacteristics(samples);
    
    // ìŒìƒ‰ íŠ¹ì„± (í•˜ëª¨ë‹‰ ë¶„í¬ ì‹œë®¬ë ˆì´ì…˜)
    final timbreVector = _extractTimbreFeatures(samples);
    
    // ì „í™˜ íŠ¹ì„± (í¬ë¥´íƒ€ë©˜í† /ê¸€ë¦¬ì‚°ë„)
    final transitionStats = _analyzeTransitions(samples);
    
    return UserVoiceProfile(
      // ê¸°ë³¸ í†µê³„
      minFrequency: minFreq,
      maxFrequency: maxFreq,
      comfortableMin: frequencies[frequencies.length ~/ 4],
      comfortableMax: frequencies[frequencies.length * 3 ~/ 4],
      medianFrequency: medianFreq,
      meanFrequency: meanFreq,
      stdDeviation: stdDev,
      
      // ê³ ê¸‰ íŠ¹ì„±
      vibratoRate: vibratoSamples['rate'] ?? 0,
      vibratoExtent: vibratoSamples['extent'] ?? 0,
      timbreVector: timbreVector,
      
      // ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜
      confidenceMultiplier: 1.0,
      
      // ë©”íƒ€ë°ì´í„°
      createdAt: DateTime.now(),
      sampleCount: samples.length,
      
      // ì „í™˜ íŠ¹ì„±
      averageTransitionSpeed: transitionStats['speed'] ?? 0,
      preferredPitchStep: transitionStats['step'] ?? 0,
    );
  }
  
  /// ë¹„ë¸Œë¼í†  íŠ¹ì„± ê°ì§€
  Map<String, double> _detectVibratoCharacteristics(List<VoiceSample> samples) {
    // ì—°ì†ëœ ìƒ˜í”Œì—ì„œ ì£¼ê¸°ì  ë³€ë™ ê°ì§€
    final result = <String, double>{};
    
    // ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (1ì´ˆ = 100 ìƒ˜í”Œ @ 100Hz)
    const windowSize = 100;
    if (samples.length < windowSize) return result;
    
    for (int i = 0; i < samples.length - windowSize; i++) {
      final window = samples.sublist(i, i + windowSize);
      final frequencies = window.map((s) => s.frequency).toList();
      
      // í‰ê·  ì œê±°
      final mean = frequencies.reduce((a, b) => a + b) / frequencies.length;
      final centered = frequencies.map((f) => f - mean).toList();
      
      // Zero-crossingìœ¼ë¡œ ì£¼ê¸° ì¶”ì •
      int crossings = 0;
      for (int j = 1; j < centered.length; j++) {
        if ((centered[j] >= 0) != (centered[j-1] >= 0)) {
          crossings++;
        }
      }
      
      final rate = crossings / 2.0; // Hz
      
      // ë¹„ë¸Œë¼í†  ë²”ìœ„ (4-8Hz)
      if (rate >= 4 && rate <= 8) {
        final extent = centered.map((c) => c.abs()).reduce(math.max);
        
        result['rate'] = (result['rate'] ?? 0) + rate;
        result['extent'] = (result['extent'] ?? 0) + extent;
        result['count'] = (result['count'] ?? 0) + 1;
      }
    }
    
    // í‰ê·  ê³„ì‚°
    if (result.containsKey('count') && result['count']! > 0) {
      result['rate'] = result['rate']! / result['count']!;
      result['extent'] = result['extent']! / result['count']!;
    }
    
    return result;
  }
  
  /// ìŒìƒ‰ íŠ¹ì§• ì¶”ì¶œ
  List<double> _extractTimbreFeatures(List<VoiceSample> samples) {
    // ê°„ë‹¨í•œ í†µê³„ ê¸°ë°˜ íŠ¹ì§• ë²¡í„° (ì‹¤ì œë¡œëŠ” ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ í•„ìš”)
    final features = List<double>.filled(8, 0);
    
    if (samples.isEmpty) return features;
    
    final frequencies = samples.map((s) => s.frequency).toList();
    final confidences = samples.map((s) => s.confidence).toList();
    
    // Feature 0-3: ì£¼íŒŒìˆ˜ 4ë¶„ìœ„ìˆ˜
    frequencies.sort();
    features[0] = frequencies[frequencies.length ~/ 4];
    features[1] = frequencies[frequencies.length ~/ 2];
    features[2] = frequencies[frequencies.length * 3 ~/ 4];
    features[3] = frequencies.last - frequencies.first; // Range
    
    // Feature 4-5: ì‹ ë¢°ë„ í†µê³„
    features[4] = confidences.reduce((a, b) => a + b) / confidences.length;
    features[5] = confidences.reduce(math.min);
    
    // Feature 6-7: ë³€ë™ì„±
    double totalChange = 0;
    for (int i = 1; i < frequencies.length; i++) {
      totalChange += (frequencies[i] - frequencies[i-1]).abs();
    }
    features[6] = totalChange / frequencies.length;
    features[7] = features[6] / features[3]; // Normalized variation
    
    // ì •ê·œí™”
    final maxFeature = features.reduce(math.max);
    if (maxFeature > 0) {
      for (int i = 0; i < features.length; i++) {
        features[i] /= maxFeature;
      }
    }
    
    return features;
  }
  
  /// ì „í™˜ íŠ¹ì„± ë¶„ì„
  Map<String, double> _analyzeTransitions(List<VoiceSample> samples) {
    final stats = <String, double>{};
    
    if (samples.length < 2) return stats;
    
    final transitions = <double>[];
    final speeds = <double>[];
    
    for (int i = 1; i < samples.length; i++) {
      final prev = samples[i-1];
      final curr = samples[i];
      
      final timeDiff = curr.timestamp.difference(prev.timestamp).inMilliseconds / 1000.0;
      if (timeDiff <= 0) continue;
      
      final freqDiff = (curr.frequency - prev.frequency).abs();
      final cents = 1200 * math.log(curr.frequency / prev.frequency) / math.log(2);
      
      transitions.add(cents.abs());
      speeds.add(cents.abs() / timeDiff); // cents per second
    }
    
    if (transitions.isNotEmpty) {
      transitions.sort();
      speeds.sort();
      
      stats['speed'] = speeds[speeds.length ~/ 2]; // Median speed
      stats['step'] = transitions[transitions.length ~/ 2]; // Median step
      stats['maxSpeed'] = speeds[speeds.length * 9 ~/ 10]; // 90 percentile
    }
    
    return stats;
  }
  
  /// í”„ë¡œí•„ ë³‘í•©
  UserVoiceProfile _mergeProfiles(UserVoiceProfile old, UserVoiceProfile new_) {
    // ê°€ì¤‘ í‰ê·  (ìƒˆ ë°ì´í„°ì— ë” ë§ì€ ê°€ì¤‘ì¹˜)
    const oldWeight = 0.3;
    const newWeight = 0.7;
    
    return UserVoiceProfile(
      minFrequency: old.minFrequency * oldWeight + new_.minFrequency * newWeight,
      maxFrequency: old.maxFrequency * oldWeight + new_.maxFrequency * newWeight,
      comfortableMin: old.comfortableMin * oldWeight + new_.comfortableMin * newWeight,
      comfortableMax: old.comfortableMax * oldWeight + new_.comfortableMax * newWeight,
      medianFrequency: old.medianFrequency * oldWeight + new_.medianFrequency * newWeight,
      meanFrequency: old.meanFrequency * oldWeight + new_.meanFrequency * newWeight,
      stdDeviation: old.stdDeviation * oldWeight + new_.stdDeviation * newWeight,
      vibratoRate: old.vibratoRate * oldWeight + new_.vibratoRate * newWeight,
      vibratoExtent: old.vibratoExtent * oldWeight + new_.vibratoExtent * newWeight,
      timbreVector: _mergeVectors(old.timbreVector, new_.timbreVector, oldWeight, newWeight),
      confidenceMultiplier: old.confidenceMultiplier,
      createdAt: old.createdAt,
      sampleCount: old.sampleCount + new_.sampleCount,
      averageTransitionSpeed: old.averageTransitionSpeed * oldWeight + new_.averageTransitionSpeed * newWeight,
      preferredPitchStep: old.preferredPitchStep * oldWeight + new_.preferredPitchStep * newWeight,
    );
  }
  
  /// ë²¡í„° ë³‘í•©
  List<double> _mergeVectors(List<double> old, List<double> new_, double oldWeight, double newWeight) {
    final merged = <double>[];
    final length = math.min(old.length, new_.length);
    
    for (int i = 0; i < length; i++) {
      merged.add(old[i] * oldWeight + new_[i] * newWeight);
    }
    
    return merged;
  }
  
  /// ì–´ëŒ‘í„° ì—…ë°ì´íŠ¸ (ê²½ëŸ‰ ê°œì¸í™”)
  Future<void> _updateAdapter(List<VoiceSample> samples) async {
    print('ğŸ”§ ëª¨ë¸ ì–´ëŒ‘í„° ì—…ë°ì´íŠ¸ ì¤‘...');
    
    // ì–´ëŒ‘í„° ì´ˆê¸°í™”
    _modelAdapter ??= VoiceAdapter(size: kAdapterSize);
    
    // íŠ¹ì§• ì¶”ì¶œ
    final features = _extractTimbreFeatures(samples);
    
    // ê°„ë‹¨í•œ gradient descent ì—…ë°ì´íŠ¸
    for (int i = 0; i < math.min(features.length, kAdapterSize); i++) {
      final error = features[i] - _modelAdapter!.weights[i];
      _modelAdapter!.weights[i] += error * kLearningRate;
    }
    
    _modelAdapter!.updateCount++;
    
    // ì €ì¥
    await _saveAdapter();
    
    print('âœ… ì–´ëŒ‘í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ (iteration: ${_modelAdapter!.updateCount})');
  }
  
  /// ì–´ëŒ‘í„° ë¡œë“œ
  Future<void> loadAdapter() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final adapterJson = prefs.getString(kAdapterKey);
      
      if (adapterJson != null) {
        final data = json.decode(adapterJson);
        _modelAdapter = VoiceAdapter.fromJson(data);
      }
    } catch (e) {
      print('âŒ ì–´ëŒ‘í„° ë¡œë“œ ì‹¤íŒ¨: $e');
    }
  }
  
  /// ì–´ëŒ‘í„° ì €ì¥
  Future<void> _saveAdapter() async {
    if (_modelAdapter == null) return;
    
    try {
      final prefs = await SharedPreferences.getInstance();
      await prefs.setString(kAdapterKey, json.encode(_modelAdapter!.toJson()));
    } catch (e) {
      print('âŒ ì–´ëŒ‘í„° ì €ì¥ ì‹¤íŒ¨: $e');
    }
  }
  
  /// ê°œì„ ì‚¬í•­ ê³„ì‚°
  List<String> _calculateImprovements(UserVoiceProfile newProfile) {
    final improvements = <String>[];
    
    if (_calibrationHistory.length > 1) {
      final prevProfile = _calibrationHistory[_calibrationHistory.length - 2].profile;
      
      // ìŒì—­ëŒ€ í™•ì¥
      final rangeIncrease = (newProfile.maxFrequency - newProfile.minFrequency) -
                           (prevProfile.maxFrequency - prevProfile.minFrequency);
      if (rangeIncrease > 10) {
        improvements.add('ìŒì—­ëŒ€ê°€ ${rangeIncrease.toStringAsFixed(0)}Hz í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤');
      }
      
      // ì•ˆì •ì„± í–¥ìƒ
      if (newProfile.stdDeviation < prevProfile.stdDeviation * 0.9) {
        improvements.add('ìŒì • ì•ˆì •ì„±ì´ ${((1 - newProfile.stdDeviation/prevProfile.stdDeviation) * 100).toStringAsFixed(0)}% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤');
      }
      
      // ë¹„ë¸Œë¼í†  ê°œì„ 
      if (newProfile.vibratoRate > 0 && prevProfile.vibratoRate == 0) {
        improvements.add('ë¹„ë¸Œë¼í† ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ (${newProfile.vibratoRate.toStringAsFixed(1)}Hz)');
      }
    }
    
    if (improvements.isEmpty) {
      improvements.add('í”„ë¡œí•„ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤');
    }
    
    return improvements;
  }
  
  /// í˜„ì¬ í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°
  UserVoiceProfile? get currentProfile => _currentProfile;
  
  /// ì–´ëŒ‘í„° ê°€ì ¸ì˜¤ê¸°
  VoiceAdapter? get adapter => _modelAdapter;
  
  /// í†µê³„ ê°€ì ¸ì˜¤ê¸°
  VoiceStatistics get statistics => _statistics;
  
  /// í”„ë¡œí•„ ë¦¬ì…‹
  Future<void> resetProfile() async {
    _currentProfile = null;
    _modelAdapter = null;
    _calibrationHistory.clear();
    
    final prefs = await SharedPreferences.getInstance();
    await prefs.remove(kProfileKey);
    await prefs.remove(kCalibrationKey);
    await prefs.remove(kAdapterKey);
    
    print('ğŸ”„ í”„ë¡œí•„ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤');
  }
}

/// ì‚¬ìš©ì ìŒì„± í”„ë¡œí•„
class UserVoiceProfile {
  final double minFrequency;
  final double maxFrequency;
  final double comfortableMin;
  final double comfortableMax;
  final double medianFrequency;
  final double meanFrequency;
  final double stdDeviation;
  final double vibratoRate;
  final double vibratoExtent;
  final List<double> timbreVector;
  final double confidenceMultiplier;
  final DateTime createdAt;
  final int sampleCount;
  final double averageTransitionSpeed;
  final double preferredPitchStep;
  
  const UserVoiceProfile({
    required this.minFrequency,
    required this.maxFrequency,
    required this.comfortableMin,
    required this.comfortableMax,
    required this.medianFrequency,
    required this.meanFrequency,
    required this.stdDeviation,
    required this.vibratoRate,
    required this.vibratoExtent,
    required this.timbreVector,
    required this.confidenceMultiplier,
    required this.createdAt,
    required this.sampleCount,
    required this.averageTransitionSpeed,
    required this.preferredPitchStep,
  });
  
  Map<String, dynamic> toJson() => {
    'minFrequency': minFrequency,
    'maxFrequency': maxFrequency,
    'comfortableMin': comfortableMin,
    'comfortableMax': comfortableMax,
    'medianFrequency': medianFrequency,
    'meanFrequency': meanFrequency,
    'stdDeviation': stdDeviation,
    'vibratoRate': vibratoRate,
    'vibratoExtent': vibratoExtent,
    'timbreVector': timbreVector,
    'confidenceMultiplier': confidenceMultiplier,
    'createdAt': createdAt.toIso8601String(),
    'sampleCount': sampleCount,
    'averageTransitionSpeed': averageTransitionSpeed,
    'preferredPitchStep': preferredPitchStep,
  };
  
  factory UserVoiceProfile.fromJson(Map<String, dynamic> json) => UserVoiceProfile(
    minFrequency: json['minFrequency'],
    maxFrequency: json['maxFrequency'],
    comfortableMin: json['comfortableMin'],
    comfortableMax: json['comfortableMax'],
    medianFrequency: json['medianFrequency'],
    meanFrequency: json['meanFrequency'],
    stdDeviation: json['stdDeviation'],
    vibratoRate: json['vibratoRate'] ?? 0,
    vibratoExtent: json['vibratoExtent'] ?? 0,
    timbreVector: List<double>.from(json['timbreVector'] ?? []),
    confidenceMultiplier: json['confidenceMultiplier'] ?? 1.0,
    createdAt: DateTime.parse(json['createdAt']),
    sampleCount: json['sampleCount'],
    averageTransitionSpeed: json['averageTransitionSpeed'] ?? 0,
    preferredPitchStep: json['preferredPitchStep'] ?? 0,
  );
  
  @override
  String toString() {
    final noteMin = _frequencyToNote(minFrequency);
    final noteMax = _frequencyToNote(maxFrequency);
    final comfortNoteMin = _frequencyToNote(comfortableMin);
    final comfortNoteMax = _frequencyToNote(comfortableMax);
    
    return '''
User Voice Profile:
  Range: $noteMin - $noteMax (${minFrequency.toStringAsFixed(1)} - ${maxFrequency.toStringAsFixed(1)} Hz)
  Comfortable: $comfortNoteMin - $comfortNoteMax
  Median: ${_frequencyToNote(medianFrequency)} (${medianFrequency.toStringAsFixed(1)} Hz)
  Stability: Â±${stdDeviation.toStringAsFixed(1)} Hz
  Vibrato: ${vibratoRate > 0 ? "${vibratoRate.toStringAsFixed(1)}Hz, Â±${vibratoExtent.toStringAsFixed(1)} cents" : "Not detected"}
  Samples: $sampleCount
''';
  }
  
  static String _frequencyToNote(double frequency) {
    if (frequency < 20 || frequency > 20000) return '';
    
    const notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const a4 = 440.0;
    
    final halfSteps = 12 * math.log(frequency / a4) / math.log(2);
    final noteIndex = (halfSteps.round() + 9 + 48) % 12;
    final octave = ((halfSteps.round() + 9 + 48) ~/ 12) - 1;
    
    return '${notes[noteIndex]}$octave';
  }
}

/// ìŒì„± ìƒ˜í”Œ
class VoiceSample {
  final double frequency;
  final double confidence;
  final DateTime timestamp;
  final int exerciseType;
  
  const VoiceSample({
    required this.frequency,
    required this.confidence,
    required this.timestamp,
    required this.exerciseType,
  });
}

/// ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¸ì…˜
class CalibrationSession {
  final DateTime timestamp;
  final int sampleCount;
  final Duration duration;
  final UserVoiceProfile profile;
  
  const CalibrationSession({
    required this.timestamp,
    required this.sampleCount,
    required this.duration,
    required this.profile,
  });
  
  Map<String, dynamic> toJson() => {
    'timestamp': timestamp.toIso8601String(),
    'sampleCount': sampleCount,
    'duration': duration.inSeconds,
    'profile': profile.toJson(),
  };
  
  factory CalibrationSession.fromJson(Map<String, dynamic> json) => CalibrationSession(
    timestamp: DateTime.parse(json['timestamp']),
    sampleCount: json['sampleCount'],
    duration: Duration(seconds: json['duration']),
    profile: UserVoiceProfile.fromJson(json['profile']),
  );
}

/// ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼
class CalibrationResult {
  final bool success;
  final UserVoiceProfile? profile;
  final String message;
  final List<String>? improvements;
  
  const CalibrationResult({
    required this.success,
    this.profile,
    required this.message,
    this.improvements,
  });
}

/// ìŒì„± ì–´ëŒ‘í„° (ê²½ëŸ‰ ê°œì¸í™” íŒŒë¼ë¯¸í„°)
class VoiceAdapter {
  final int size;
  final List<double> weights;
  int updateCount;
  
  VoiceAdapter({required this.size})
      : weights = List<double>.filled(size, 0.5),
        updateCount = 0;
  
  Map<String, dynamic> toJson() => {
    'size': size,
    'weights': weights,
    'updateCount': updateCount,
  };
  
  factory VoiceAdapter.fromJson(Map<String, dynamic> json) {
    final adapter = VoiceAdapter(size: json['size']);
    adapter.weights.setAll(0, List<double>.from(json['weights']));
    adapter.updateCount = json['updateCount'];
    return adapter;
  }
}

/// ìŒì„± í†µê³„
class VoiceStatistics {
  int totalSessions = 0;
  int totalSamples = 0;
  Duration totalDuration = Duration.zero;
  double averageAccuracy = 0;
  double averageConfidence = 0;
  
  void update({
    required int samples,
    required Duration duration,
    required double accuracy,
    required double confidence,
  }) {
    totalSessions++;
    totalSamples += samples;
    totalDuration += duration;
    
    // ì´ë™ í‰ê· 
    averageAccuracy = (averageAccuracy * (totalSessions - 1) + accuracy) / totalSessions;
    averageConfidence = (averageConfidence * (totalSessions - 1) + confidence) / totalSessions;
  }
  
  @override
  String toString() => '''
Voice Statistics:
  Sessions: $totalSessions
  Total Samples: $totalSamples
  Total Duration: ${totalDuration.inMinutes} minutes
  Average Accuracy: ${(averageAccuracy * 100).toStringAsFixed(1)}%
  Average Confidence: ${(averageConfidence * 100).toStringAsFixed(1)}%
''';
}