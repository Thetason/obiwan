import 'dart:typed_data';
import 'dart:math' as math;
import 'package:flutter/foundation.dart';
import 'dual_engine_service.dart';
import '../models/analysis_result.dart';

/// ì˜¤ë¹„ì™„ v3 - ìœ ë‹ˆë²„ì„¤ í”¼ì¹˜ ë¶„ì„ê¸°
/// ì¸ê°„ ê°€ì²­ì£¼íŒŒìˆ˜ ì „ì²´ ë²”ìœ„ (20Hz ~ 20,000Hz) ì§€ì›
class UniversalPitchAnalyzer {
  final DualEngineService _dualEngine = DualEngineService();
  
  // ì£¼íŒŒìˆ˜ ë²”ìœ„ ì •ì˜
  static const double MIN_FREQUENCY = 20.0;    // ì¸ê°„ ê°€ì²­ ìµœì €ìŒ
  static const double MAX_FREQUENCY = 20000.0; // ì¸ê°„ ê°€ì²­ ìµœê³ ìŒ
  static const double VOCAL_MIN = 80.0;        // ì¼ë°˜ ë³´ì»¬ ìµœì €ìŒ (E2)
  static const double VOCAL_MAX = 4000.0;      // íœ˜ìŠ¬ ë³´ì´ìŠ¤ ìµœê³ ìŒ (C8)
  
  // ìŒê³„ë³„ ì£¼íŒŒìˆ˜ ë§µ (C0 ~ C10)
  static final Map<String, double> noteFrequencies = {
    // ì„œë¸Œ ë² ì´ìŠ¤ (20Hz ~ 80Hz)
    'C0': 16.35, 'D0': 18.35, 'E0': 20.60, 'F0': 21.83, 'G0': 24.50, 'A0': 27.50, 'B0': 30.87,
    'C1': 32.70, 'D1': 36.71, 'E1': 41.20, 'F1': 43.65, 'G1': 49.00, 'A1': 55.00, 'B1': 61.74,
    
    // ë² ì´ìŠ¤ ë²”ìœ„ (80Hz ~ 250Hz)
    'C2': 65.41, 'D2': 73.42, 'E2': 82.41, 'F2': 87.31, 'G2': 98.00, 'A2': 110.00, 'B2': 123.47,
    'C3': 130.81, 'D3': 146.83, 'E3': 164.81, 'F3': 174.61, 'G3': 196.00, 'A3': 220.00, 'B3': 246.94,
    
    // ì¤‘ìŒ ë²”ìœ„ (250Hz ~ 1000Hz) 
    'C4': 261.63, 'D4': 293.66, 'E4': 329.63, 'F4': 349.23, 'G4': 392.00, 'A4': 440.00, 'B4': 493.88,
    'C5': 523.25, 'D5': 587.33, 'E5': 659.25, 'F5': 698.46, 'G5': 783.99, 'A5': 880.00, 'B5': 987.77,
    
    // ê³ ìŒ ë²”ìœ„ (1000Hz ~ 4000Hz)
    'C6': 1046.50, 'D6': 1174.66, 'E6': 1318.51, 'F6': 1396.91, 'G6': 1567.98, 'A6': 1760.00, 'B6': 1975.53,
    'C7': 2093.00, 'D7': 2349.32, 'E7': 2637.02, 'F7': 2793.83, 'G7': 3135.96, 'A7': 3520.00, 'B7': 3951.07,
    'C8': 4186.01,
    
    // ì´ˆê³ ìŒ ë²”ìœ„ (4000Hz ~ 20000Hz)
    'C9': 8372.02, 'C10': 16744.04
  };
  
  /// ì „ì²´ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ (20Hz ~ 20kHz)
  Future<SpectrumAnalysisResult> analyzeFullSpectrum(Float32List audioData, {
    double sampleRate = 48000.0,
  }) async {
    print('ğŸµ [UniversalAnalyzer] ì „ì²´ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ ì‹œì‘');
    print('ğŸ“Š ë²”ìœ„: ${MIN_FREQUENCY}Hz ~ ${MAX_FREQUENCY}Hz');
    
    // 1. AI ì—”ì§„ ë¶„ì„ (ì •ë°€ ë¶„ì„)
    final aiResult = await _analyzeWithAI(audioData, sampleRate);
    
    // 2. FFT ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ (ì „ì²´ ë²”ìœ„)
    final spectrumData = _performFFT(audioData, sampleRate);
    
    // 3. í•˜ëª¨ë‹‰ ë¶„ì„ (ë°°ìŒ ê°ì§€)
    final harmonics = _detectHarmonics(spectrumData);
    
    // 4. ìŒì„± íŠ¹ì„± ë¶„ì„
    final vocalCharacteristics = _analyzeVocalCharacteristics(audioData, aiResult);
    
    return SpectrumAnalysisResult(
      primaryFrequency: aiResult?.frequency ?? 0.0,
      confidence: aiResult?.confidence ?? 0.0,
      spectrumData: spectrumData,
      harmonics: harmonics,
      vocalCharacteristics: vocalCharacteristics,
      frequencyRange: _detectFrequencyRange(aiResult?.frequency ?? 0.0),
      timestamp: DateTime.now(),
    );
  }
  
  /// AI ì—”ì§„ì„ í†µí•œ ì •ë°€ ë¶„ì„
  Future<DualResult?> _analyzeWithAI(Float32List audioData, double sampleRate) async {
    try {
      // ìµœì  ìœˆë„ìš° í¬ê¸° ìë™ ì„ íƒ
      final windowSize = _getOptimalWindowSize(sampleRate);
      
      final result = await _dualEngine.analyzeDual(audioData);
      
      if (result != null) {
        print('âœ… [AI] ì£¼íŒŒìˆ˜: ${result.frequency.toStringAsFixed(1)}Hz, '
              'ì‹ ë¢°ë„: ${(result.confidence * 100).toStringAsFixed(1)}%');
      }
      
      return result;
    } catch (e) {
      print('âŒ [AI] ë¶„ì„ ì‹¤íŒ¨: $e');
      return null;
    }
  }
  
  /// FFTë¥¼ í†µí•œ ì „ì²´ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
  List<SpectrumPoint> _performFFT(Float32List audioData, double sampleRate) {
    // ê°„ë‹¨í•œ FFT êµ¬í˜„ (ì‹¤ì œë¡œëŠ” FFT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥)
    final points = <SpectrumPoint>[];
    
    // ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ê³„ì‚°
    final bands = [
      FrequencyBand('Sub-Bass', 20, 80),
      FrequencyBand('Bass', 80, 250),
      FrequencyBand('Low-Mid', 250, 500),
      FrequencyBand('Mid', 500, 1000),
      FrequencyBand('High-Mid', 1000, 2000),
      FrequencyBand('High', 2000, 4000),
      FrequencyBand('Brilliance', 4000, 20000),
    ];
    
    for (final band in bands) {
      final energy = _calculateBandEnergy(audioData, sampleRate, band.minFreq, band.maxFreq);
      points.add(SpectrumPoint(
        frequency: (band.minFreq + band.maxFreq) / 2,
        amplitude: energy,
        bandName: band.name,
      ));
    }
    
    return points;
  }
  
  /// ì£¼íŒŒìˆ˜ ëŒ€ì—­ ì—ë„ˆì§€ ê³„ì‚°
  double _calculateBandEnergy(Float32List data, double sampleRate, double minFreq, double maxFreq) {
    // ê°„ë‹¨í•œ ì—ë„ˆì§€ ê³„ì‚° (ì‹¤ì œë¡œëŠ” FFT ì‚¬ìš©)
    double energy = 0.0;
    for (final sample in data) {
      energy += sample * sample;
    }
    return math.sqrt(energy / data.length);
  }
  
  /// í•˜ëª¨ë‹‰(ë°°ìŒ) ê°ì§€
  List<Harmonic> _detectHarmonics(List<SpectrumPoint> spectrum) {
    final harmonics = <Harmonic>[];
    
    // ê¸°ë³¸ ì£¼íŒŒìˆ˜ ì°¾ê¸°
    if (spectrum.isEmpty) return harmonics;
    
    final fundamental = spectrum.reduce((a, b) => 
      a.amplitude > b.amplitude ? a : b).frequency;
    
    // ë°°ìŒ ê³„ì‚° (2ë°°, 3ë°°, 4ë°°...)
    for (int n = 1; n <= 5; n++) {
      final harmonicFreq = fundamental * n;
      if (harmonicFreq <= MAX_FREQUENCY) {
        harmonics.add(Harmonic(
          order: n,
          frequency: harmonicFreq,
          amplitude: 1.0 / n, // ê°„ë‹¨í•œ ê°ì‡  ëª¨ë¸
        ));
      }
    }
    
    return harmonics;
  }
  
  /// ìŒì„± íŠ¹ì„± ë¶„ì„
  VocalCharacteristics _analyzeVocalCharacteristics(Float32List audioData, DualResult? aiResult) {
    final freq = aiResult?.frequency ?? 0.0;
    
    // ìŒì—­ëŒ€ íŒì •
    String voiceType;
    if (freq < 100) {
      voiceType = 'Sub-Bass';
    } else if (freq < 165) {
      voiceType = 'Bass';
    } else if (freq < 260) {
      voiceType = 'Baritone/Alto';
    } else if (freq < 520) {
      voiceType = 'Tenor/Mezzo-Soprano';
    } else if (freq < 1050) {
      voiceType = 'Soprano';
    } else if (freq < 4000) {
      voiceType = 'Whistle Voice';
    } else {
      voiceType = 'Super High';
    }
    
    // ë¹„ë¸Œë¼í†  ê°ì§€
    final vibrato = _detectVibrato(audioData);
    
    // ìŒìƒ‰ ë¶„ì„
    final timbre = _analyzeTimbre(audioData);
    
    return VocalCharacteristics(
      voiceType: voiceType,
      vibrato: vibrato,
      timbre: timbre,
      breathiness: _calculateBreathiness(audioData),
      brightness: _calculateBrightness(freq),
    );
  }
  
  /// ë¹„ë¸Œë¼í†  ê°ì§€
  double _detectVibrato(Float32List audioData) {
    // ì£¼íŒŒìˆ˜ ë³€ë™ ë¶„ì„ (ê°„ë‹¨í•œ êµ¬í˜„)
    double variation = 0.0;
    for (int i = 1; i < audioData.length; i++) {
      variation += (audioData[i] - audioData[i-1]).abs();
    }
    return variation / audioData.length;
  }
  
  /// ìŒìƒ‰ ë¶„ì„
  String _analyzeTimbre(Float32List audioData) {
    // RMS ê³„ì‚°ìœ¼ë¡œ ê°„ë‹¨í•œ ìŒìƒ‰ íŒì •
    double rms = 0.0;
    for (final sample in audioData) {
      rms += sample * sample;
    }
    rms = math.sqrt(rms / audioData.length);
    
    if (rms < 0.1) return 'Soft';
    if (rms < 0.3) return 'Warm';
    if (rms < 0.5) return 'Balanced';
    if (rms < 0.7) return 'Bright';
    return 'Powerful';
  }
  
  /// ìˆ¨ì†Œë¦¬ ì •ë„ ê³„ì‚°
  double _calculateBreathiness(Float32List audioData) {
    // ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ë¹„ìœ¨ë¡œ ê³„ì‚°
    return 0.3; // ê°„ë‹¨í•œ ê¸°ë³¸ê°’
  }
  
  /// ë°ê¸° ê³„ì‚°
  double _calculateBrightness(double frequency) {
    // ì£¼íŒŒìˆ˜ ê¸°ë°˜ ë°ê¸° (0.0 ~ 1.0)
    return math.min(1.0, frequency / 2000.0);
  }
  
  /// ì£¼íŒŒìˆ˜ ë²”ìœ„ ê°ì§€
  String _detectFrequencyRange(double frequency) {
    if (frequency < 80) return 'Sub-Bass (20-80Hz)';
    if (frequency < 250) return 'Bass (80-250Hz)';
    if (frequency < 500) return 'Low-Mid (250-500Hz)';
    if (frequency < 1000) return 'Mid (500-1kHz)';
    if (frequency < 2000) return 'High-Mid (1-2kHz)';
    if (frequency < 4000) return 'High (2-4kHz)';
    if (frequency < 20000) return 'Brilliance (4-20kHz)';
    return 'Ultrasonic (>20kHz)';
  }
  
  /// ìµœì  ìœˆë„ìš° í¬ê¸° ê³„ì‚°
  int _getOptimalWindowSize(double sampleRate) {
    // ë‚®ì€ ì£¼íŒŒìˆ˜: í° ìœˆë„ìš°, ë†’ì€ ì£¼íŒŒìˆ˜: ì‘ì€ ìœˆë„ìš°
    // ê¸°ë³¸: 8192 ìƒ˜í”Œ (ì•½ 170ms @ 48kHz)
    return 8192;
  }
  
  /// ì£¼íŒŒìˆ˜ë¥¼ ìŒê³„ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
  String frequencyToNote(double frequency) {
    if (frequency < MIN_FREQUENCY || frequency > MAX_FREQUENCY) {
      return 'Out of range';
    }
    
    // ê°€ì¥ ê°€ê¹Œìš´ ìŒê³„ ì°¾ê¸°
    String closestNote = '';
    double minDiff = double.infinity;
    
    noteFrequencies.forEach((note, freq) {
      final diff = (frequency - freq).abs();
      if (diff < minDiff) {
        minDiff = diff;
        closestNote = note;
      }
    });
    
    // ì„¼íŠ¸ ë‹¨ìœ„ ì˜¤ì°¨ ê³„ì‚°
    final targetFreq = noteFrequencies[closestNote]!;
    final cents = 1200 * math.log(frequency / targetFreq) / math.log(2);
    
    return '$closestNote ${cents >= 0 ? '+' : ''}${cents.toStringAsFixed(0)}Â¢';
  }
}

/// ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ ê²°ê³¼
class SpectrumAnalysisResult {
  final double primaryFrequency;
  final double confidence;
  final List<SpectrumPoint> spectrumData;
  final List<Harmonic> harmonics;
  final VocalCharacteristics vocalCharacteristics;
  final String frequencyRange;
  final DateTime timestamp;
  
  SpectrumAnalysisResult({
    required this.primaryFrequency,
    required this.confidence,
    required this.spectrumData,
    required this.harmonics,
    required this.vocalCharacteristics,
    required this.frequencyRange,
    required this.timestamp,
  });
}

/// ìŠ¤í™íŠ¸ëŸ¼ í¬ì¸íŠ¸
class SpectrumPoint {
  final double frequency;
  final double amplitude;
  final String bandName;
  
  SpectrumPoint({
    required this.frequency,
    required this.amplitude,
    required this.bandName,
  });
}

/// í•˜ëª¨ë‹‰ ì •ë³´
class Harmonic {
  final int order;
  final double frequency;
  final double amplitude;
  
  Harmonic({
    required this.order,
    required this.frequency,
    required this.amplitude,
  });
}

/// ìŒì„± íŠ¹ì„±
class VocalCharacteristics {
  final String voiceType;
  final double vibrato;
  final String timbre;
  final double breathiness;
  final double brightness;
  
  VocalCharacteristics({
    required this.voiceType,
    required this.vibrato,
    required this.timbre,
    required this.breathiness,
    required this.brightness,
  });
}

/// ì£¼íŒŒìˆ˜ ëŒ€ì—­
class FrequencyBand {
  final String name;
  final double minFreq;
  final double maxFreq;
  
  FrequencyBand(this.name, this.minFreq, this.maxFreq);
}