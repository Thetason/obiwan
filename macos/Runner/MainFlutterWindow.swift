import Cocoa
import FlutterMacOS
import AVFoundation

class RealTimeAudioRecorder: NSObject, AVAudioPlayerDelegate {
  private var audioEngine: AVAudioEngine?
  private var inputNode: AVAudioInputNode?
  private var channel: FlutterMethodChannel?
  private var isRecording = false
  private var recordedSamples: [Float] = []
  private var recordingStartTime: Date?
  private var audioPlayer: AVAudioPlayer?
  private var playbackTimer: Timer?
  
  init(channel: FlutterMethodChannel) {
    self.channel = channel
    super.init()
    setupAudioEngine()
  }
  
  private func setupAudioEngine() {
    audioEngine = AVAudioEngine()
    inputNode = audioEngine?.inputNode
    print("ğŸ”§ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
  }
  
  func startRecording(result: @escaping FlutterResult) {
    print("ğŸ™ï¸ [RealTime] ë…¹ìŒ ì‹œì‘ ìš”ì²­")
    
    // 1. ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
    let status = AVCaptureDevice.authorizationStatus(for: .audio)
    print("ğŸ” [RealTime] ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ: \(status.rawValue)")
    
    guard status == .authorized else {
      print("âŒ [RealTime] ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ")
      result(FlutterError(code: "PERMISSION_DENIED", message: "Microphone permission required", details: nil))
      return
    }
    
    guard let engine = audioEngine, let input = inputNode else {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨")
      result(FlutterError(code: "ENGINE_NOT_READY", message: "Audio engine not ready", details: nil))
      return
    }
    
    if isRecording {
      print("âš ï¸ [RealTime] ì´ë¯¸ ë…¹ìŒ ì¤‘")
      result(true)
      return
    }
    
    do {
      // 2. ìƒ˜í”Œ ë°°ì—´ ì´ˆê¸°í™”
      recordedSamples.removeAll()
      recordingStartTime = Date()
      
      // 3. ì…ë ¥ í¬ë§· í™•ì¸
      let inputFormat = input.outputFormat(forBus: 0)
      print("ğŸ›ï¸ [RealTime] ì…ë ¥ í¬ë§·: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ì±„ë„")
      
      // 4. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ íƒ­ ì„¤ì¹˜
      input.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, when in
        self?.processAudioBuffer(buffer: buffer)
      }
      
      // 5. ì˜¤ë””ì˜¤ ì—”ì§„ ì‹œì‘
      try engine.start()
      isRecording = true
      
      print("âœ… [RealTime] ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œì‘ ì„±ê³µ!")
      print("ğŸ“Š [RealTime] ì—”ì§„ ì‹¤í–‰ ìƒíƒœ: \(engine.isRunning)")
      
      result(true)
      
    } catch {
      print("âŒ [RealTime] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: \(error)")
      result(FlutterError(code: "START_FAILED", message: error.localizedDescription, details: nil))
    }
  }
  
  private func processAudioBuffer(buffer: AVAudioPCMBuffer) {
    let frameLength = Int(buffer.frameLength)
    let channelCount = Int(buffer.format.channelCount)
    
    // ë©€í‹°ì±„ë„ ì˜¤ë””ì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë‹¤ìš´ë¯¹ìŠ¤
    if channelCount == 1 {
      // ëª¨ë…¸ ì˜¤ë””ì˜¤: ì§ì ‘ ì‚¬ìš©
      guard let channelData = buffer.floatChannelData?[0] else { return }
      for i in 0..<frameLength {
        recordedSamples.append(channelData[i])
      }
    } else {
      // ìŠ¤í…Œë ˆì˜¤/ë©€í‹°ì±„ë„ ì˜¤ë””ì˜¤: í‰ê· ìœ¼ë¡œ ë‹¤ìš´ë¯¹ìŠ¤
      guard let leftChannel = buffer.floatChannelData?[0],
            let rightChannel = buffer.floatChannelData?[1] else { return }
      
      for i in 0..<frameLength {
        let monoSample = (leftChannel[i] + rightChannel[i]) * 0.5  // L+R í‰ê· 
        recordedSamples.append(monoSample)
      }
      
      print("ğŸ“Š [RealTime] ìŠ¤í…Œë ˆì˜¤â†’ëª¨ë…¸ ë‹¤ìš´ë¯¹ìŠ¤: \(channelCount)ì±„ë„ â†’ 1ì±„ë„")
    }
    
    // RMS ë ˆë²¨ ê³„ì‚° (ìµœê·¼ ì¶”ê°€ëœ ìƒ˜í”Œë“¤ë¡œ)
    let recentSampleCount = min(frameLength, recordedSamples.count)
    let startIndex = max(0, recordedSamples.count - recentSampleCount)
    
    var sum: Float = 0.0
    for i in startIndex..<recordedSamples.count {
      sum += recordedSamples[i] * recordedSamples[i]
    }
    let rms = sqrt(sum / Float(recentSampleCount))
    let dbLevel = 20 * log10(max(rms, 0.000001))  // dB ë³€í™˜
    
    // ì‹¤ì‹œê°„ìœ¼ë¡œ ë ˆë²¨ì„ Flutterë¡œ ì „ì†¡
    DispatchQueue.main.async {
      // ë„ˆë¬´ ìì£¼ í˜¸ì¶œë˜ì§€ ì•Šë„ë¡ ìƒ˜í”Œë§
      if self.recordedSamples.count % 4410 == 0 { // 0.1ì´ˆë§ˆë‹¤
        print("ğŸ“Š [RealTime] ë ˆë²¨: \(String(format: "%.1f", dbLevel))dB, ìƒ˜í”Œ: \(self.recordedSamples.count)")
        
        // Flutterë¡œ ì˜¤ë””ì˜¤ ë ˆë²¨ ì „ì†¡
        self.channel?.invokeMethod("onAudioLevel", arguments: [
          "level": Double(dbLevel),
          "rms": Double(rms),
          "samples": self.recordedSamples.count
        ])
      }
    }
  }
  
  func stopRecording(result: @escaping FlutterResult) {
    print("ğŸ›‘ [RealTime] ë…¹ìŒ ì¤‘ì§€ ìš”ì²­")
    
    guard let engine = audioEngine, let input = inputNode else {
      result(false)
      return
    }
    
    if !isRecording {
      print("âš ï¸ [RealTime] ë…¹ìŒ ì¤‘ì´ ì•„ë‹˜")
      result(true)
      return
    }
    
    // íƒ­ ì œê±°
    input.removeTap(onBus: 0)
    
    // ì—”ì§„ ì¤‘ì§€
    if engine.isRunning {
      engine.stop()
    }
    
    isRecording = false
    
    let duration = recordingStartTime?.timeIntervalSinceNow ?? 0
    print("âœ… [RealTime] ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ")
    print("ğŸ“Š [RealTime] ì´ ìƒ˜í”Œ: \(recordedSamples.count), ì‹œê°„: \(String(format: "%.1f", abs(duration)))ì´ˆ")
    
    result(true)
  }
  
  func getRecordedAudio(result: @escaping FlutterResult) {
    print("ğŸ“ [RealTime] ë…¹ìŒ ë°ì´í„° ìš”ì²­")
    print("ğŸ“Š [RealTime] ì €ì¥ëœ ìƒ˜í”Œ ìˆ˜: \(recordedSamples.count)")
    
    if recordedSamples.isEmpty {
      print("âš ï¸ [RealTime] ë…¹ìŒëœ ë°ì´í„° ì—†ìŒ, ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
      let dummyData = (0..<44100).map { i in
        Float(sin(Double(i) * 0.01) * 0.5)
      }
      result(dummyData)
    } else {
      print("âœ… [RealTime] ì‹¤ì œ ë…¹ìŒ ë°ì´í„° ë°˜í™˜: \(recordedSamples.count) ìƒ˜í”Œ")
      result(recordedSamples)
    }
  }
  
  func playRecording(result: @escaping FlutterResult) {
    print("ğŸ”Š [RealTime] ì‹¤ì œ ì˜¤ë””ì˜¤ ì¬ìƒ ìš”ì²­")
    
    guard !recordedSamples.isEmpty else {
      print("âŒ [RealTime] ì¬ìƒí•  ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ")
      result(false)
      return
    }
    
    // ë…¹ìŒëœ Float ë°°ì—´ì„ ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë³€í™˜
    do {
      let tempURL = createTempAudioFile(samples: recordedSamples)
      
      // AVAudioPlayerë¡œ ì¬ìƒ
      audioPlayer = try AVAudioPlayer(contentsOf: tempURL)
      audioPlayer?.delegate = self
      audioPlayer?.prepareToPlay()
      
      if audioPlayer?.play() == true {
        print("âœ… [RealTime] ì‹¤ì œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ - ê¸¸ì´: \(String(format: "%.1f", audioPlayer?.duration ?? 0))ì´ˆ")
        
        // ì¬ìƒ ì™„ë£Œë¥¼ ëª¨ë‹ˆí„°ë§
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
          guard let player = self?.audioPlayer else {
            self?.playbackTimer?.invalidate()
            return
          }
          
          if !player.isPlaying {
            self?.playbackTimer?.invalidate()
            print("â¸ï¸ [RealTime] ì¬ìƒ ì™„ë£Œ")
            
            // ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try? FileManager.default.removeItem(at: tempURL)
          }
        }
        
        result(true)
      } else {
        print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ ì‹¤íŒ¨")
        result(false)
      }
      
    } catch {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: \(error)")
      result(false)
    }
  }
  
  private func createTempAudioFile(samples: [Float]) -> URL {
    let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    let tempURL = documentsPath.appendingPathComponent("temp_playback.wav")
    
    // ì‹¤ì œ ë…¹ìŒëœ ìƒ˜í”Œë ˆì´íŠ¸ì™€ ë™ì¼í•˜ê²Œ ì„¤ì • (48kHz)
    let sampleRate: Double = 48000.0  // ë…¹ìŒê³¼ ë™ì¼í•œ 48kHzë¡œ ë³€ê²½
    let format = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: sampleRate, channels: 1, interleaved: false)!
    
    do {
      let audioFile = try AVAudioFile(forWriting: tempURL, settings: format.settings)
      
      guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(samples.count)) else {
        print("âŒ [RealTime] ë²„í¼ ìƒì„± ì‹¤íŒ¨")
        return tempURL
      }
      
      // Float ìƒ˜í”Œì„ ë²„í¼ì— ë³µì‚¬
      let channelData = buffer.floatChannelData![0]
      for i in 0..<samples.count {
        channelData[i] = samples[i]
      }
      buffer.frameLength = AVAudioFrameCount(samples.count)
      
      try audioFile.write(from: buffer)
      print("ğŸ“ [RealTime] ì„ì‹œ ì¬ìƒ íŒŒì¼ ìƒì„±: \(samples.count) ìƒ˜í”Œ -> \(tempURL.lastPathComponent)")
      
    } catch {
      print("âŒ [RealTime] ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: \(error)")
    }
    
    return tempURL
  }
  
  // MARK: - AVAudioPlayerDelegate
  func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
    print("ğŸ”Š [RealTime] ì¬ìƒ ì™„ë£Œë¨: successfully=\(flag)")
    playbackTimer?.invalidate()
    playbackTimer = nil
  }
  
  func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
    if let error = error {
      print("âŒ [RealTime] ì¬ìƒ ë””ì½”ë“œ ì˜¤ë¥˜: \(error)")
    }
  }
}

class MainFlutterWindow: NSWindow {
  private var audioRecorder: RealTimeAudioRecorder?
  
  override func awakeFromNib() {
    let flutterViewController = FlutterViewController()
    let windowFrame = self.frame
    self.contentViewController = flutterViewController
    self.setFrame(windowFrame, display: true)

    RegisterGeneratedPlugins(registry: flutterViewController)
    setupAudioChannel(controller: flutterViewController)
    requestMicrophonePermission()

    super.awakeFromNib()
  }
  
  private func requestMicrophonePermission() {
    let status = AVCaptureDevice.authorizationStatus(for: .audio)
    
    switch status {
    case .authorized:
      print("âœ… [Main] macOS ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨")
    case .notDetermined:
      print("ğŸ”” [Main] macOS ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...")
      AVCaptureDevice.requestAccess(for: .audio) { granted in
        DispatchQueue.main.async {
          print(granted ? "âœ… [Main] ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨!" : "âŒ [Main] ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨")
        }
      }
    case .denied, .restricted:
      print("âŒ [Main] ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    @unknown default:
      print("âš ï¸ [Main] ì•Œ ìˆ˜ ì—†ëŠ” ê¶Œí•œ ìƒíƒœ")
    }
  }
  
  private func setupAudioChannel(controller: FlutterViewController) {
    let channel = FlutterMethodChannel(
      name: "audio_capture",
      binaryMessenger: controller.engine.binaryMessenger
    )
    
    audioRecorder = RealTimeAudioRecorder(channel: channel)
    
    channel.setMethodCallHandler { [weak self] (call, result) in
      guard let recorder = self?.audioRecorder else {
        result(FlutterError(code: "NO_RECORDER", message: "Recorder not initialized", details: nil))
        return
      }
      
      switch call.method {
      case "startRecording":
        recorder.startRecording(result: result)
      case "stopRecording":
        recorder.stopRecording(result: result)
      case "getRecordedAudio":
        recorder.getRecordedAudio(result: result)
      case "playAudio":
        recorder.playRecording(result: result)
      case "pauseAudio":
        result(true)
      case "stopAudio":
        result(true)
      case "seekAudio":
        result(true)
      default:
        result(FlutterMethodNotImplemented)
      }
    }
    
    print("âœ… [Main] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
  }
}