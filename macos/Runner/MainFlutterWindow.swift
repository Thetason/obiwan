import Cocoa
import FlutterMacOS
import AVFoundation

class RealTimeAudioRecorder: NSObject, AVAudioPlayerDelegate {
  private var audioEngine: AVAudioEngine?
  private var inputNode: AVAudioInputNode?
  private var channel: FlutterMethodChannel?
  private var isRecording = false
  private var recordedSamples: [Float] = []
  private var recordingStartTime: Date?
  private var audioPlayer: AVAudioPlayer?
  private var playbackTimer: Timer?
  private var tempFileURL: URL?  // ì„ì‹œ íŒŒì¼ ì¶”ì 
  private var isDisposed = false  // dispose ìƒíƒœ ì¶”ì 
  
  init(channel: FlutterMethodChannel) {
    self.channel = channel
    super.init()
    setupAudioEngine()
  }
  
  deinit {
    print("ğŸ§¹ [RealTime] RealTimeAudioRecorder deinit í˜¸ì¶œë¨")
    isDisposed = true
    
    // CRITICAL FIX: íƒ€ì´ë¨¸ë¥¼ ë¨¼ì € ì •ë¦¬ (ì½œë°± ë°©ì§€)
    playbackTimer?.invalidate()
    playbackTimer = nil
    
    // CRITICAL FIX: audioPlayer delegateë¥¼ nilë¡œ ì„¤ì • í›„ ì •ì§€
    if let player = audioPlayer {
      player.delegate = nil  // delegate í•´ì œë¡œ ì½œë°± ë°©ì§€
      player.stop()
      audioPlayer = nil
    }
    
    // ë…¹ìŒ ì¤‘ì´ë©´ ì¤‘ì§€
    if isRecording {
      inputNode?.removeTap(onBus: 0)
      audioEngine?.stop()
      isRecording = false
    }
    
    // CRITICAL FIX: ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ
    if let tempURL = tempFileURL {
      DispatchQueue.global(qos: .background).async {
        try? FileManager.default.removeItem(at: tempURL)
      }
      tempFileURL = nil
    }
    
    // ì—”ì§„ ì •ë¦¬
    audioEngine = nil
    inputNode = nil
    
    // ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬
    recordedSamples.removeAll()
    
    print("âœ… [RealTime] RealTimeAudioRecorder ì •ë¦¬ ì™„ë£Œ")
  }
  
  private func setupAudioEngine() {
    print("ğŸ”§ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì…‹ì—… ì‹œì‘")
    
    // ê¸°ì¡´ ì—”ì§„ì´ ìˆìœ¼ë©´ ì™„ì „íˆ ì •ë¦¬
    if let engine = audioEngine {
      print("ğŸ”§ [RealTime] ê¸°ì¡´ ì—”ì§„ ì •ë¦¬ ì¤‘ (ì‹¤í–‰ìƒíƒœ: \(engine.isRunning))")
      if engine.isRunning {
        engine.stop()
      }
      // ê¸°ì¡´ íƒ­ë„ ì œê±°
      inputNode?.removeTap(onBus: 0)
      audioEngine = nil
      inputNode = nil
    }
    
    // CRITICAL FIX: macOS ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì¤€ë¹„
    print("ğŸ”§ [RealTime] macOS ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...")
    
    // ìƒˆ ì—”ì§„ ìƒì„±
    audioEngine = AVAudioEngine()
    inputNode = audioEngine?.inputNode
    
    // ì—”ì§„ê³¼ ì…ë ¥ ë…¸ë“œ ìœ íš¨ì„± ê²€ì‚¬
    guard let engine = audioEngine else {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ìƒì„± ì‹¤íŒ¨")
      return
    }
    
    guard let input = inputNode else {
      print("âŒ [RealTime] ì…ë ¥ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨")
      return
    }
    
    print("âœ… [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    print("ğŸ›ï¸ [RealTime] ì—”ì§„ ìƒíƒœ: isRunning=\(engine.isRunning)")
    print("ğŸ¤ [RealTime] ì…ë ¥ ë…¸ë“œ í¬ë§·: \(input.outputFormat(forBus: 0))")
  }
  
  func startRecording(result: @escaping FlutterResult) {
    print("ğŸ™ï¸ [RealTime] ë…¹ìŒ ì‹œì‘ ìš”ì²­")
    
    // 1. ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
    let status = AVCaptureDevice.authorizationStatus(for: .audio)
    print("ğŸ” [RealTime] ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ: \(status.rawValue)")
    
    guard status == .authorized else {
      print("âŒ [RealTime] ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ")
      result(FlutterError(code: "PERMISSION_DENIED", message: "Microphone permission required", details: nil))
      return
    }
    
    // ì—”ì§„ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì´ˆê¸°í™”
    if audioEngine == nil {
      print("ğŸ”§ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ì´ nil - ì¬ì´ˆê¸°í™”")
      setupAudioEngine()
    }
    
    guard let engine = audioEngine, let input = inputNode else {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨")
      result(FlutterError(code: "ENGINE_NOT_READY", message: "Audio engine not ready", details: nil))
      return
    }
    
    if isRecording {
      print("âš ï¸ [RealTime] ì´ë¯¸ ë…¹ìŒ ì¤‘")
      result(true)
      return
    }
    
    do {
      // 2. ìƒ˜í”Œ ë°°ì—´ ì´ˆê¸°í™”
      recordedSamples.removeAll()
      recordingStartTime = Date()
      
      // 3. ì…ë ¥ í¬ë§· í™•ì¸
      let inputFormat = input.outputFormat(forBus: 0)
      print("ğŸ›ï¸ [RealTime] ì…ë ¥ í¬ë§·: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ì±„ë„")
      
      // 4. ê¸°ì¡´ íƒ­ ì œê±° (ì•ˆì „ ì¡°ì¹˜)
      input.removeTap(onBus: 0)
      print("ğŸ”§ [RealTime] ê¸°ì¡´ íƒ­ ì œê±° ì™„ë£Œ")
      
      // 5. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ íƒ­ ì„¤ì¹˜ - CRITICAL FIX (SIMPLIFIED VERSION)
      let bufferSize: AVAudioFrameCount = 2048  // ì ì ˆí•œ ë²„í¼ í¬ê¸°
      
      print("ğŸ”§ [RealTime] íƒ­ ì„¤ì¹˜ ì‹œë„ - ë²„í¼: \(bufferSize)")
      print("ğŸ”§ [RealTime] ì…ë ¥ í¬ë§·: \(inputFormat)")
      
      // ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ íƒ­ ì„¤ì¹˜ (formatì„ nilë¡œ í•˜ì—¬ ìë™ ë³€í™˜)
      input.installTap(onBus: 0, bufferSize: bufferSize, format: nil) { [weak self] (buffer, when) in
        // ì¦‰ì‹œ ë¡œê¹… - ì–´ë–¤ ìŠ¤ë ˆë“œì—ì„œë“  í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        print("ğŸ“¥ [RealTime] *** TAP CALLBACK RECEIVED *** - frameLength: \(buffer.frameLength)")
        
        // ê°•ì œ ì–¸ë˜í•‘ì„ í”¼í•˜ê³  ì•ˆì „í•œ ì²´í¬
        guard let strongSelf = self else { 
          print("âŒ [RealTime] self is nil in callback")
          return 
        }
        
        // ë…¹ìŒ ìƒíƒœ ì²´í¬ ì¶”ê°€
        guard strongSelf.isRecording else {
          print("âš ï¸ [RealTime] ë…¹ìŒ ì¤‘ì´ ì•„ë‹Œë° ì½œë°± ìˆ˜ì‹ ë¨")
          return
        }
        
        // ì§ì ‘ ì²˜ë¦¬ (ë©”ì¸ ìŠ¤ë ˆë“œ ë””ìŠ¤íŒ¨ì¹˜ ì œê±°)
        strongSelf.processAudioBuffer(buffer: buffer)
      }
      
      print("ğŸ§ [RealTime] ì˜¤ë””ì˜¤ íƒ­ ì„¤ì¹˜ ì™„ë£Œ - ë²„í¼ í¬ê¸°: \(bufferSize)")
      print("ğŸ§ [RealTime] ì½œë°±ì´ ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œì—ì„œ ì§ì ‘ ì‹¤í–‰ë¨")
      
      // 5. ì˜¤ë””ì˜¤ ì—”ì§„ ì‹œì‘ - CRITICAL FIX with validation
      print("ğŸš€ [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì‹œì‘ ì‹œë„...")
      try engine.start()
      
      // ì—”ì§„ ì‹œì‘ í›„ ì¦‰ì‹œ ìƒíƒœ í™•ì¸
      let engineRunning = engine.isRunning
      print("ğŸ” [RealTime] ì—”ì§„ ì‹œì‘ í›„ ìƒíƒœ: isRunning=\(engineRunning)")
      
      if !engineRunning {
        throw NSError(domain: "AudioEngine", code: -1, userInfo: [NSLocalizedDescriptionKey: "Engine failed to start"])
      }
      
      // ì…ë ¥ ë…¸ë“œ ìƒíƒœ í™•ì¸ (macOSì—ì„œëŠ” isRunning ì†ì„±ì´ ì—†ìŒ)
      print("ğŸ” [RealTime] ì…ë ¥ ë…¸ë“œ ìƒíƒœ í™•ì¸ ì™„ë£Œ")
      print("ğŸ¤ [RealTime] ì…ë ¥ ë²„ìŠ¤ ìˆ˜: \(input.numberOfInputs), ì¶œë ¥ ë²„ìŠ¤ ìˆ˜: \(input.numberOfOutputs)")
      
      // 0.5ì´ˆ í›„ ìƒ˜í”Œ ì²´í¬ (ì‹¤ì œ ì˜¤ë””ì˜¤ë§Œ ì‚¬ìš©)
      DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
        guard let self = self else { return }
        if self.recordedSamples.isEmpty {
          print("âš ï¸ [RealTime] 0.5ì´ˆ ê²½ê³¼ - ì•„ì§ ìƒ˜í”Œì´ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ")
          print("ğŸ¤ [RealTime] ë§ˆì´í¬ í™•ì¸ í•„ìš” - ì‹¤ì œ ì˜¤ë””ì˜¤ ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
        } else {
          print("âœ… [RealTime] ì‹¤ì œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„±ê³µ: \(self.recordedSamples.count) ìƒ˜í”Œ")
        }
      }
      
      // ë…¹ìŒ ìƒíƒœ ì„¤ì •
      isRecording = true
      
      print("âœ… [RealTime] ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œì‘ ì„±ê³µ!")
      print("ğŸ“Š [RealTime] ìµœì¢… ìƒíƒœ - ì—”ì§„: \(engineRunning), ë…¹ìŒ: \(isRecording)")
      
      // CRITICAL FIX: dispose ìƒíƒœ ì²´í¬ì™€ í•¨ê»˜ weak self ì‚¬ìš©
      var checkCount = 0
      Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] timer in
        guard let self = self, !self.isDisposed else {
          timer.invalidate()
          return
        }
        
        checkCount += 1
        print("ğŸ” [RealTime] \(checkCount)ì´ˆ í›„ ìƒíƒœ ì²´í¬ - ìƒ˜í”Œ ìˆ˜: \(self.recordedSamples.count)")
        
        if checkCount >= 5 { // 5ì´ˆ í›„ ì •ì§€
          timer.invalidate()
        }
        
        if self.recordedSamples.count > 0 {
          print("ğŸ‰ [RealTime] ì½œë°± ì‘ë™ í™•ì¸! ìƒ˜í”Œ ìˆ˜ì§‘ ì„±ê³µ!")
          timer.invalidate()
        }
      }
      
      result(true)
      
    } catch {
      print("âŒ [RealTime] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: \(error)")
      result(FlutterError(code: "START_FAILED", message: error.localizedDescription, details: nil))
    }
  }
  
  private func processAudioBuffer(buffer: AVAudioPCMBuffer) {
    // ë…¹ìŒ ìƒíƒœ ì¬í™•ì¸
    guard isRecording else {
      print("âš ï¸ [RealTime] processAudioBuffer í˜¸ì¶œë¨ - ë…¹ìŒ ì¤‘ì´ ì•„ë‹˜")
      return
    }
    
    let frameLength = Int(buffer.frameLength)
    let channelCount = Int(buffer.format.channelCount)
    let sampleRate = buffer.format.sampleRate
    
    // ì¦‰ì‹œ ë¡œê¹… - processAudioBuffer í˜¸ì¶œ í™•ì¸ (ë§¤ë²ˆ ë¡œê·¸)
    print("ğŸ”„ [RealTime] *** PROCESS AUDIO BUFFER CALLED *** - \(frameLength) í”„ë ˆì„, \(channelCount) ì±„ë„, \(sampleRate)Hz")
    
    // ë²„í¼ ìœ íš¨ì„± ê²€ì‚¬
    guard frameLength > 0 && frameLength < 100000 else {
      print("âŒ [RealTime] ë¹„ì •ìƒì ì¸ í”„ë ˆì„ ê¸¸ì´: \(frameLength)")
      return
    }
    
    guard let channelData = buffer.floatChannelData else {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì±„ë„ ë°ì´í„°ê°€ nil")
      return
    }
    
    // ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ ê²€ì‚¬
    let firstChannelData = channelData[0]
    var hasNonZeroSample = false
    var maxSample: Float = 0.0
    
    for i in 0..<min(frameLength, 10) {  // ì²« 10ê°œ ìƒ˜í”Œë§Œ ì²´í¬
      let sample = firstChannelData[i]
      if abs(sample) > 0.0001 {
        hasNonZeroSample = true
        maxSample = max(maxSample, abs(sample))
      }
    }
    
    print("ğŸ” [RealTime] ë²„í¼ ë°ì´í„° ê²€ì‚¬ - ë¹„ì˜ ìƒ˜í”Œ: \(hasNonZeroSample), ìµœëŒ€ ê°’: \(maxSample)")
    
    // ì‹¤ì œ ë§ˆì´í¬ ì…ë ¥ë§Œ ë…¹ìŒ (í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ì ˆëŒ€ ìƒì„±í•˜ì§€ ì•ŠìŒ)
    if !hasNonZeroSample {
      print("ğŸ¤ [RealTime] ë¬´ìŒ êµ¬ê°„ - ì‹¤ì œ ë§ˆì´í¬ ì…ë ¥ ëŒ€ê¸° ì¤‘")
      // ë¬´ìŒì´ì–´ë„ ê³„ì† ë…¹ìŒ (ì‹¤ì œ ë¬´ìŒë„ ë…¹ìŒì˜ ì¼ë¶€)
    }
    
    // ë””ë²„ê·¸: ë²„í¼ ìˆ˜ì‹  í™•ì¸
    if recordedSamples.count % 10000 == 0 {
      print("ğŸ¤ [RealTime] ë²„í¼ ìˆ˜ì‹ : \(frameLength) í”„ë ˆì„, \(channelCount) ì±„ë„, ì´ ìƒ˜í”Œ: \(recordedSamples.count)")
    }
    
    // ë©€í‹°ì±„ë„ ì˜¤ë””ì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë‹¤ìš´ë¯¹ìŠ¤ - CRITICAL FIX
    let oldSampleCount = recordedSamples.count
    
    if channelCount == 1 {
      // ëª¨ë…¸ ì˜¤ë””ì˜¤: ì§ì ‘ ì‚¬ìš©
      let monoChannelData = channelData[0] // UnsafeMutablePointer<Float>
      print("ğŸ“Š [RealTime] ëª¨ë…¸ ì±„ë„ ë°ì´í„° ì¶”ê°€ ì¤‘... \(frameLength) ìƒ˜í”Œ")
      
      for i in 0..<frameLength {
        recordedSamples.append(monoChannelData[i])
      }
      
      print("âœ… [RealTime] ëª¨ë…¸ ìƒ˜í”Œ ì¶”ê°€ ì™„ë£Œ: \(oldSampleCount) -> \(recordedSamples.count)")
      
    } else if channelCount >= 2 {
      // ìŠ¤í…Œë ˆì˜¤/ë©€í‹°ì±„ë„ ì˜¤ë””ì˜¤: í‰ê· ìœ¼ë¡œ ë‹¤ìš´ë¯¹ìŠ¤
      let leftChannel = channelData[0] // UnsafeMutablePointer<Float>
      
      print("ğŸ“Š [RealTime] ìŠ¤í…Œë ˆì˜¤ ì±„ë„ ë°ì´í„° ë‹¤ìš´ë¯¹ìŠ¤ ì¤‘... \(frameLength) ìƒ˜í”Œ")
      
      // ì˜¤ë¥¸ìª½ ì±„ë„ì´ ìˆìœ¼ë©´ í‰ê· , ì—†ìœ¼ë©´ ì™¼ìª½ë§Œ ì‚¬ìš©
      if channelCount >= 2 {
        let rightChannel = channelData[1] // UnsafeMutablePointer<Float>
        for i in 0..<frameLength {
          let monoSample = (leftChannel[i] + rightChannel[i]) * 0.5  // L+R í‰ê· 
          recordedSamples.append(monoSample)
        }
        print("âœ… [RealTime] ìŠ¤í…Œë ˆì˜¤ L+R í‰ê·  ìƒ˜í”Œ ì¶”ê°€: \(oldSampleCount) -> \(recordedSamples.count)")
      } else {
        for i in 0..<frameLength {
          recordedSamples.append(leftChannel[i])
        }
        print("âœ… [RealTime] ì¢Œì¸¡ ì±„ë„ë§Œ ìƒ˜í”Œ ì¶”ê°€: \(oldSampleCount) -> \(recordedSamples.count)")
      }
    }
    
    // ìƒ˜í”Œ ì¶”ê°€ í™•ì¸
    let newSampleCount = recordedSamples.count
    if newSampleCount > oldSampleCount {
      print("ğŸ¯ [RealTime] ìƒ˜í”Œ ì¶”ê°€ ì„±ê³µ: \(oldSampleCount) -> \(newSampleCount) (+\(newSampleCount - oldSampleCount))")
    } else {
      print("âš ï¸ [RealTime] ìƒ˜í”Œì´ ì¶”ê°€ë˜ì§€ ì•ŠìŒ! ì´ì „: \(oldSampleCount), í˜„ì¬: \(newSampleCount)")
    }
    
    // RMS ë ˆë²¨ ê³„ì‚° (ìµœê·¼ ì¶”ê°€ëœ ìƒ˜í”Œë“¤ë¡œ)
    let recentSampleCount = min(frameLength, recordedSamples.count)
    let startIndex = max(0, recordedSamples.count - recentSampleCount)
    
    var sum: Float = 0.0
    for i in startIndex..<recordedSamples.count {
      sum += recordedSamples[i] * recordedSamples[i]
    }
    let rms = sqrt(sum / Float(recentSampleCount))
    let dbLevel = 20 * log10(max(rms, 0.000001))  // dB ë³€í™˜
    
    // CRITICAL FIX: dispose ìƒíƒœì™€ í•¨ê»˜ ì‹¤ì‹œê°„ ë ˆë²¨ ì „ì†¡
    DispatchQueue.main.async { [weak self] in
      guard let self = self, !self.isDisposed else { return }
      
      // ë„ˆë¬´ ìì£¼ í˜¸ì¶œë˜ì§€ ì•Šë„ë¡ ìƒ˜í”Œë§
      if self.recordedSamples.count % 4410 == 0 { // 0.1ì´ˆë§ˆë‹¤
        print("ğŸ“Š [RealTime] ë ˆë²¨: \(String(format: "%.1f", dbLevel))dB, ìƒ˜í”Œ: \(self.recordedSamples.count)")
        
        // channelê³¼ disposed ìƒíƒœ ì²´í¬
        if let channel = self.channel, !self.isDisposed {
          channel.invokeMethod("onAudioLevel", arguments: [
            "level": Double(dbLevel),
            "rms": Double(rms),
            "samples": self.recordedSamples.count
          ])
        }
      }
    }
  }
  
  func stopRecording(result: @escaping FlutterResult) {
    print("ğŸ›‘ [RealTime] ë…¹ìŒ ì¤‘ì§€ ìš”ì²­")
    
    guard let engine = audioEngine, let input = inputNode else {
      result(false)
      return
    }
    
    if !isRecording {
      print("âš ï¸ [RealTime] ë…¹ìŒ ì¤‘ì´ ì•„ë‹˜")
      result(true)
      return
    }
    
    // ì•ˆì „í•˜ê²Œ íƒ­ ì œê±°
    input.removeTap(onBus: 0)
    print("âœ… [RealTime] ì…ë ¥ íƒ­ ì œê±° ì™„ë£Œ")
    
    // ì—”ì§„ ì¤‘ì§€ (ì•ˆì „í•˜ê²Œ)
    if engine.isRunning {
      engine.stop()
      print("âœ… [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ì¤‘ì§€ ì™„ë£Œ")
    }
    
    isRecording = false
    
    let duration = recordingStartTime?.timeIntervalSinceNow ?? 0
    print("âœ… [RealTime] ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ")
    print("ğŸ“Š [RealTime] ì´ ìƒ˜í”Œ: \(recordedSamples.count), ì‹œê°„: \(String(format: "%.1f", abs(duration)))ì´ˆ")
    
    // ì—”ì§„ì€ ìœ ì§€í•˜ê³  ìƒíƒœë§Œ ë¦¬ì…‹
    // ë‹¤ìŒ ë…¹ìŒì„ ìœ„í•´ ì—”ì§„ ì¬ì‚¬ìš©
    
    result(true)
  }
  
  func getRecordedAudio(result: @escaping FlutterResult) {
    print("ğŸ“ [RealTime] ë…¹ìŒ ë°ì´í„° ìš”ì²­")
    print("ğŸ“Š [RealTime] ì €ì¥ëœ ìƒ˜í”Œ ìˆ˜: \(recordedSamples.count)")
    print("ğŸ” [RealTime] ë…¹ìŒ ìƒíƒœ: isRecording=\(isRecording)")
    print("ğŸ” [RealTime] ì˜¤ë””ì˜¤ ì—”ì§„ ìƒíƒœ: \(audioEngine?.isRunning ?? false)")
    
    if recordedSamples.isEmpty {
      print("âŒ [RealTime] ë…¹ìŒëœ ë°ì´í„° ì—†ìŒ - ì‹¤ì œ ì—ëŸ¬ ë°˜í™˜")
      
      // ì—ëŸ¬ ì›ì¸ ë¶„ì„
      var errorMessage = "No audio samples recorded"
      var errorCode = "NO_SAMPLES"
      
      if audioEngine == nil {
        errorMessage = "Audio engine not initialized"
        errorCode = "ENGINE_NOT_READY"
      } else if let engine = audioEngine, !engine.isRunning {
        errorMessage = "Audio engine not running during recording"
        errorCode = "ENGINE_NOT_RUNNING"
      } else if inputNode == nil {
        errorMessage = "Audio input node not available"
        errorCode = "INPUT_NODE_MISSING"
      } else {
        errorMessage = "Audio buffer processing failed - no data captured"
        errorCode = "BUFFER_PROCESSING_FAILED"
      }
      
      print("ğŸ” [RealTime] ì—ëŸ¬ ë¶„ì„: \(errorMessage)")
      result(FlutterError(code: errorCode, message: errorMessage, details: [
        "samplesCount": recordedSamples.count,
        "isRecording": isRecording,
        "engineRunning": audioEngine?.isRunning ?? false,
        "inputNodeAvailable": inputNode != nil
      ]))
    } else {
      print("âœ… [RealTime] ì‹¤ì œ ë…¹ìŒ ë°ì´í„° ë°˜í™˜: \(recordedSamples.count) ìƒ˜í”Œ")
      result(recordedSamples)
    }
  }
  
  func getRealtimeAudioBuffer(result: @escaping FlutterResult) {
    // ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ì„ ìœ„í•œ ìµœê·¼ ë²„í¼ë§Œ ë°˜í™˜ (2048 ìƒ˜í”Œ = ~0.04ì´ˆ)
    let bufferSize = 2048
    
    if recordedSamples.count < bufferSize {
      // ì•„ì§ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŒ
      result([])
      return
    }
    
    // ìµœê·¼ ë²„í¼ë§Œ ì¶”ì¶œ
    let startIdx = recordedSamples.count - bufferSize
    let recentBuffer = Array(recordedSamples[startIdx..<recordedSamples.count])
    
    print("ğŸ¤ [RealTime] ì‹¤ì‹œê°„ ë²„í¼ ë°˜í™˜: \(recentBuffer.count) ìƒ˜í”Œ")
    result(recentBuffer)
  }
  
  func loadAudioFile(path: String, result: @escaping FlutterResult) {
    print("ğŸµ [RealTime] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”©: \(path)")
    
    let fileURL = URL(fileURLWithPath: path)
    
    do {
      // AVAudioFileë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
      let audioFile = try AVAudioFile(forReading: fileURL)
      let format = audioFile.processingFormat
      let frameCount = UInt32(audioFile.length)
      
      print("ğŸ“Š [RealTime] ì˜¤ë””ì˜¤ í¬ë§·: \(format.sampleRate)Hz, \(format.channelCount)ì±„ë„, \(frameCount)í”„ë ˆì„")
      
      // ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„± (ì•ˆì „í•œ í¬ê¸° ì²´í¬)
      guard frameCount > 0 && frameCount < 100_000_000 else {  // í•©ë¦¬ì ì¸ ìƒí•œì„  ì„¤ì •
        result(FlutterError(code: "INVALID_FRAME_COUNT", message: "Invalid frame count: \(frameCount)", details: nil))
        return
      }
      
      guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
        result(FlutterError(code: "BUFFER_ERROR", message: "Failed to create audio buffer", details: nil))
        return
      }
      
      // íŒŒì¼ì—ì„œ ë²„í¼ë¡œ ì½ê¸°
      try audioFile.read(into: buffer)
      buffer.frameLength = frameCount
      
      // Float ë°°ì—´ë¡œ ë³€í™˜ (ëª¨ë…¸ë¡œ ë‹¤ìš´ë¯¹ìŠ¤)
      var audioSamples: [Float] = []
      let channelCount = Int(format.channelCount)
      
      if channelCount == 1 {
        // ëª¨ë…¸ ì˜¤ë””ì˜¤
        guard let channelData = buffer.floatChannelData?[0] else {
          result(FlutterError(code: "CHANNEL_ERROR", message: "Failed to get channel data", details: nil))
          return
        }
        for i in 0..<Int(frameCount) {
          audioSamples.append(channelData[i])
        }
      } else {
        // ìŠ¤í…Œë ˆì˜¤/ë©€í‹°ì±„ë„ â†’ ëª¨ë…¸ ë‹¤ìš´ë¯¹ìŠ¤
        guard let leftChannel = buffer.floatChannelData?[0],
              let rightChannel = buffer.floatChannelData?[1] else {
          result(FlutterError(code: "CHANNEL_ERROR", message: "Failed to get channel data", details: nil))
          return
        }
        
        for i in 0..<Int(frameCount) {
          let monoSample = (leftChannel[i] + rightChannel[i]) * 0.5
          audioSamples.append(monoSample)
        }
      }
      
      print("âœ… [RealTime] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: \(audioSamples.count) ìƒ˜í”Œ")
      
      // Flutterë¡œ ë°˜í™˜ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ)
      result([
        "samples": audioSamples,
        "sampleRate": format.sampleRate,
        "duration": Double(frameCount) / format.sampleRate
      ])
      
    } catch {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: \(error)")
      result(FlutterError(code: "LOAD_ERROR", message: error.localizedDescription, details: nil))
    }
  }
  
  func playRecording(result: @escaping FlutterResult) {
    print("ğŸ”Š [RealTime] ì‹¤ì œ ì˜¤ë””ì˜¤ ì¬ìƒ ìš”ì²­")
    
    guard !recordedSamples.isEmpty, !isDisposed else {
      print("âŒ [RealTime] ì¬ìƒí•  ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ ë˜ëŠ” disposed")
      result(false)
      return
    }
    
    // CRITICAL FIX: ê¸°ì¡´ í”Œë ˆì´ì–´ì™€ íƒ€ì´ë¨¸ë¥¼ ì•ˆì „í•˜ê²Œ ì •ë¦¬
    cleanupPlayback()
    
    // ë…¹ìŒëœ Float ë°°ì—´ì„ ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë³€í™˜
    do {
      let tempURL = createTempAudioFile(samples: recordedSamples)
      tempFileURL = tempURL  // ì„ì‹œ íŒŒì¼ ì¶”ì 
      print("ğŸ“ [RealTime] ì„ì‹œ íŒŒì¼ ìƒì„±: \(tempURL.path)")
      
      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      guard FileManager.default.fileExists(atPath: tempURL.path) else {
        print("âŒ [RealTime] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        result(false)
        return
      }
      
      // AVAudioSessionì€ iOS ì „ìš©ì´ë¯€ë¡œ macOSì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
      // macOSëŠ” AVAudioEngineì´ ìë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ ì„¸ì…˜ì„ ê´€ë¦¬í•¨
      
      // AVAudioPlayerë¡œ ì¬ìƒ
      audioPlayer = try AVAudioPlayer(contentsOf: tempURL)
      audioPlayer?.delegate = self
      
      guard audioPlayer?.prepareToPlay() == true else {
        print("âŒ [RealTime] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì¤€ë¹„ ì‹¤íŒ¨")
        result(false)
        return
      }
      
      if audioPlayer?.play() == true {
        print("âœ… [RealTime] ì‹¤ì œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ - ê¸¸ì´: \(String(format: "%.1f", audioPlayer?.duration ?? 0))ì´ˆ")
        
        // CRITICAL FIX: ì¬ìƒ ì™„ë£Œë¥¼ ì•ˆì „í•˜ê²Œ ëª¨ë‹ˆí„°ë§
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] timer in
          guard let self = self, !self.isDisposed else {
            timer.invalidate()
            return
          }
          
          guard let player = self.audioPlayer else {
            timer.invalidate()
            return
          }
          
          if !player.isPlaying {
            timer.invalidate()
            print("â¸ï¸ [RealTime] ì¬ìƒ ì™„ë£Œ")
            
            // CRITICAL FIX: ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
            if let tempURL = self.tempFileURL {
              DispatchQueue.global(qos: .background).asyncAfter(deadline: .now() + 1.0) {
                try? FileManager.default.removeItem(at: tempURL)
              }
              self.tempFileURL = nil
            }
          }
        }
        
        result(true)
      } else {
        print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ ì‹¤íŒ¨")
        cleanupPlayback()  // ì‹¤íŒ¨ ì‹œ ì •ë¦¬
        result(false)
      }
      
    } catch {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: \(error)")
      cleanupPlayback()  // ì˜ˆì™¸ ë°œìƒ ì‹œ ì •ë¦¬
      result(false)
    }
  }
  
  // CRITICAL FIX: ì¬ìƒ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì•ˆì „ ì •ë¦¬
  func cleanupPlayback() {
    // íƒ€ì´ë¨¸ ë¨¼ì € ì •ë¦¬
    playbackTimer?.invalidate()
    playbackTimer = nil
    
    // í”Œë ˆì´ì–´ delegate í•´ì œ í›„ ì •ì§€ (ì•ˆì „í•œ ìˆœì„œë¡œ)
    if let player = audioPlayer {
      // 1. delegateë¥¼ ë¨¼ì € í•´ì œ (ì¶”ê°€ ì½œë°± ë°©ì§€)
      player.delegate = nil
      // 2. ì¬ìƒ ì¤‘ì§€
      if player.isPlaying {
        player.stop()
      }
      // 3. ì°¸ì¡° í•´ì œ
      audioPlayer = nil
    }
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
    if let tempURL = tempFileURL {
      DispatchQueue.global(qos: .background).async {
        try? FileManager.default.removeItem(at: tempURL)
      }
      tempFileURL = nil
    }
  }
  
  private func createTempAudioFile(samples: [Float]) -> URL {
    let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    let tempURL = documentsPath.appendingPathComponent("temp_playback_\(Int(Date().timeIntervalSince1970)).wav")
    
    // ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
    try? FileManager.default.removeItem(at: tempURL)
    
    // ì‹¤ì œ ë…¹ìŒëœ ìƒ˜í”Œë ˆì´íŠ¸ì™€ ë™ì¼í•˜ê²Œ ì„¤ì • (48kHz)
    let sampleRate: Double = 48000.0
    
    guard let format = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: sampleRate, channels: 1, interleaved: false) else {
      print("âŒ [RealTime] ì˜¤ë””ì˜¤ í¬ë§· ìƒì„± ì‹¤íŒ¨")
      return tempURL
    }
    
    do {
      // ì•ˆì „í•œ íŒŒì¼ ìƒì„±
      let audioFile = try AVAudioFile(forWriting: tempURL, settings: format.settings)
      
      let frameCapacity = AVAudioFrameCount(samples.count)
      guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCapacity) else {
        print("âŒ [RealTime] ë²„í¼ ìƒì„± ì‹¤íŒ¨")
        return tempURL
      }
      
      // Float ìƒ˜í”Œì„ ë²„í¼ì— ì•ˆì „í•˜ê²Œ ë³µì‚¬
      guard let channelData = buffer.floatChannelData?[0] else {
        print("âŒ [RealTime] ì±„ë„ ë°ì´í„° ì ‘ê·¼ ì‹¤íŒ¨")
        return tempURL
      }
      
      let sampleCount = min(samples.count, Int(frameCapacity))
      for i in 0..<sampleCount {
        channelData[i] = samples[i]
      }
      buffer.frameLength = AVAudioFrameCount(sampleCount)
      
      try audioFile.write(from: buffer)
      print("ğŸ“ [RealTime] ì„ì‹œ ì¬ìƒ íŒŒì¼ ìƒì„±: \(sampleCount) ìƒ˜í”Œ -> \(tempURL.lastPathComponent)")
      
      // íŒŒì¼ í¬ê¸° í™•ì¸
      if let fileSize = try? FileManager.default.attributesOfItem(atPath: tempURL.path)[.size] as? Int {
        print("ğŸ“Š [RealTime] ìƒì„±ëœ íŒŒì¼ í¬ê¸°: \(fileSize) bytes")
      }
      
    } catch {
      print("âŒ [RealTime] ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: \(error)")
    }
    
    return tempURL
  }
  
  // MARK: - AVAudioPlayerDelegate
  // CRITICAL FIX: delegate ë©”ì†Œë“œì—ì„œ disposed ìƒíƒœ í™•ì¸
  func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
    guard !isDisposed else { return }  // disposed ìƒíƒœë©´ ë¬´ì‹œ
    
    print("ğŸ”Š [RealTime] ì¬ìƒ ì™„ë£Œë¨: successfully=\(flag)")
    
    // íƒ€ì´ë¨¸ ì •ë¦¬
    playbackTimer?.invalidate()
    playbackTimer = nil
    
    // í”Œë ˆì´ì–´ ì •ë¦¬ (ì¤‘ìš”: delegateë¥¼ ë¨¼ì € nilë¡œ ì„¤ì •)
    if audioPlayer === player {
      player.delegate = nil
      audioPlayer = nil
    }
    
    // ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ
    if let tempURL = tempFileURL {
      DispatchQueue.global(qos: .background).asyncAfter(deadline: .now() + 0.5) {
        try? FileManager.default.removeItem(at: tempURL)
      }
      tempFileURL = nil
    }
  }
  
  func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
    guard !isDisposed else { return }  // disposed ìƒíƒœë©´ ë¬´ì‹œ
    
    if let error = error {
      print("âŒ [RealTime] ì¬ìƒ ë””ì½”ë“œ ì˜¤ë¥˜: \(error)")
    }
    
    // ì˜¤ë¥˜ ì‹œ ì •ë¦¬
    cleanupPlayback()
  }
}

class MainFlutterWindow: NSWindow {
  private var audioRecorder: RealTimeAudioRecorder?
  
  override func awakeFromNib() {
    let flutterViewController = FlutterViewController()
    let windowFrame = self.frame
    self.contentViewController = flutterViewController
    self.setFrame(windowFrame, display: true)

    RegisterGeneratedPlugins(registry: flutterViewController)
    setupAudioChannel(controller: flutterViewController)
    requestMicrophonePermission()

    super.awakeFromNib()
  }
  
  private func requestMicrophonePermission() {
    let status = AVCaptureDevice.authorizationStatus(for: .audio)
    
    switch status {
    case .authorized:
      print("âœ… [Main] macOS ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨")
    case .notDetermined:
      print("ğŸ”” [Main] macOS ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...")
      AVCaptureDevice.requestAccess(for: .audio) { granted in
        DispatchQueue.main.async {
          print(granted ? "âœ… [Main] ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨!" : "âŒ [Main] ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨")
        }
      }
    case .denied, .restricted:
      print("âŒ [Main] ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    @unknown default:
      print("âš ï¸ [Main] ì•Œ ìˆ˜ ì—†ëŠ” ê¶Œí•œ ìƒíƒœ")
    }
  }
  
  private func setupAudioChannel(controller: FlutterViewController) {
    let channel = FlutterMethodChannel(
      name: "audio_capture",
      binaryMessenger: controller.engine.binaryMessenger
    )
    
    audioRecorder = RealTimeAudioRecorder(channel: channel)
    
    channel.setMethodCallHandler { [weak self] (call, result) in
      guard let recorder = self?.audioRecorder else {
        result(FlutterError(code: "NO_RECORDER", message: "Recorder not initialized", details: nil))
        return
      }
      
      switch call.method {
      case "startRecording":
        recorder.startRecording(result: result)
      case "stopRecording":
        recorder.stopRecording(result: result)
      case "getRecordedAudio":
        recorder.getRecordedAudio(result: result)
      case "getRealtimeAudioBuffer":
        recorder.getRealtimeAudioBuffer(result: result)
      case "loadAudioFile":
        if let args = call.arguments as? [String: Any],
           let path = args["path"] as? String {
          recorder.loadAudioFile(path: path, result: result)
        } else {
          result(FlutterError(code: "INVALID_ARGS", message: "Path required", details: nil))
        }
      case "playAudio":
        recorder.playRecording(result: result)
      case "pauseAudio":
        result(true)
      case "stopAudio":
        self?.audioRecorder?.cleanupPlayback()
        result(true)
      case "stopPlayback":
        // stopPlayback ë©”ì„œë“œ êµ¬í˜„ (stopAudioì™€ ë™ì¼í•œ ë™ì‘)
        self?.audioRecorder?.cleanupPlayback()
        result(true)
      case "seekAudio":
        result(true)
      case "getCurrentAudioLevel":
        // í˜„ì¬ ì˜¤ë””ì˜¤ ë ˆë²¨ ë°˜í™˜ (ì„ì‹œ êµ¬í˜„)
        result(0.0)
      default:
        result(FlutterMethodNotImplemented)
      }
    }
    
    print("âœ… [Main] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
  }
}