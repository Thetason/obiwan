#!/usr/bin/env python3
"""ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë¼ë²¨ë§ í…ŒìŠ¤íŠ¸"""

import os
import json
import base64
import requests
import numpy as np
from datetime import datetime

# ê¸°ì¡´ ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
audio_files = [
    "/Users/seoyeongbin/vocal_trainer_ai/test_audio.wav",
    "/Users/seoyeongbin/vocal_trainer_ai/test_recording.wav",
    "/Users/seoyeongbin/Downloads/sample.wav"
]

# ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ì°¾ê¸°
test_file = None
for file in audio_files:
    if os.path.exists(file):
        test_file = file
        break

if not test_file:
    print("âŒ í…ŒìŠ¤íŠ¸í•  ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("WAV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # ê°„ë‹¨í•œ WAV íŒŒì¼ ìƒì„±
    import wave
    sample_rate = 44100
    duration = 2.0
    frequency = 440.0  # A4
    
    t = np.linspace(0, duration, int(sample_rate * duration))
    audio = (np.sin(2 * np.pi * frequency * t) * 32767).astype(np.int16)
    
    test_file = "/Users/seoyeongbin/vocal_trainer_ai/test_generated.wav"
    with wave.open(test_file, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(audio.tobytes())
    print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±: {test_file}")

print(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ë¼ë²¨ë§ í…ŒìŠ¤íŠ¸")
print(f"íŒŒì¼: {test_file}")
print(f"í¬ê¸°: {os.path.getsize(test_file):,} bytes")

# íŒŒì¼ ì½ê¸° ë° Base64 ì¸ì½”ë”©
with open(test_file, 'rb') as f:
    audio_bytes = f.read()
    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

print(f"Base64 í¬ê¸°: {len(audio_base64):,} characters")

# CREPE ì„œë²„ í…ŒìŠ¤íŠ¸
print("\nğŸ“Š AI ë¶„ì„ ì‹œì‘...")
try:
    response = requests.post(
        'http://localhost:5002/analyze',
        json={'audio': audio_base64},
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        print("âœ… CREPE ë¶„ì„ ì„±ê³µ!")
        
        # ê²°ê³¼ ìš”ì•½
        if 'pitch' in result:
            pitch_data = result['pitch']
            print(f"  - ë¶„ì„ëœ í”„ë ˆì„: {len(pitch_data)}")
            
            # í‰ê·  í”¼ì¹˜ ê³„ì‚°
            valid_pitches = [p for p in pitch_data if p > 0]
            if valid_pitches:
                avg_pitch = np.mean(valid_pitches)
                print(f"  - í‰ê·  í”¼ì¹˜: {avg_pitch:.2f}Hz")
                print(f"  - ìµœì†Œ í”¼ì¹˜: {min(valid_pitches):.2f}Hz")
                print(f"  - ìµœëŒ€ í”¼ì¹˜: {max(valid_pitches):.2f}Hz")
        
        # ë¼ë²¨ ìƒì„±
        label = {
            "id": f"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "file": test_file,
            "timestamp": datetime.now().isoformat(),
            "analysis": {
                "crepe": result,
                "summary": {
                    "frames": len(result.get('pitch', [])),
                    "avg_pitch": avg_pitch if 'avg_pitch' in locals() else None
                }
            }
        }
        
        # ë¼ë²¨ ì €ì¥
        label_file = f"/Users/seoyeongbin/vocal_trainer_ai/labels/test_label_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(label_file, 'w') as f:
            json.dump(label, f, indent=2)
        
        print(f"\nâœ… ë¼ë²¨ ì €ì¥ ì™„ë£Œ: {label_file}")
        
    else:
        print(f"âŒ ì„œë²„ ì—ëŸ¬: {response.status_code}")
        print(response.text)
        
except Exception as e:
    print(f"âŒ ì—°ê²° ì‹¤íŒ¨: {e}")

print("\n" + "="*60)
print("ğŸ¯ YouTube ë¼ë²¨ë§ ë´‡ ê°œë°œ ìƒíƒœ:")
print("âœ… ë¡œì»¬ íŒŒì¼ ë¼ë²¨ë§: í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
print("â³ YouTube ë‹¤ìš´ë¡œë“œ: ffmpeg ì„¤ì¹˜ ëŒ€ê¸°")
print("ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: YouTube URLë¡œ ì‹¤ì œ ë¼ë²¨ë§")