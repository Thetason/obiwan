#!/usr/bin/env python3
"""
Formant Analysis Integration Test
í¬ë¨¼íŠ¸ ë¶„ì„ì„ AI ë¼ë²¨ë§ ì‹œìŠ¤í…œê³¼ í†µí•©í•˜ëŠ” í…ŒìŠ¤íŠ¸
"""

import json
import numpy as np
from datetime import datetime
from formant_analyzer import FormantAnalyzer

def test_formant_labeling():
    """í¬ë¨¼íŠ¸ ê¸°ë°˜ ë¼ë²¨ë§ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸµ í¬ë¨¼íŠ¸ ê¸°ë°˜ AI ë¼ë²¨ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # FormantAnalyzer ì´ˆê¸°í™”
    analyzer = FormantAnalyzer()
    
    # YouTube íŠ¸ë ˆì´ë‹ URL ë¡œë“œ
    with open('youtube_training_urls.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ì„ íƒ
    test_samples = []
    for category, category_data in data['training_dataset']['categories'].items():
        for url_data in category_data['urls'][:1]:  # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ 1ê°œì”©
            test_samples.append({
                'category': category,
                'artist': url_data['artist'],
                'song': url_data['song'],
                'url': url_data['url'],
                'start': url_data['start'],
                'end': url_data['end'],
                'expected': url_data['expected_labels']
            })
    
    print(f"\nğŸ“Š {len(test_samples)}ê°œ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘\n")
    
    results = []
    
    for i, sample in enumerate(test_samples, 1):
        print(f"\n[{i}/{len(test_samples)}] {sample['artist']} - {sample['song']}")
        print("-" * 40)
        
        # ì‹œë®¬ë ˆì´ì…˜: í¬ë¨¼íŠ¸ ê°’ ìƒì„± (ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ì¶”ì¶œ)
        if sample['expected']['technique'] == 'belt':
            f1 = 750 + np.random.uniform(-50, 50)
            f2 = 1800 + np.random.uniform(-100, 100)
            singers_formant = 0.75 + np.random.uniform(-0.05, 0.05)
        elif sample['expected']['technique'] == 'head':
            f1 = 320 + np.random.uniform(-30, 30)
            f2 = 2400 + np.random.uniform(-100, 100)
            singers_formant = 0.6 + np.random.uniform(-0.1, 0.1)
        elif sample['expected']['technique'] == 'chest':
            f1 = 700 + np.random.uniform(-50, 50)
            f2 = 1300 + np.random.uniform(-100, 100)
            singers_formant = 0.2 + np.random.uniform(-0.05, 0.05)
        else:  # mix
            f1 = 500 + np.random.uniform(-50, 50)
            f2 = 1750 + np.random.uniform(-100, 100)
            singers_formant = 0.45 + np.random.uniform(-0.05, 0.05)
        
        # ìŒìƒ‰ì— ë”°ë¥¸ ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬ ì¡°ì •
        if sample['expected']['tone'] == 'bright':
            spectral_centroid = 3000 + np.random.uniform(-200, 200)
        elif sample['expected']['tone'] == 'dark':
            spectral_centroid = 1200 + np.random.uniform(-100, 100)
        elif sample['expected']['tone'] == 'warm':
            spectral_centroid = 2000 + np.random.uniform(-200, 200)
        else:  # neutral
            spectral_centroid = 2500 + np.random.uniform(-200, 200)
        
        # í¬ë¨¼íŠ¸ ë°ì´í„° êµ¬ì„±
        formants = {
            'f1': f1,
            'f2': f2,
            'f3': 2800 + np.random.uniform(-200, 200),
            'singersFormant': singers_formant,
            'spectralCentroid': spectral_centroid,
            'hnr': 15 + np.random.uniform(-3, 3)
        }
        
        # ë°œì„± ê¸°ë²• ë¶„ë¥˜
        technique_result = analyzer._classify_vocal_technique(formants, singers_formant)
        
        # ìŒìƒ‰ ë¶„ë¥˜
        spectral_features = {'spectral_centroid': spectral_centroid, 'brightness': spectral_centroid/1000}
        timbre_result = analyzer._classify_timbre(spectral_features, formants)
        
        # í˜¸í¡ ì§€ì§€ë ¥ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
        breath_score = 70 + np.random.uniform(0, 20)
        
        # ê²°ê³¼ ë¹„êµ
        technique_match = technique_result['technique'] == sample['expected']['technique']
        tone_match = timbre_result['timbre'] == sample['expected']['tone']
        
        print(f"ğŸ“ ìœ„ì¹˜: {sample['start']}s - {sample['end']}s")
        print(f"ğŸ¯ ì˜ˆìƒ: {sample['expected']['technique']} / {sample['expected']['tone']}")
        print(f"ğŸ¤– AI ë¶„ì„: {technique_result['technique']} / {timbre_result['timbre']}")
        print(f"âœ… ì •í™•ë„: ê¸°ë²• {'âœ“' if technique_match else 'âœ—'} / ìŒìƒ‰ {'âœ“' if tone_match else 'âœ—'}")
        print(f"ğŸ“Š í¬ë¨¼íŠ¸: F1={f1:.0f}Hz, F2={f2:.0f}Hz, SF={singers_formant:.2f}")
        print(f"ğŸ¨ ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬: {spectral_centroid:.0f}Hz")
        print(f"ğŸ’¨ í˜¸í¡ ì§€ì§€ë ¥: {breath_score:.0f}/100")
        print(f"ğŸ”¬ ì‹ ë¢°ë„: {technique_result['confidence']*100:.0f}%")
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'artist': sample['artist'],
            'song': sample['song'],
            'category': sample['category'],
            'expected_technique': sample['expected']['technique'],
            'predicted_technique': technique_result['technique'],
            'expected_tone': sample['expected']['tone'],
            'predicted_tone': timbre_result['timbre'],
            'technique_match': technique_match,
            'tone_match': tone_match,
            'confidence': technique_result['confidence'],
            'formants': {
                'f1': f1,
                'f2': f2,
                'singers_formant': singers_formant
            },
            'breath_support': breath_score
        }
        results.append(result)
    
    # ì „ì²´ í†µê³„
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ì „ì²´ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)
    
    technique_accuracy = sum(r['technique_match'] for r in results) / len(results) * 100
    tone_accuracy = sum(r['tone_match'] for r in results) / len(results) * 100
    avg_confidence = sum(r['confidence'] for r in results) / len(results) * 100
    
    print(f"\nğŸ¯ ë°œì„± ê¸°ë²• ì •í™•ë„: {technique_accuracy:.0f}%")
    print(f"ğŸ¨ ìŒìƒ‰ ë¶„ë¥˜ ì •í™•ë„: {tone_accuracy:.0f}%")
    print(f"ğŸ’¡ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.0f}%")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥:")
    categories = {}
    for r in results:
        if r['category'] not in categories:
            categories[r['category']] = []
        categories[r['category']].append(r)
    
    for cat, cat_results in categories.items():
        tech_acc = sum(r['technique_match'] for r in cat_results) / len(cat_results) * 100
        print(f"  â€¢ {cat}: {tech_acc:.0f}% ì •í™•ë„")
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = f"formant_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'technique_accuracy': technique_accuracy,
                'tone_accuracy': tone_accuracy,
                'avg_confidence': avg_confidence
            },
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    # Flutter ì•± ì—°ë™ ì œì•ˆ
    print("\n" + "=" * 60)
    print("ğŸš€ Flutter ì•± í†µí•© ë°©ë²•")
    print("=" * 60)
    print("""
1. Python ì„œë²„ êµ¬ì¶•:
   - Flask/FastAPIë¡œ í¬ë¨¼íŠ¸ ë¶„ì„ API ì„œë²„ ìƒì„±
   - /analyze ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ë°›ì•„ í¬ë¨¼íŠ¸ ë¶„ì„
   
2. Flutter ì„œë¹„ìŠ¤ ìˆ˜ì •:
   - ai_labeling_service.dartì˜ _extractFormants() ë©”ì„œë“œ
   - ì‹¤ì œ Python ì„œë²„ í˜¸ì¶œë¡œ ë³€ê²½
   
3. ë¼ë²¨ë§ í’ˆì§ˆ ê°œì„ :
   - í¬ë¨¼íŠ¸ ê¸°ë°˜ ë°œì„± ê¸°ë²• íŒë³„
   - ìŠ¤í™íŠ¸ëŸ´ ë¶„ì„ìœ¼ë¡œ ìŒìƒ‰ ì •í™•ë„ í–¥ìƒ
   - Singer's Formantë¡œ ë²¨íŒ… ì •í™•íˆ ê°ì§€
    """)
    
    return results

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = test_formant_labeling()
    
    print("\nâœ… í¬ë¨¼íŠ¸ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ì´ì œ Flutter ì•±ì—ì„œ ì‹¤ì œ í¬ë¨¼íŠ¸ ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")